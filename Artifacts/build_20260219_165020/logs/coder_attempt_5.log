OpenAI Codex v0.87.0 (research preview)
--------
workdir: /Users/emmanuel/Documents/Theory/Redefining_racism
model: gpt-5.2-codex
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: high
reasoning summaries: auto
session id: 019c77f4-f944-7960-9e56-c7b41dd42a4e
--------
user
You are a Swift/SwiftUI developer. A previous attempt to complete a task failed.

TESTING & DEBUGGING REFERENCE:
For building, testing, and debugging iOS/macOS apps, reference this workflow guide:
/Users/emmanuel/Dev/Tools/Eocon-Foundation-V1/.Foundation/Docs/swiftDocs/Testing/XCODEBUILD_MCP_WORKFLOW.md

This guide covers:
- XcodeBuild MCP server tools for programmatic Xcode interaction
- Building for simulator, booting simulators, installing/launching apps
- UI automation: screenshots, accessibility hierarchy, tap simulation
- Debugging UI issues (button taps, gestures, navigation)

=== ORIGINAL TASK ===
I have created the following plan after thorough exploration and analysis of the codebase. Follow the below plan verbatim. Trust the files and references. Do not re-verify what's written in the plan. Explore only when absolutely necessary. First implement all the proposed file changes and then I'll review all the changes together at the end.

## Observations

The project at \`file:app/decodingOppression/decodingOppression.xcodeproj\` is a freshly generated multiplatform SwiftUI + SwiftData app. It uses Xcode 16's \`PBXFileSystemSynchronizedRootGroup\`, meaning any new files/folders added to the \`decodingOppression/\` directory on disk are automatically picked up by the build system — no manual \`.pbxproj\` edits are needed for source files. The only \`.pbxproj\` change required is adding the SPM package. The placeholder \`Item.swift\` and \`ContentView.swift\` must be replaced.

## Approach

Work directly on the existing project without recreating it. The steps follow a strict dependency order: SPM first (so \`@Generable\` and \`FoundationModels\` are resolvable at compile time), then data models (depended on by the app entry point), then the app entry point update, then the placeholder \`ContentView\`, and finally the bundled JSON resource.

---

## Implementation Steps

### 1. Add \`mlx-swift-lm\` SPM Dependency

In Xcode, open \`file:app/decodingOppression/decodingOppression.xcodeproj\` and go to **Project → Package Dependencies → +**. Add:

- **URL:** \`https://github.com/ml-explore/mlx-swift-lm/\`
- **Version rule:** Up to Next Minor From \`2.29.1\`

Link the \`MLXLLM\`, \`MLXEmbedders\`, and \`MLXLMCommon\` products to the \`decodingOppression\` app target. (These are needed now so that \`@Generable\` types in \`GenerableTypes.swift\` compile; the actual engines come in later tickets.)

> **Note:** \`@Generable\` is part of Apple's \`FoundationModels\` framework (iOS 26+ / macOS 26+), which is a system framework — no additional SPM package is needed for it. Only \`mlx-swift-lm\` is an external dependency.

---

### 2. Create the \`Models/\` Group and Source Files

Create a new folder \`app/decodingOppression/decodingOppression/Models/\` on disk. Because the project uses \`PBXFileSystemSynchronizedRootGroup\`, Xcode will automatically include all \`.swift\` files placed here.

#### 2a. \`Models/Policy.swift\`

Define the following types (all value types, no SwiftData persistence):

- \`struct Policy: Identifiable\` — \`id: UUID\`, \`name: String\`, \`year: Int\`, \`sections: [Section]\`, \`clauses: [Clause]\`
- \`struct Clause: Identifiable\` — \`id: UUID\`, \`text: String\`, \`sectionType: SectionType\`, \`targetGroup: TargetGroup?\`, \`effectDirection: EffectDirection?\`
- \`struct Section: Identifiable\` — \`id: UUID\`, \`type: SectionType\`, \`rawText: String\`
- \`enum SectionType: String, Codable, CaseIterable\` — cases: \`title\`, \`definitions\`, \`operativeClauses\`, \`penalties\`, \`exceptions\`
- \`enum TargetGroup: String, Codable, CaseIterable\` — cases: \`outgroup\`, \`ingroupNonElite\`, \`elite\`, \`multiple\`
- \`enum EffectDirection: String, Codable, CaseIterable\` — cases: \`burden\`, \`benefit\`, \`neutral\`, \`mixed\`
- \`enum MLTier: String, Codable\` — cases: \`tier1\`, \`tier2\`, \`tier3\`

All enums should conform to \`Codable\` so they can be stored in SwiftData \`@Model\` classes and serialized to JSON.

#### 2b. \`Models/ScoreResult.swift\`

Define \`struct ScoreResult: Codable\` with six \`Double\` properties: \`dis\`, \`ads\`, \`eis\`, \`cis\`, \`oes\`, \`coi\`. Add a static \`zero\` property returning all zeros. This is a pure value type — no SwiftData annotation.

#### 2c. \`Models/AnalyzedClause.swift\`

Define \`@Model final class AnalyzedClause\` with:
- \`var id: UUID\`
- \`var text: String\`
- \`var sectionType: SectionType\`
- \`var targetGroup: TargetGroup\`
- \`var effectDirection: EffectDirection\`
- \`var confidence: Double\`
- \`var tierUsed: MLTier\`
- \`var analysis: PolicyAnalysis?\` (inverse relationship — back-reference to parent)

#### 2d. \`Models/PolicyAnalysis.swift\`

Define \`@Model final class PolicyAnalysis\` with:
- \`var id: UUID\`
- \`var policyName: String\`
- \`var sourceFilename: String\`
- \`var dateAnalyzed: Date\`
- \`var scoreResult: ScoreResult\` (embedded value type — use \`@Attribute(.externalStorage)\` if needed for the Codable struct)
- \`@Relationship(deleteRule: .cascade) var clauses: [AnalyzedClause]\`

This replaces \`Item.swift\` as the primary SwiftData entity.

#### 2e. \`Models/GenerableTypes.swift\`

Import \`FoundationModels\`. Define three \`@Generable\` structs for Foundation Models structured output:

- \`ClauseClassification\` — with nested \`@Generable enum TargetGroup\` and \`@Generable enum EffectDirection\`, plus \`confidence: Double\` and \`rationale: String\` with appropriate \`@Guide\` annotations
- \`ArchitectureDetection\` — four \`Double\` properties (\`asymmetricAutonomyRestriction\`, \`selectiveEmpathy\`, \`ideologicalJustification\`, \`resistanceToStructuralCritique\`) each with \`@Guide(.range(0.0...1.0))\`
- \`ProxyDetection\` — \`usesProxyVariables: Bool\`, \`proxyTerms: [String]\` with \`@Guide(.count(0...5))\`, \`expandsOutgroup: Bool\`

Declare properties in classification-first order so constrained decoding can use earlier fields to influence later ones.

#### 2f. \`Models/PipelineContracts.swift\`

Define the two shared pipeline types:

- \`enum AnalysisProgress\` — cases: \`extracting\`, \`classifying(clauseIndex: Int, total: Int, partialScores: ScoreResult)\`, \`complete(ScoreResult)\`, \`failed(Error)\`
- \`struct TierClassification\` — properties: \`targetGroup: TargetGroup\`, \`effectDirection: EffectDirection\`, \`architectureScores: ArchitectureScores\`, \`proxyDetection: ProxyDetection\`, \`confidence: Double\`, \`tier: MLTier\`

Also define \`struct ArchitectureScores: Codable\` here (four \`Double\` fields: \`aar\`, \`se\`, \`ij\`, \`rsc\`) since it is referenced by \`TierClassification\` and later by \`TrainingClause\`.

---

### 3. Create \`Data/KeywordTaxonomies.json\`

Create \`app/decodingOppression/decodingOppression/Data/KeywordTaxonomies.json\` as a bundled resource. The JSON structure should have three top-level keys:

\`\`\`
{
  \"outgroupBurden\": [...],      // O-targeting burden keywords
  \"ingroupBenefit\": [...],      // I\\E-targeting benefit keywords
  \"eliteExtraction\": [...],     // E-targeting extraction keywords
  \"dogWhistleProxies\": [...]    // proxy term gazetteer for NLGazetteer
}
\`\`\`

Populate each array with seed terms drawn from the paper's framework (e.g., \"negro\", \"slave\", \"colored\", \"redlined\", \"drug offender\" for \`outgroupBurden\`; \"citizen\", \"property owner\", \"taxpayer\" for \`ingroupBenefit\`; etc.). This file is consumed at runtime by \`KeywordEngine\` (T2) via \`Bundle.main.url(forResource:withExtension:)\`.

Ensure the file is added to the app target's **Copy Bundle Resources** build phase. Since the project uses \`PBXFileSystemSynchronizedRootGroup\`, placing it inside the \`decodingOppression/\` folder should include it automatically, but verify in Xcode's target membership panel.

---

### 4. Update \`decodingOppressionApp.swift\`

In \`file:app/decodingOppression/decodingOppression/decodingOppressionApp.swift\`, update \`sharedModelContainer\` to register \`PolicyAnalysis\` and \`AnalyzedClause\` instead of \`Item\`:

- Replace \`Item.self\` in the \`Schema([...])\` array with \`PolicyAnalysis.self, AnalyzedClause.self\`
- Remove the \`import\` of anything \`Item\`-specific (none needed beyond what's already there)

---

### 5. Replace \`ContentView.swift\` with a Minimal Placeholder

Replace the entire body of \`file:app/decodingOppression/decodingOppression/ContentView.swift\` with a minimal stub that:
- Removes all references to \`Item\` and \`@Query private var items: [Item]\`
- Shows a simple \`Text(\"decodingOppression\")\` or \`ContentUnavailableView\` placeholder
- Keeps the \`#Preview\` block compiling without a model container (since \`Item\` is gone)

This placeholder will be replaced in T7.

---

### 6. Delete \`Item.swift\`

Delete \`file:app/decodingOppression/decodingOppression/Item.swift\` from disk. Because the project uses \`PBXFileSystemSynchronizedRootGroup\`, Xcode will automatically stop compiling it once it is removed from the filesystem. Verify no remaining references to \`Item\` exist anywhere in the project (search for \`Item\` in the project).

---

## File Change Summary

| Action | File |
|--------|------|
| Delete | \`file:app/decodingOppression/decodingOppression/Item.swift\` |
| Replace | \`file:app/decodingOppression/decodingOppression/ContentView.swift\` |
| Update | \`file:app/decodingOppression/decodingOppression/decodingOppressionApp.swift\` |
| Create | \`file:app/decodingOppression/decodingOppression/Models/Policy.swift\` |
| Create | \`file:app/decodingOppression/decodingOppression/Models/ScoreResult.swift\` |
| Create | \`file:app/decodingOppression/decodingOppression/Models/AnalyzedClause.swift\` |
| Create | \`file:app/decodingOppression/decodingOppression/Models/PolicyAnalysis.swift\` |
| Create | \`file:app/decodingOppression/decodingOppression/Models/GenerableTypes.swift\` |
| Create | \`file:app/decodingOppression/decodingOppression/Models/PipelineContracts.swift\` |
| Create | \`file:app/decodingOppression/decodingOppression/Data/KeywordTaxonomies.json\` |
| SPM | Add \`mlx-swift-lm\` ≥ 2.29.1 via Xcode Package Dependencies |
=== END ORIGINAL TASK ===

=== REFERENCE CONTEXT ===

=== SWIFT DOCUMENTATION ===

--- FILE: Generable.md ---
# Generable

**A type that the model uses when responding to prompts.**

## Availability

- **iOS** 26.0+
- **iPadOS** 26.0+
- **Mac Catalyst** 26.0+
- **macOS** 26.0+
- **visionOS** 26.0+


## Overview

Annotate your Swift structure or enumeration with the `@Generable` macro to allow the model to respond to prompts by generating an instance of your type. Use the `@Guide` macro to provide natural language descriptions of your properties, and programmatically control the values that the model can generate.

```swift
@Generable
struct SearchSuggestions {
    @Guide(description: "A list of suggested search terms", .count(4))
    var searchTerms: [SearchTerm]

    @Generable
    struct SearchTerm {
        // Use a generation identifier for data structures the framework generates.
        var id: GenerationID

        @Guide(description: "A 2 or 3 word search term, like 'Beautiful sunsets'")
        var searchTerm: String
    }
}
```


> **NOTE**: `@Generable` macro [doc://com.apple.foundationmodels/documentation/FoundationModels/Generable(description:)](https://developer.apple.com/documentation/FoundationModels/Generable(description:)) and  `@Guide` macro [doc://com.apple.foundationmodels/documentation/FoundationModels/Guide(description:)](https://developer.apple.com/documentation/FoundationModels/Guide(description:)).


## Topics

### Defining a generable type

- [Generable(description:)](https://developer.apple.com/documentation/foundationmodels/generable(description:)) — Conforms a type to [doc://com.apple.foundationmodels/documentation/FoundationModels/Generable](https://developer.apple.com/documentation/FoundationModels/Generable) protocol.
### Creating a guide

- [Guide(description:)](https://developer.apple.com/documentation/foundationmodels/guide(description:)) — Allows for influencing the allowed values of properties of a [doc://com.apple.foundationmodels/documentation/FoundationModels/Generable](https://developer.apple.com/documentation/FoundationModels/Generable) type.
- [Guide(description:_:)](https://developer.apple.com/documentation/foundationmodels/guide(description:_:)) — Allows for influencing the allowed values of properties of a [doc://com.apple.foundationmodels/documentation/FoundationModels/Generable](https://developer.apple.com/documentation/FoundationModels/Generable) type.
- [GenerationGuide](https://developer.apple.com/documentation/foundationmodels/generationguide) — Guides that control how values are generated.
### Getting the schema

- [generationSchema](https://developer.apple.com/documentation/foundationmodels/generable/generationschema) — An instance of the generation schema.
- [GenerationSchema](https://developer.apple.com/documentation/foundationmodels/generationschema) — A type that describes the properties of an object and any guides on their values.
### Generating a unique identifier

- [GenerationID](https://developer.apple.com/documentation/foundationmodels/generationid) — A unique identifier that is stable for the duration of a response, but not across responses.
### Converting to partially generated

- [asPartiallyGenerated()](https://developer.apple.com/documentation/foundationmodels/generable/aspartiallygenerated()) — The partially generated type of this struct.
- [PartiallyGenerated](https://developer.apple.com/documentation/foundationmodels/generable/partiallygenerated) — A representation of partially generated content
### Generate dynamic shemas

- [DynamicGenerationSchema](https://developer.apple.com/documentation/foundationmodels/dynamicgenerationschema) — The dynamic counterpart to the generation schema type that you use to construct schemas at runtime.

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/Generable](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/Generable)*
--- END FILE ---

--- FILE: Generating-Swift-data-structures-with-guided-generation.md ---
# Generating Swift data structures with guided generation

**Create robust apps by describing output you want programmatically.**


## Overview

When you perform a request, the model returns a raw string in its natural language format. Raw strings require you to manually parse the details you want. Instead of working with raw strings, the framework provides guided generation, which gives strong guarantees that the response is in a format you expect.

To use guided generation, describe the output you want as a new Swift type. When you make a request to the model, include your custom type and the framework performs the work necessary to fill in and return an object with the parameters filled in for you. The framework uses constrained sampling when generating output, which defines the rules on what the model can generate. Constrained sampling prevents the model from producing malformed output and provides you with results as a type you define.

For more information about creating a session and prompting the model, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models](https://developer.apple.com/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models).


## Conform your data type to Generable

To conform your type to [doc://com.apple.foundationmodels/documentation/FoundationModels/Generable](https://developer.apple.com/documentation/FoundationModels/Generable), describe the type and the parameters to guide the response of the model. The framework supports generating content with basic Swift types like `Bool`, `Int`, `Float`, `Double`, `Decimal`, and `Array`. For example, if you only want the model to return a numeric result, call [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/respond(to:generating:includeSchemaInPrompt:options:)-13kji](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/respond(to:generating:includeSchemaInPrompt:options:)-13kji) using the type `Float`:

```swift
let prompt = "How many tablespoons are in a cup?"
let session = LanguageModelSession(model: .default)

// Generate a response with the type `Float`, instead of `String`.
let response = try await session.respond(to: prompt, generating: Float.self)
```

A schema provides the ability to control the values of a property, and you can specify guides to control values you associate with it. The framework provides two macros that help you with schema creation. Use [doc://com.apple.foundationmodels/documentation/FoundationModels/Generable(description:)](https://developer.apple.com/documentation/FoundationModels/Generable(description:)) on structures, actors, and enumerations; and only use [doc://com.apple.foundationmodels/documentation/FoundationModels/Guide(description:)](https://developer.apple.com/documentation/FoundationModels/Guide(description:)) with stored properties.

When you add descriptions to `Generable` properties, you help the model understand the semantics of the properties. Keep the descriptions as short as possible — long descriptions take up additional context size and can introduce latency. The following example creates a type that describes a cat and includes a name, an age that’s constrained to a range of values, and a short profile:

```swift
@Generable(description: "Basic profile information about a cat")
struct CatProfile {
    // A guide isn't necessary for basic fields.
    var name: String

    @Guide(description: "The age of the cat", .range(0...20))
    var age: Int

    @Guide(description: "A one sentence profile about the cat's personality")
    var profile: String
}
```


> **NOTE**: The model generates `Generable` properties in the order they’re declared.


You can nest custom `Generable` types inside other `Generable` types, and mark enumerations with associated values as `Generable`. The `Generable` macro ensures that all associated and nested values are themselves generable. This allows for advanced use cases like creating complex data types or dynamically generating views at runtime.


## Make a request with your custom data type

After creating your type, use it along with a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession) to prompt the model. When you use a `Generable` type it prevents the model from producing malformed output and prevents the need for any manual string parsing.

```swift
// Generate a response using a custom type.
let response = try await session.respond(
    to: "Generate a cute rescue cat",
    generating: CatProfile.self
)
```


## Define a dynamic schema at runtime

If you don’t know what you want the model to produce at compile time use [doc://com.apple.foundationmodels/documentation/FoundationModels/DynamicGenerationSchema](https://developer.apple.com/documentation/FoundationModels/DynamicGenerationSchema) to define what you need. For example, when you’re working on a restaurant app and want to restrict the model to pick from menu options that a restaurant provides. Because each restaurant provides a different menu, the schema won’t be known in its entirety until runtime.

```swift
// Create the dynamic schema at runtime.
let menuSchema = DynamicGenerationSchema(
    name: "Menu",
    properties: [
        DynamicGenerationSchema.Property(
            name: "dailySoup",
            schema: DynamicGenerationSchema(
                name: "dailySoup",
                anyOf: ["Tomato", "Chicken Noodle", "Clam Chowder"]
            )
        )

        // Add additional properties.
    ]
)
```

After creating a dynamic schema, use it to create a [doc://com.apple.foundationmodels/documentation/FoundationModels/GenerationSchema](https://developer.apple.com/documentation/FoundationModels/GenerationSchema) that you provide with your request. When you try to create a generation schema, it can throw an error if there are conflicting property names, undefined references, or duplicate types.

```swift
// Create the schema.
let schema = try GenerationSchema(root: menuSchema, dependencies: [])

// Pass the schema to the model to guide the output.
let response = try await session.respond(
    to: "The prompt you want to make.",
    schema: schema
)
```

The response you get is an instance of [doc://com.apple.foundationmodels/documentation/FoundationModels/GeneratedContent](https://developer.apple.com/documentation/FoundationModels/GeneratedContent). You can decode the outputs from schemas you define at runtime by calling [doc://com.apple.foundationmodels/documentation/FoundationModels/GeneratedContent/value(_:forProperty:)-3xsez](https://developer.apple.com/documentation/FoundationModels/GeneratedContent/value(_:forProperty:)-3xsez) for the property you want.

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation)*
--- END FILE ---

--- FILE: Guide-description-semantics--.md ---
# Guide(description:semantics:)

## Availability

- **iOS** 26.1+ (Beta)
- **iPadOS** 26.1+ (Beta)
- **Mac Catalyst** 26.1+ (Beta)
- **macOS** 26.1+ (Beta)
- **visionOS** 26.1+ (Beta)


---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/Guide(description:semantics:)](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/Guide(description:semantics:))*
--- END FILE ---

--- FILE: Guide-description-semantics----.md ---
# Guide(description:semantics:_:)

## Availability

- **iOS** 26.1+ (Beta)
- **iPadOS** 26.1+ (Beta)
- **Mac Catalyst** 26.1+ (Beta)
- **macOS** 26.1+ (Beta)
- **visionOS** 26.1+ (Beta)


---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/Guide(description:semantics:_:)](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/Guide(description:semantics:_:))*
--- END FILE ---

--- FILE: Foundation-Models.md ---
# Foundation Models

**Perform tasks with the on-device model that specializes in language understanding, structured output, and tool calling.**

## Availability

- **iOS** 26.0+
- **iPadOS** 26.0+
- **Mac Catalyst** 26.0+
- **macOS** 26.0+
- **visionOS** 26.0+


## Overview

The Foundation Models framework provides access to Apple’s on-device large language model that powers Apple Intelligence to help you perform intelligent tasks specific to your use case. The text-based on-device model identifies patterns that allow for generating new text that’s appropriate for the request you make, and it can make decisions to call code you write to perform specialized tasks.

![Image](foundation-models-hero)

Generate text content based on requests you make. The on-device model excels at a diverse range of text generation tasks, like summarization, entity extraction, text understanding, refinement, dialog for games, generating creative content, and more.

Generate entire Swift data structures with guided generation. With the `@Generable` macro, you can define custom data structures and the framework provides strong guarantees that the model generates instances of your type.

To expand what the on-device foundation model can do, use [doc://com.apple.foundationmodels/documentation/FoundationModels/Tool](https://developer.apple.com/documentation/FoundationModels/Tool) to create custom tools that the model can call to assist with handling your request. For example, the model can call a tool that searches a local or online database for information, or calls a service in your app.

To use the on-device language model, people need to turn on Apple Intelligence on their device. For a list of supported devices, see [https://www.apple.com/apple-intelligence/](https://www.apple.com/apple-intelligence/).

For more information about acceptable usage of the Foundation Models framework, see [https://developer.apple.com/apple-intelligence/acceptable-use-requirements-for-the-foundation-models-framework](https://developer.apple.com/apple-intelligence/acceptable-use-requirements-for-the-foundation-models-framework).


### Related videos


### Related Links

- doc://com.apple.documentation/videos/play/wwdc2025/286

- doc://com.apple.documentation/videos/play/wwdc2025/301

- doc://com.apple.documentation/videos/play/wwdc2025/259

## Topics

### Essentials

- [Generating content and performing tasks with Foundation Models](https://developer.apple.com/documentation/foundationmodels/generating-content-and-performing-tasks-with-foundation-models) — Enhance the experience in your app by prompting an on-device large language model.
- [Improving the safety of generative model output](https://developer.apple.com/documentation/foundationmodels/improving-the-safety-of-generative-model-output) — Create generative experiences that appropriately handle sensitive inputs and respect people.
- [Support languages and locales with Foundation Models](https://developer.apple.com/documentation/foundationmodels/support-languages-and-locales-with-foundation-models) — Generate content in the language people prefer when they interact with your app.
- [Adding intelligent app features with generative models](https://developer.apple.com/documentation/foundationmodels/adding-intelligent-app-features-with-generative-models) — Build robust apps with guided generation and tool calling by adopting the Foundation Models framework.
- [SystemLanguageModel](https://developer.apple.com/documentation/foundationmodels/systemlanguagemodel) — An on-device large language model capable of text generation tasks.
- [SystemLanguageModel.UseCase](https://developer.apple.com/documentation/foundationmodels/systemlanguagemodel/usecase) — A type that represents the use case for prompting.
### Prompting

- [LanguageModelSession](https://developer.apple.com/documentation/foundationmodels/languagemodelsession) — An object that represents a session that interacts with a language model.
- [Instructions](https://developer.apple.com/documentation/foundationmodels/instructions) — Details you provide that define the model’s intended behavior on prompts.
- [Prompt](https://developer.apple.com/documentation/foundationmodels/prompt) — A prompt from a person to the model.
- [Transcript](https://developer.apple.com/documentation/foundationmodels/transcript) — A transcript contains a linear history of [doc://com.apple.foundationmodels/documentation/FoundationModels/Transcript/Entry](https://developer.apple.com/documentation/FoundationModels/Transcript/Entry) entries.
- [GenerationOptions](https://developer.apple.com/documentation/foundationmodels/generationoptions) — Options that control how the model generates its response to a prompt.
### Guided generation

- [Generating Swift data structures with guided generation](https://developer.apple.com/documentation/foundationmodels/generating-swift-data-structures-with-guided-generation) — Create robust apps by describing output you want programmatically.
- [Generable](https://developer.apple.com/documentation/foundationmodels/generable) — A type that the model uses when responding to prompts.
### Tool calling

- [Expanding generation with tool calling](https://developer.apple.com/documentation/foundationmodels/expanding-generation-with-tool-calling) — Build tools that enable the model to perform tasks that are specific to your use case.
- [Generate dynamic game content with guided generation and tools](https://developer.apple.com/documentation/foundationmodels/generate-dynamic-game-content-with-guided-generation-and-tools) — Make gameplay more lively with AI generated dialog and encounters personalized to the player.
- [Tool](https://developer.apple.com/documentation/foundationmodels/tool) — A tool that a model can call to gather information at runtime or perform side effects.
### Feedback

- [LanguageModelFeedback](https://developer.apple.com/documentation/foundationmodels/languagemodelfeedback) — Feedback appropriate for logging or attaching to Feedback Assistant.
### Macros

- [Guide(description:semantics:)](https://developer.apple.com/documentation/foundationmodels/guide(description:semantics:))
- [Guide(description:semantics:_:)](https://developer.apple.com/documentation/foundationmodels/guide(description:semantics:_:))

### Related Resources

- [Meet the Foundation Models framework](https://developer.apple.com/videos/play/wwdc2025/286)
- [Deep dive into the Foundation Models framework](https://developer.apple.com/videos/play/wwdc2025/301)
- [Code-along: Bring on-device AI to your app using the Foundation Models framework](https://developer.apple.com/videos/play/wwdc2025/259)

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels)*
--- END FILE ---

--- FILE: Generating-content-and-performing-tasks-with-Foundation-Models.md ---
# Generating content and performing tasks with Foundation Models

**Enhance the experience in your app by prompting an on-device large language model.**


## Overview

The Foundation Models framework lets you tap into the on-device large models at the core of Apple Intelligence. You can enhance your app by using generative models to create content or perform tasks. The framework supports language understanding and generation based on model capabilities.

For design guidance, see Human Interface Guidelines > Technologies > [https://developer.apple.com/design/human-interface-guidelines/generative-ai](https://developer.apple.com/design/human-interface-guidelines/generative-ai).


## Understand model capabilities

When considering features for your app, it helps to know what the on-device language model can do. The on-device model supports text generation and understanding that you can use to:

The on-device language model may not be suitable for handling all requests, like:

The model can complete complex generative tasks when you use guided generation or tool calling. For more on handling complex tasks, or tasks that require extensive world-knowledge, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation) and [doc://com.apple.foundationmodels/documentation/FoundationModels/expanding-generation-with-tool-calling](https://developer.apple.com/documentation/FoundationModels/expanding-generation-with-tool-calling).


## Check for availability

Before you use the on-device model in your app, check that the model is available by creating an instance of [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel) with the [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/default](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/default) property.

Model availability depends on device factors like:

- The device must support Apple Intelligence.

- The device must have Apple Intelligence turned on in Settings.


> **NOTE**: It can take some time for the model to download and become available when a person turns on Apple Intelligence.


Always verify model availability first, and plan for a fallback experience in case the model is unavailable.

```swift
struct GenerativeView: View {
    // Create a reference to the system language model.
    private var model = SystemLanguageModel.default

    var body: some View {
        switch model.availability {
        case .available:
            // Show your intelligence UI.
        case .unavailable(.deviceNotEligible):
            // Show an alternative UI.
        case .unavailable(.appleIntelligenceNotEnabled):
            // Ask the person to turn on Apple Intelligence.
        case .unavailable(.modelNotReady):
            // The model isn't ready because it's downloading or because of other system reasons.
        case .unavailable(let other):
            // The model is unavailable for an unknown reason.
        }
    }
}
```


## Create a session

After confirming that the model is available, create a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession) object to call the model. For a single-turn interaction, create a new session each time you call the model:

```swift
// Create a session with the system model.
let session = LanguageModelSession()
```

For a multiturn interaction — where the model retains some knowledge of what it produced — reuse the same session each time you call the model.


## Provide a prompt to the model

A [doc://com.apple.foundationmodels/documentation/FoundationModels/Prompt](https://developer.apple.com/documentation/FoundationModels/Prompt) is an input that the model responds to. Prompt engineering is the art of designing high-quality prompts so that the model generates a best possible response for the request you make. A prompt can be as short as “hello”, or as long as multiple paragraphs. The process of designing a prompt involves a lot of exploration to discover the best prompt, and involves optimizing prompt length and writing style.

When thinking about the prompt you want to use in your app, consider using conversational language in the form of a question or command. For example, “What’s a good month to visit Paris?” or “Generate a food truck menu.”

Write prompts that focus on a single and specific task, like “Write a profile for the dog breed Siberian Husky”. When a prompt is long and complicated, the model takes longer to respond, and may respond in unpredictable ways. If you have a complex generation task in mind, break the task down into a series of specific prompts.

You can refine your prompt by telling the model exactly how much content it should generate. A prompt like, “Write a profile for the dog breed Siberian Husky” often takes a long time to process as the model generates a full multi-paragraph essay. If you specify “using three sentences”, it speeds up processing and generates a concise summary. Use phrases like “in a single sentence” or “in a few words” to shorten the generation time and produce shorter text.

```swift
// Generate a longer response for a specific command.
let simple = "Write me a story about pears."

// Quickly generate a concise response.
let quick = "Write the profile for the dog breed Siberian Husky using three sentences."
```


## Provide instructions to the model

[doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) help steer the model in a way that fits the use case of your app. The model obeys prompts at a lower priority than the instructions you provide. When you provide instructions to the model, consider specifying details like:

- What the model’s role is; for example, “You are a mentor,” or “You are a movie critic”.

- What the model should do, like “Help the person extract calendar events,” or “Help the person by recommending search suggestions”.

- What the style preferences are, like “Respond as briefly as possible”.

- What the possible safety measures are, like “Respond with ‘I can’t help with that’ if you’re asked to do something dangerous”.

Use content you trust in instructions because the model follows them more closely than the prompt itself. When you initialize a session with instructions, it affects all prompts the model responds to in that session. Instructions can also include example responses to help steer the model. When you add examples to your prompt, you provide the model with a template that shows the model what a good response looks like.


## Generate a response

To call the model with a prompt, call [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/respond(to:options:)-b2re](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/respond(to:options:)-b2re) on your session. The response call is asynchronous because it may take a few seconds for the on-device foundation model to generate the response.

```swift
let instructions = """
    Suggest five related topics. Keep them concise (three to seven words) and make sure they \
    build naturally from the person's topic.
    """

let session = LanguageModelSession(instructions: instructions)

let prompt = "Making homemade bread"
let response = try await session.respond(to: prompt)
```


> **NOTE**: A session can only handle a single request at a time, and causes a runtime error if you call it again before the previous request finishes. Check [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/isResponding](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/isResponding) to verify the session is done processing the previous request before sending a new one.


Instead of working with raw string output from the model, the framework offers guided generation to generate a custom Swift data structure you define. For more information about guided generation, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation).

When you make a request to the model, you can provide custom tools to help the model complete the request. If the model determines that a [doc://com.apple.foundationmodels/documentation/FoundationModels/Tool](https://developer.apple.com/documentation/FoundationModels/Tool) can assist with the request, the framework calls your [doc://com.apple.foundationmodels/documentation/FoundationModels/Tool](https://developer.apple.com/documentation/FoundationModels/Tool) to perform additional actions like retrieving content from your local database. For more information about tool calling, see [doc://com.apple.foundationmodels/documentation/FoundationModels/expanding-generation-with-tool-calling](https://developer.apple.com/documentation/FoundationModels/expanding-generation-with-tool-calling)


## Consider context size limits per session

The *context window size* is a limit on how much data the model can process for a session instance. A token is a chunk of text the model processes, and the system model supports up to 4,096 tokens. A single token corresponds to three or four characters in languages like English, Spanish, or German, and one token per character in languages like Japanese, Chinese, or Korean. In a single session, the sum of all tokens in the instructions, all prompts, and all outputs count toward the context window size.

If your session processes a large amount of tokens that exceed the context window, the framework throws the error [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)). When you encounter the error, start a new session and try shortening your prompts. If you need to process a large amount of data that won’t fit in a single context window limit, break your data into smaller chunks, process each chunk in a separate session, and then combine the results.


## Tune generation options and optimize performance

To get the best results for your prompt, experiment with different generation options. [doc://com.apple.foundationmodels/documentation/FoundationModels/GenerationOptions](https://developer.apple.com/documentation/FoundationModels/GenerationOptions) affects the runtime parameters of the model, and you can customize them for every request you make.

```swift
// Customize the temperature to increase creativity.
let options = GenerationOptions(temperature: 2.0)

let session = LanguageModelSession()

let prompt = "Write me a story about coffee."
let response = try await session.respond(
    to: prompt,
    options: options
)
```

When you test apps that use the framework, use Xcode Instruments to understand more about the requests you make, like the time it takes to perform a request. When you make a request, you can access the [doc://com.apple.foundationmodels/documentation/FoundationModels/Transcript](https://developer.apple.com/documentation/FoundationModels/Transcript) entries that describe the actions the model takes during your [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession).

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models)*
--- END FILE ---

--- FILE: Meet_the_Foundation_Models_framework.md ---
# Meet the Foundation Models framework

Hi, I’m Erik. And I’m Yifei. And today, we are so excited to get the privilege of introducing you to the new Foundation Models framework! The Foundation Models framework gives you access to the on-device Large Language Model that powers Apple Intelligence, with a convenient and powerful Swift API. It is available on macOS, iOS, iPadOS, and visionOS! You can use it to enhance existing features in your apps, like providing personalized search suggestions. Or you can create completely new features, like generating an itinerary in a travel app, all on-device. You can even use it to create dialog on-the-fly for characters in a game.

It is optimized for generating content, summarizing text, analyzing user input and so much more.

All of this runs on-device, so all data going into and out of the model stays private. That also means it can run offline! And it’s built into the operating system, so it won’t increase your app size. It’s a huge year, so to help you get the most out of the FoundationModels framework, we’ve prepared a series of videos. In this first video, we’ll be giving you a high level overview of the framework in its entirety. Starting with the details of the model.

We will then introduce guided generation which allows you to get structured output in Swift, and the powerful streaming APIs that turn latency into delight.

We will also talk about tool calling, which allows the model to autonomously execute code you define in your app.

Finally, we will finish up with how we provide multi-turn support with stateful sessions, and how we seamlessly integrate the framework into the Apple developer ecosystem. The most important part of the framework, of course, is the model that powers it. And the best way to get started with prompting the model, is to jump into Xcode.

Testing out a variety of prompts to find what works best is an important part of building with large language models, and the new Playgrounds feature in Xcode is the best way to do that. With just a few lines of code, you can immediately start prompting the on-device model. Here I'll ask it to generate a title for a trip to Japan, and the model's output will appear in the canvas on the right. 

```swift
import FoundationModels
import Playgrounds

#Playground {
    let session = LanguageModelSession()
    let response = try await session.respond(to: "What's a good name for a trip to Japan? Respond only with a title")
}
```

Now, I want to see if this prompt works well for other destinations too. In a #Playground, you can access types defined in your app, so I'll create a for loop over the landmarks featured in mine. Now Xcode will show me the model's response for all of the landmarks.

```swift
import FoundationModels
import Playgrounds

#Playground {
    let session = LanguageModelSession()
    for landmark in ModelData.shared.landmarks {
        let response = try await session.respond(to: "What's a good name for a trip to \(landmark.name)? Respond only with a title")
    }
}
```

The on-device model we just used is a large language model with 3 billion parameters, each quantized to 2 bits. It is several orders of magnitude bigger than any other models that are part of the operating system.

But even so, it’s important to keep in mind that the on-device model is a device-scale model. It is optimized for use cases like summarization, extraction, classification, and many more. It’s not designed for world knowledge or advanced reasoning, which are tasks you might typically use server-scale LLMs for.

Device scale models require tasks to be broken down into smaller pieces. As you work with the model, you’ll develop an intuition for its strengths and weaknesses.

For certain common use cases, such as content tagging, we also provide specialized adapters that maximize the model’s capability in specific domains.

We will also continue to improve our models over time. Later in this video we’ll talk about how you can tell us how you use our models, which will help us to improve them in ways that matter to you.

Now that we've taken a look at the model, the first stop on our journey is Guided Generation. Guided Generation is what makes it possible to build features like the ones you just saw, and it is the beating heart of the FoundationModels framework. Let's take a look at a common problem and talk about how Guided Generation solves it.

By default, language models produce unstructured, natural language as output. It's easy for humans to read, but difficult to map onto views in your app.

A common solution is to prompt the model to produce something that's easy to parse, like JSON or CSV.

However, that quickly turns into a game of whack-a-mole. You have to add increasingly specific instructions about what it it is and isn't supposed to do… Often that doesn't quite work… So you end up writing hacks to extract and patch the content. This isn't reliable because the model is probabilistic and there is a non-zero chance of structural mistakes. Guided Generation offers a fundamental solution to this problem.

When you import FoundationModels, you get access to two new macros, @Generable and @Guide. Generable let's you describe a type that you want the model to generate an instance of.

```swift
// Creating a Generable struct

@Generable
struct SearchSuggestions {
    @Guide(description: "A list of suggested search terms", .count(4))
    var searchTerms: [String]
}
```

Additionally, Guides let you provide natural language descriptions of properties, and programmatically control the values that can be generated for those properties.

Once you've defined a Generable type, you can make the model respond to prompts by generating an instance of your type. This is really powerful.

```swift
// Responding with a Generable type

let prompt = """
    Generate a list of suggested search terms for an app about visiting famous landmarks.
    """

let response = try await session.respond(
    to: prompt,
    generating: SearchSuggestions.self
)

print(response.content)
```

Observe how our prompt no longer needs to specify the output format. The framework takes care of that for you.

The most important part, of course, is that we now get back a rich Swift object that we can easily map onto an engaging view.

Generable types can be constructed using primitives, like Strings, Integers, Doubles, Floats, and Decimals, and Booleans. Arrays are also generable. And Generable types can be composed as well. Generable even supports recursive types, which have powerful applications in domains like generative UIs.

```swift
// Composing Generable types

@Generable struct Itinerary {
    var destination: String
    var days: Int
    var budget: Float
    var rating: Double
    var requiresVisa: Bool
    var activities: [String]
    var emergencyContact: Person
    var relatedItineraries: [Itinerary]
}
```

The most important thing to understand about Guided Generation is that it fundamentally guarantees structural correctness using a technique called constrained decoding.

When using Guided Generation, your prompts can be simpler and focused on desired behavior instead of the format.

Additionally, Guided Generation tends to improve model accuracy. And, it allows us to perform optimizations that speed up inference at the same time. This is all made possible by carefully coordinated integration of Apple operating systems, developer tools, and the training of our foundation models. There is still a lot more to cover about guided generation, like how to create dynamic schemas at runtime, so please check out our deep dive video for more details. So that wraps up Guided Generation — we’ve seen how Swift’s powerful type system augments natural language prompts to enable reliable structured output. Our next topic is streaming, and it all builds on top of the @Generable macro you’re already familiar with.

If you’ve worked with large language models before, you may be aware that they generate text as short groups of characters called tokens.

Typically when streaming output, tokens are delivered in what’s called a delta, but the FoundationModels framework actually takes a different approach, and I want to show you why.

As deltas are produced, the responsibility for accumulating them usually falls on the developer.

You append each delta as they come in. And the response grows as you do.

But it gets tricky when the result has structure. If you want to show the greeting string after each delta, you have to parse it out of the accumulation, and that’s not trivial, especially for complicated structures. Delta streaming just isn’t the right formula when working with structured output.

And as you’ve learned, structured output is at the very core of the FoundationModels framework, which is why we’ve developed a different approach. Instead of raw deltas, we stream snapshots.

As the model produces deltas, the framework transforms them into snapshots. Snapshots represent partially generated responses. Their properties are all optional. And they get filled in as the model produces more of the response.

Snapshots are a robust and convenient representation for streaming structured output.

You're already familiar with the @Generable macro, and as it turns out, it's also where the definitions for partially generated types come from. If you expand the macro, you'll discover it produces a type named `PartiallyGenerated`. It is effectively a mirror of the outer structure, except every property is optional.

```swift
// PartiallyGenerated types

@Generable struct Itinerary {
    var name: String
    var days: [Day]
}
```

The partially generated type comes into play when you call the `streamResponse` method on your session.

```swift
// Streaming partial generations

let stream = session.streamResponse(
    to: "Craft a 3-day itinerary to Mt. Fuji.",
    generating: Itinerary.self
)

for try await partial in stream {
    print(partial)
}
```

Stream response returns an async sequence. And the elements of that sequence are instances of a partially generated type. Each element in the sequence will contain an updated snapshot.

These snapshots work great with declarative frameworks like SwiftUI. First, create state holding a partially generated type.

Then, just iterate over a response stream, store its elements, and watch as your UI comes to life.

```swift
ItineraryView: View {
    let session: LanguageModelSession
    let dayCount: Int
    let landmarkName: String
  
    @State
    private var itinerary: Itinerary.PartiallyGenerated?
  
    var body: some View {
        //...
        Button("Start") {
            Task {
                do {
                    let prompt = """
                        Generate a \(dayCount) itinerary \
                        to \(landmarkName).
                        """
                  
                    let stream = session.streamResponse(
                        to: prompt,
                        generating: Itinerary.self
                    )
                  
                    for try await partial in stream {
                        self.itinerary = partial
                    }
                } catch {
                    print(error)  
                }
            }
        }
    }
}
```

To wrap up, let's review some best practices for streaming.

First, get creative with SwiftUI animations and transitions to hide latency. You have an opportunity turn a moment of waiting into one of delight. Second, you'll need to think carefully about view identity in SwiftUI, especially when generating arrays. Finally, bear in mind that properties are generated in the order they are declared on your Swift struct. This matters both for animations and for the quality of the model's output. For example, you may find that the model produces the best summaries when they're the last property in the struct.

```swift
@Generable struct Itinerary {
  
  @Guide(description: "Plans for each day")
  var days: [DayPlan]
  
  @Guide(description: "A brief summary of plans")
  var summary: String
}
```

There is a lot to unpack here, so make sure to check out our video on integrating Foundation Models into your app for more details. So that wraps up streaming with Foundation Models. Next up, Yifei is going to teach you all about tool calling! Thanks Erik! Tool calling is another one of our key features. It lets the model execute code you define in your app. This feature is especially important for getting the most out of our model, since tool calling gives the model many additional capabilities. It allows the model to identify that a task may require additional information or actions and autonomously make decisions about what tool to use and when, when it’s difficult to decide programmatically.

The information you provide to the model can be world knowledge, recent events, or personal data. For example, in our travel app, it provides information about various locations from MapKit. This also gives the model the ability to cite sources of truth, which can suppress hallucinations and allow fact-checking the model output.

Finally, it allows the model to take actions, whether it’s in your app, on the system, or in the real world.

Integrating with various sources of information in your app is a winning strategy for building compelling experiences. Now that you know why tool calling is very useful, let’s take a look at how it works.

On the left we have a transcript which records everything that has happened so far. If you’ve provided tools to the session, the session will present these tools to the model along with the instructions. Next comes the prompt, where we tell the model which destination we want to visit.

Now, if the model deems that calling a tool can enhance the response, it will produce one or more tool calls. In this example, the model produces two tool calls — querying restaurants and hotels.

At this phase, the FoundationModels framework will automatically call the code you wrote for these tools. The framework then automatically inserts the tool outputs back into the transcript. Finally, the model will incorporate the tool output along with everything else in the transcript to furnish the final response.

Now that we have a high level understanding of tool calling, let's define a tool.

Here we're defining a simple weather tool, which conforms to the Tool protocol. The weather tool has kind of emerged as the de-facto 'hello world' of tool calling, and it's a great way to get started.

The protocol first requires you to specify a name and a natural language description of the tool.

The framework will automatically provide them for the model to help it understand when to call your tool.

When the model calls your tool, it will run the call method you define.

The argument to the call method can be any Generable type.

The reason your arguments need to be generable is because tool calling is built on guided generation to ensure that the model will never produce invalid tool names or arguments.

After defining your arguments type, you can now write anything you want in the body of your method. Here we're using CoreLocation and WeatherKit to find the temperature of a given city. The output is represented using the ToolOutput type, which can be created from GeneratedContent to represent structured data. Or from a string if your tool's output is natural language. 

```swift
// Defining a tool
import WeatherKit
import CoreLocation
import FoundationModels

struct GetWeatherTool: Tool {
    let name = "getWeather"
    let description = "Retrieve the latest weather information for a city"

    @Generable
    struct Arguments {
        @Guide(description: "The city to fetch the weather for")
        var city: String
    }

    func call(arguments: Arguments) async throws -> ToolOutput {
        let places = try await CLGeocoder().geocodeAddressString(arguments.city)
        let weather = try await WeatherService.shared.weather(for: places.first!.location!)
        let temperature = weather.currentWeather.temperature.value

        let content = GeneratedContent(properties: ["temperature": temperature])
        let output = ToolOutput(content)

        // Or if your tool's output is natural language:
        // let output = ToolOutput("\(arguments.city)'s temperature is \(temperature) degrees.")

        return output
    }
}
```

Now that we have defined a tool, we have to ensure that the model has access to it.

To do so, pass your tool into your session's initializer. Tools must be attached at session initialization, and will be available to the model for the session's lifetime.

```swift
// Attaching tools to a session

let session = LanguageModelSession(
    tools: [GetWeatherTool()],
    instructions: "Help the user with weather forecasts."
)

let response = try await session.respond(
    to: "What is the temperature in Cupertino?"
)

print(response.content)
// It's 71˚F in Cupertino!
```

After creating a session with tools, all you need to do is prompt the model as you would normally. Tool calls will happen transparently and autonomously, and the model will incorporate the tools' outputs into its final response. The examples I’ve shown here demonstrate how to define type-safe tools at compile time, which is great for the vast majority of use cases. But tools can also be dynamic in every way! For example, you can define the arguments and behaviors of a tool at runtime by using dynamic generation schemas. If you are curious about that, feel free to check out our deep dive video to learn more.

That wraps up tool calling. We learned why tool calling is useful and how to implement tools to extend the model's capabilities. Next, let's talk about stateful sessions. You've seen the word session pop up in this video many times already. The Foundation Models framework is built around the notion of a stateful session. By default, when you create a session, you will be prompting the on-device general-purpose model. And you can provide custom instructions.

Instructions are an opportunity for you to tell the model its role and provide guidance on how the model should respond. For example, you can specify things like style and verbosity.

```swift
// Supplying custom instructions

let session = LanguageModelSession(
    instructions: """
        You are a helpful assistant who always \
        responds in rhyme.
        """
)
```

Note that providing custom instructions is optional, and reasonable default instructions will be used if you don't specify any.

If you do choose to provide custom instructions, it is important to understand the difference between instructions and prompts. Instructions should come from you, the developer, while prompts can come from the user. This is because the model is trained to obey instructions over prompts. This helps protect against prompt injection attacks, but is by no means bullet proof.

As a general rule, instructions are mostly static, and it’s best not to interpolate untrusted user input into the instructions.

So this is a basic primer on how to best form your instructions and prompts. To discover even more best practices, check out our video on prompt design and safety.

Now that you have initialized a session, let's talk about multi-turn interactions! When using the respond or streamResponse methods we talked about earlier. Each interaction with the model is retained as context in a transcript, so the model will be able to refer to and understand past multi-turn interactions within a single session. For example, here the model is able to understand when we say "do another one", that we're referring back to writing a haiku.

```swift
// Multi-turn interactions

let session = LanguageModelSession()

let firstHaiku = try await session.respond(to: "Write a haiku about fishing")
print(firstHaiku.content)
// Silent waters gleam,
// Casting lines in morning mist—
// Hope in every cast.

let secondHaiku = try await session.respond(to: "Do another one about golf")
print(secondHaiku.content)
// Silent morning dew,
// Caddies guide with gentle words—
// Paths of patience tread.

print(session.transcript)// (Prompt) Write a haiku about fishing
// (Response) Silent waters gleam...
// (Prompt) Do another one about golf
// (Response) Silent morning dew...
```

And the `transcript` property on the session object will allow you to inspect previous interactions or draw UI views to represent them.

One more important thing to know is that while the model is producing output, its `isResponding` property will become `true`. You may need to observe this property and make sure not to submit another prompt until the model finishes responding.

```swift
import SwiftUI
import FoundationModels

struct HaikuView: View {

    @State
    private var session = LanguageModelSession()

    @State
    private var haiku: String?

    var body: some View {
        if let haiku {
            Text(haiku)
        }
        Button("Go!") {
            Task {
                haiku = try await session.respond(
                    to: "Write a haiku about something you haven't yet"
                ).content
            }
        }
        // Gate on `isResponding`
        .disabled(session.isResponding)
    }
}
```

Beyond the default model, we are also providing additional built-in specialized use cases that are backed by adapters.

If you find a built-in use case that fits your need, you can pass it to SystemLanguageModel's initializer. 

```swift
// Using a built-in use case

let session = LanguageModelSession(
    model: SystemLanguageModel(useCase: .contentTagging)
)
```

To understand what built-in use cases are available and how to best utilize them, check out our documentation on the developer website. One specialized adapter I want to talk more about today is the content tagging adapter. The content tagging adapter provides first class support for tag generation, entity extraction, and topic detection. By default, the adapter is trained to output topic tags, and it integrates with guided generation out of the box. So you can simply define a struct with our Generable macro, and pass the user input to extract topics from it.

```swift
// Content tagging use case

@Generable
struct Result {
    let topics: [String]
}

let session = LanguageModelSession(model: SystemLanguageModel(useCase: .contentTagging))
let response = try await session.respond(to: ..., generating: Result.self)
```

But there's more! By providing it with custom instructions and a custom Generable output type, you can even use it to detect things like actions and emotions.

```swift
// Content tagging use case

@Generable
struct Top3ActionEmotionResult {
    @Guide(.maximumCount(3))
    let actions: [String]
    @Guide(.maximumCount(3))
    let emotions: [String]
}

let session = LanguageModelSession(
    model: SystemLanguageModel(useCase: .contentTagging),
    instructions: "Tag the 3 most important actions and emotions in the given input text."
)
let response = try await session.respond(to: ..., generating: Top3ActionEmotionResult.self)
```

Before you create a session, you should also check for availability, since the model can only run on Apple Intelligence-enabled devices in supported regions. To check if the model is currently available, you can access the availability property on the SystemLanguageModel.

Availability is a two case enum that's either available or unavailable. If it's unavailable, you also receive a reason so you can adjust your UI accordingly.

```swift
// Availability checking

struct AvailabilityExample: View {
    private let model = SystemLanguageModel.default

    var body: some View {
        switch model.availability {
        case .available:
            Text("Model is available").foregroundStyle(.green)
        case .unavailable(let reason):
            Text("Model is unavailable").foregroundStyle(.red)
            Text("Reason: \(reason)")
        }
    }
}
```

Lastly, you could encounter errors when you are calling into the model.

These errors might include guardrail violation, unsupported language, or context window exceeded. To provide the best user experience, you should handle them appropriately, and the deep-dive video will teach you more about them. That’s it for multi-turn stateful sessions! We learned how to create a session and use it, as well as how our model keeps track of your context. Now that you’ve seen all the cool features of the framework, let’s talk about developer tooling and experience. To start, you can go to any Swift file in your project and use the new playground macro to prompt the model.

Playgrounds are powerful because they let you quickly iterate on your prompts without having to rebuild and rerun your entire app.

In a playground, your code can access all the types in your project, such as the generable types that are already powering your UI.

Next, we know that when it comes to building app experiences powered by large language models, it is important to understand all the latency under the hood, because large language models take longer to run compared to traditional ML models. Understanding where latency goes can help you tweak the verbosity of your prompts, or determine when to call useful APIs such as prewarming.

And our new Instruments app profiling template is built exactly for that. You can profile the latency of a model request, observe areas of optimizations, and quantify improvements.

Now, as you develop your app, you may have feedback that can help us improve our models and our APIs.

We encourage you to provide your feedback through Feedback Assistant. We even provide an encodable feedback attachment data structure that you can attach as a file to your feedback.

```swift
let feedback = LanguageModelFeedbackAttachment(
  input: [
    // ...
  ],
  output: [
    // ...
  ],
  sentiment: .negative,
  issues: [
    LanguageModelFeedbackAttachment.Issue(
      category: .incorrect,
      explanation: "..."
    )
  ],
  desiredOutputExamples: [
    [
      // ...
    ]
  ]
)
let data = try JSONEncoder().encode(feedback)
```

Finally, if you are an ML practitioner with a highly specialized use case and a custom dataset, you can also train your custom adapters using our adapter training toolkit. But bear in mind, this comes with significant responsibilities because you need to retrain it as Apple improves the model over time. To learn more, you can visit the developer website. 

Now that you've learned many of the cool features provided by the new Foundation Models framework, we can't wait to see all the amazing things you build with it! To discover even more about how you can integrate generative AI into your app, how technologies like guided generation work under the hood, and how you can create the best prompts, we have a whole series of wonderful videos and articles for you.

Thank you so much for joining us today! Happy generating!
--- END FILE ---

--- FILE: Deep_dive_into_Foundation_Models_Framework.md ---
Hi, I’m Louis. Today we’ll look at getting the most out of the Foundation Models framework.

As you may know, the Foundation Models framework gives you direct access to an on-device Large Language Model, with a convenient Swift API. It’s available on macOS, iPadOS, iOS, and visionOS. And because it runs on-device, using it in your project is just a simple import away. In this video, we will look at how sessions work with Foundation Models. How to use Generable to get structured output. How to get structured output with dynamic schemas defined at runtime, and using tool calling to let the model call into your custom functions.

Let’s start simple, by generating text with a session.

Now, I've been working on this pixel art game about a coffee shop, and I think it could be really fun to use Foundation Models to generate game dialog and other content to make it feel more alive! We can prompt the model to respond to a player's question, so our barista gives a unique dialog.

To do this, we'll create a LanguageModelSession with custom instructions. This let's us tell the model what its purpose is for this session and for the prompt we'll take the user's input. And that's really all it takes for a pretty fun new game element. Let's ask the Barista "How long have you worked here?", and let it respond to our question.

```swift
import FoundationModels

func respond(userInput: String) async throws -> String {
  let session = LanguageModelSession(instructions: """
    You are a friendly barista in a world full of pixels.
    Respond to the player's question.
    """
  )
  let response = try await session.respond(to: userInput)
  return response.content
}
```

That was generated entirely on-device. Pretty amazing. But how does this actually work? Let’s get a better sense of how Foundation Models generates text, and what to look out for. When you call respond(to:) on a session, it first takes your session’s instructions, and the prompt, in this case the user’s input, and it turns that text into tokens. Tokens are small substrings, sometimes a word but typically just a few characters. A large language model takes a sequence of tokens as input, and it then generates a new sequence of tokens as output. You don’t have to worry about the exact tokens that Foundation Models operates with, the API nicely abstracts that away for you. But it is important to understand that tokens are not free. Each token in your instructions and prompt adds extra latency. Before the model can start producing response tokens, it first needs to process all the input tokens. And generating tokens also has a computational cost, which is why longer outputs take longer to generate.

A LanguageModelSession is stateful. Each respond(to:) call is recorded in the transcript.

The transcript includes all prompts and responses for a given session.

This can be useful for debugging, or even showing it in your UI.

But a session has a limit for how large it can grow.

If you’re making a lot of requests, or if you’re giving a large prompt or getting large outputs, you can hit the context limit.

If your session exceeds the available context size, it will throw an error, which you should be prepared to catch.

Back in our game, when we're talking with a character and hit an error, the conversation just ends, which is unfortunate, I was just getting to know this character! Luckily there are ways to recover from this error.

You can catch the exceededContextWindowSize error.

```swift
var session = LanguageModelSession()

do {
  let answer = try await session.respond(to: prompt)
  print(answer.content)
} catch LanguageModelSession.GenerationError.exceededContextWindowSize {
  // New session, without any history from the previous session.
  session = LanguageModelSession()
}
```

And when you do, you can start a brand new session, without any history. But in my game that would mean the character suddenly forgets the whole conversation.

You can also choose some of the transcript from your current session to carry over into the new session.

You can take the entries from a session's transcript, and condense it into a new array of entries.

So for our game dialog, we could take the first entry of the session's transcript, which is the instructions. As well as the last entry, which is the last successful response.

```swift
var session = LanguageModelSession()

do {
  let answer = try await session.respond(to: prompt)
  print(answer.content)
} catch LanguageModelSession.GenerationError.exceededContextWindowSize {
  // New session, with some history from the previous session.
  session = newSession(previousSession: session)
}

private func newSession(previousSession: LanguageModelSession) -> LanguageModelSession {
  let allEntries = previousSession.transcript.entries
  var condensedEntries = [Transcript.Entry]()
  if let firstEntry = allEntries.first {
    condensedEntries.append(firstEntry)
    if allEntries.count > 1, let lastEntry = allEntries.last {
      condensedEntries.append(lastEntry)
    }
  }
  let condensedTranscript = Transcript(entries: condensedEntries)
  // Note: transcript includes instructions.
  return LanguageModelSession(transcript: condensedTranscript)
}
```

And when we pass that into a new session, our character is good to chat with for another while.

But keep in mind, the session's transcript includes the initial instructions as the first entry. When carrying over a transcript for our game character, we definitely want to include those instructions.

Including just a few relevant pieces from the transcript can be a simple, and effective, solution. But sometimes it’s not that simple.

Let’s imagine a transcript with more entries.

You definitely always want to start by carrying over the instructions. But a lot of entries in the transcript might be relevant, so for this use case you could consider summarizing the transcript.

You could do this with some external library, or perhaps even summarize parts of the transcript with Foundation Models itself.

So that’s what you can do with the transcript of a session.

Now let’s take a brief look at how the responses are actually generated.

In our game, when you walk up to the barista, the player can ask any question.

But if you start two new games, and ask the exact same question in each, you will probably get different output. So how does that work? Well that’s where sampling comes in.

When the model is generating its output, it does so one token at a time. And it does this by creating a distribution, for the likelihood of any given token By default, Foundation Models will pick tokens within some probability range. Sometimes it might start by saying "Ah", and other times it might pick "Well" for the first token. This happens for every token that's generated. Picking a token is what we call sampling. And the default behavior is random sampling. Getting varied output is great for use cases like a game. But sometimes you might want deterministic output, like when you're writing a demo that should be repeatable. The GenerationOptions API let's you control the sampling method. You can set it to greedy to get deterministic output. And when that's set, you will get the same output for the same prompt, assuming your session is also in the same state. Although note, this only holds true for a given version of the on-device model. When the model is updated as part of an OS update, your prompt can definitely give different output, even when using greedy sampling.

```swift
// Deterministic output
let response = try await session.respond(
  to: prompt,
  options: GenerationOptions(sampling: .greedy)
)
                
// Low-variance output
let response = try await session.respond(
  to: prompt,
  options: GenerationOptions(temperature: 0.5)
)
                
// High-variance output
let response = try await session.respond(
  to: prompt,
  options: GenerationOptions(temperature: 2.0)
)
```

You can also play with the temperature for the random sampling. For example, setting the temperature to 0.5 to get output that only varies a little. Or setting it to a higher value to get wildly different output for the same prompt.

Also, keep in mind, when taking user input in your prompt, the language might not be supported.

There is the dedicated unsupportedLanguageOrLocale error that you can catch for this case.

This can be a good way to show a custom message in your UI.

```swift
var session = LanguageModelSession()

do {
  let answer = try await session.respond(to: userInput)
  print(answer.content)
} catch LanguageModelSession.GenerationError.unsupportedLanguageOrLocale {
  // Unsupported language in prompt.
}

let supportedLanguages = SystemLanguageModel.default.supportedLanguages
guard supportedLanguages.contains(Locale.current.language) else {
  // Show message
  return
}
```

And there's also an API to check whether the model supports a certain language. For example to checkout if the user's current language is supported, and to show a disclaimer when it's not. So that's an overview of sessions. You can prompt it, which will store the history in the transcript. And you can optionally set the sampling parameter, to control the randomness of the session’s output. But let’s get fancier! When the player walks around, we can generate NPCs, Non Playable Characters, again using Foundation Models. However, this time, we want more complicated output. Instead of just plain text, we’d like a name and a coffee order from the NPC. Generable can help us here.

It can be a challenge to get structured output from a Large Language Model. You could prompt it with the specific fields you expect, and have some parsing code to extract that. But this is hard to maintain, and very fragile, it might not always give the valid keys, which would make the whole method fail.

Luckily, Foundation Models has a much better API, called Generable.

On your struct, you can apply the @Generable macro. So, what is Generable and is that even a word? Well, yes, it is.

```swift
@Generable
struct NPC {
  let name: String
  let coffeeOrder: String
}
```

Generable is an easy way to let the model generate structured data, using Swift types The macro generates a schema at compile time, which the model can use to produce the expected structure.

The macro also generates an initializer, which is automatically called for you when making a request to a session.

So then we can generate instances of our struct. Like before, we'll call the respond method on our session. But this time pass the generating argument telling the model which type to generate.

```swift
@Generable
struct NPC {
  let name: String
  let coffeeOrder: String
}

func makeNPC() async throws -> NPC {
  let session = LanguageModelSession(instructions: ...)
  let response = try await session.respond(generating: NPC.self) {
    "Generate a character that orders a coffee."
  }
  return response.content
}
```

Foundation Models will even automatically include details about your Generable type in the prompt, in a specific format that the model has been trained on. You don't have to tell it about what fields your Generable type has In our game, we'll now get some great generated NPC encounters! Generable is actually more powerful than it might seem. At a low level, this uses constrained decoding, which is a technique to let the model generate text that follows a specific schema.

Remember, that schema that the macro generates.

As we saw before, an LLM generates tokens, which are later transformed into text. And with Generable, that text is even automatically parsed for you in a type-safe way. The tokens are generated in a loop, often referred to as the decoding loop.

Without constrained decoding, the model might hallucinate some invalid field name.

Like `firstName`instead of a name. Which would then fail to be parsed into the NPC type.

But with constrained decoding, the model is prevented from making structural mistakes like this. For every token that’s generated, there’s a distribution of all the tokens in the model’s vocabulary.

And constrained decoding works by masking out the tokens that are not valid. So instead of just picking any token, the model is only allowed to pick valid tokens according to the schema.

And that's all without needing to worry about manually parsing the model's output. Which means you can spend your time on what truly matters, like talking to virtual guests in your coffee shop! Generable is truly the best way to get output from the on-device LLM. And it can do so much more. Not only can you use it on structs, but also on enums! So let's use that to make our encounters more dynamic! Here, I've added an Encounter enum, with two cases. The enum can even contain associated values in its cases, so let's use that to either generate a coffee order, or, to have someone that wants to speak to the manager.

```swift
@Generable
struct NPC {
  let name: String
  let encounter: Encounter

  @Generable
  enum Encounter {
    case orderCoffee(String)
    case wantToTalkToManager(complaint: String)
  }
}
```

Let's checkout what we encounter in our game now! Wow, someone really needs a coffee.

Clearly, not every guest is as easy to deal with, so let's level this up by adding levels to our NPCs.

Generable supports most common Swift types out of the box, including Int. So let's add a level property. But we don't want to generate any integer. If we want the level to be in a specific range, we can specify this using a Guide. We can use the Guide macro on our property, and pass a range.

Again, the model will use constrained decoding, to guarantee a value in this range.

While we're at it, let's also add an array of attributes to our NPC.

```swift
@Generable
struct NPC {
  @Guide(description: "A full name")
  let name: String
  @Guide(.range(1...10))
  let level: Int
  @Guide(.count(3))
  let attributes: [Attribute]
  let encounter: Encounter

  @Generable
  enum Attribute {
    case sassy
    case tired
    case hungry
  }
  @Generable
  enum Encounter {
    case orderCoffee(String)
    case wantToTalkToManager(complaint: String)
  }
}
```

We can again use a guide, this time to specify we want exactly three attributes for this array in our NPC. Keep in mind, the properties of your Generable type are generated in the order they are declared in the source code. Here, name will be generated first, followed by the level, then the attributes, and encounter last.

This order can be important, if you’re expecting the value of a property to be influenced by another property.

And you can even stream property-by-property, if you don’t want to wait until the full output is generated. The game is pretty fun now! Almost ready to share with my friends. But I notice the names of the NPCs aren’t exactly what I had in mind. I would prefer to have a first and last name.

We can use a guide for this, but this time just provide a natural language description.

We can say our name should be a “full name”.

And this is effectively another way of prompting. Instead of having to describe different properties in your prompt, you can do it directly in your Generable type. And it gives the model a stronger relation for what these descriptions are tied to.

If we walk around in our game now, we’ll checkout these new names in action.

Here’s an overview of all the guides you can apply to different types.

With common numerical types, like int, you can specify the minimum, maximum or a range. And with array, you can control the count, or specify guides on the array's element type.

For String, you can let the model pick from an array with anyOf, or even constrain to a regex pattern.

A regex pattern guide is especially powerful. You may be familiar with using a regex for matching against text. But with Foundation Models, you can use a regex pattern to define the structure of a string to generate. For example, you can constrain the name to a set of prefixes.

```swift
@Generable
struct NPC {
  @Guide(Regex {
    Capture {
      ChoiceOf {
        "Mr"
        "Mrs"
      }
    }
    ". "
    OneOrMore(.word)
  })
  let name: String
}

session.respond(to: "Generate a fun NPC", generating: NPC.self)
// > {name: "Mrs. Brewster"}
```

And you can even use the regex builder syntax! If this renews your excitement in regex, make sure to watch the timeless classic "Meet Swift Regex" from a few years ago.

To recap, Generable is a macro that you can apply to structs and enums, and it gives you a reliable way to get structured output from the model. You don't need to worry about any of the parsing, and to get even more specific output, you can apply guides to your properties.

So Generable is great when you know the structure at compile time.

The macro generates the schema for you, and you get an instance of your type as output. But sometimes you only know about a structure at runtime. That's where dynamic schemas can help.

I'm adding a level creator to my game, where players can dynamically define entities to encounter while walking around in the game. For example, a player could create a riddle structure. Where a riddle has a question, and multiple choice answers. If we knew this structure at compile time, we could simply define a Generable struct for it:

```swift
@Generable
struct Riddle {
  let question: String
  let answers: [Answer]

  @Generable
  struct Answer {
    let text: String
    let isCorrect: Bool
  }
}
```

But our level creator allows for creating any structure the player can think of.

We can use DynamicGenerationSchema to create a schema at runtime.

Just like a compile-time defined struct, a dynamic schema has a list of properties. We can add a level creator, that can take a player's input.

Each property has a name and its own schema, which defines its type. You can use the schema for any Generable type, including built-in types, such as String.

A dynamic schema can contain an array, where you then specify a schema for the element of the array. And importantly, a dynamic schema can have references to other dynamic schemas.

So here, our array can reference a custom schema that is also defined at runtime.

From the user's input, we can create a riddle schema, with two properties.

The first is the question, which is a string property. And secondly, an array property, of a custom type called Answer.

And we'll then create the answer. This has a string and boolean property.

Note that the riddle's answers property refers to the answer schema by its name.

```swift
struct LevelObjectCreator {
  var properties: [DynamicGenerationSchema.Property] = []

  mutating func addStringProperty(name: String) {
    let property = DynamicGenerationSchema.Property(
      name: name,
      schema: DynamicGenerationSchema(type: String.self)
    )
    properties.append(property)
  }

  mutating func addArrayProperty(name: String, customType: String) {
    let property = DynamicGenerationSchema.Property(
      name: name,
      schema: DynamicGenerationSchema(
        arrayOf: DynamicGenerationSchema(referenceTo: customType)
      )
    )
    properties.append(property)
  }
  
  var root: DynamicGenerationSchema {
    DynamicGenerationSchema(
      name: name,
      properties: properties
    )
  }
}

var riddleBuilder = LevelObjectCreator(name: "Riddle")
riddleBuilder.addStringProperty(name: "question")
riddleBuilder.addArrayProperty(name: "answers", customType: "Answer")

var answerBuilder = LevelObjectCreator(name: "Answer")
answerBuilder.addStringProperty(name: "text")
answerBuilder.addBoolProperty(name: "isCorrect")

let riddleDynamicSchema = riddleBuilder.root
let answerDynamicSchema = answerBuilder.root

let schema = try GenerationSchema(
  root: riddleDynamicSchema,
  dependencies: [answerDynamicSchema]
)

let session = LanguageModelSession()
let response = try await session.respond(
  to: "Generate a fun riddle about coffee",
  schema: schema
)
let generatedContent = response.content
let question = try generatedContent.value(String.self, forProperty: "question")
let answers = try generatedContent.value([GeneratedContent].self, forProperty: "answers")
```

Then we can create the DynamicGenerationSchema instances. Each dynamic schema is independent. Meaning the riddle dynamic schema doesn't actually contain the answer's dynamic schema. Before we can do inference, we first have to convert our dynamic schemas into a validated schema. This can throw errors if there are inconsistencies in the dynamic schemas, such as type references that don't exist.

And once we have a validated schema, we can prompt a session as usual. But this time, the output type is a GeneratedContent instance. Which holds the dynamic values.

You can query this with the property names from your dynamic schemas. Again, Foundation Models will use guided generation to make sure the output matches your schema. It will never make up an unexpected field! So even though it's dynamic, you still don't have to worry about manually parsing the output.

So now when the player encounters an NPC, the model can generate this dynamic content. Which we’ll show in a dynamic UI. Let’s checkout what we run into. I’m dark or light, bitter or sweet, I wake you up and bring the heat, what am I? Coffee or hot chocolate. I think the answer is coffee.

That's correct! I think my players will have a lot of fun creating all sorts of fun levels.

To recap, with the Generable macro, we can easily generate structured output from a Swift type that’s defined at compile time.

And under the hood, Foundation Models takes care of the schema, and converting the GeneratedContent into an instance of your own type. Dynamic schemas work very similar, but give you much more control. You control the schema entirely at runtime, and get direct access to the GeneratedContent. Next, let’s take a look at tool calling, which can let the model call your own functions. I’m thinking of creating a DLC, downloadable content, to make my game more personal. Using tool calling, I can let the model autonomously fetch information. I’m thinking that integrating the player’s contacts and calendar could be really fun.

I wouldn't normally do that with a server-based model, my players wouldn't appreciate it if the game uploaded such personal data. But since it's all on-device with Foundation Models, we can do this while preserving privacy.

Defining a tool is very easy, with the Tool protocol. You start by giving it a name, and a description. This is what will be put in the prompt, automatically by the API, to let the model decide when and how often to call your tool.

It's best to make your tool name short, but still readable as English text. Avoid abbreviations, and don't make your description too long, or explain any of the implementations. Because remember, these strings are put verbatim in your prompt. So longer strings means more tokens, which can increase the latency. Instead, consider using a verb in the name, such as findContact. And your description should be about one sentence. As always, it's important to try different variations to checkout what works best for your specific tool.

Next, we can define the input for our tool. I want the tool to get contacts from a certain age generation, like millennials. The model will be able to pick a funny case based on the game state, and I can add the Arguments struct, and make it Generable.

When the model decides to call this tool, it will generate the input arguments. By using Generable, this guarantees your tool always gets valid input arguments. So it won't make up a different generation, like gen alpha, which we don't support in our game.

Then I can implement the call function. The model will call this function when it decides to invoke the tool.

In this example, we'll then call out to the Contacts API. And return a contact's name for that query.

```swift
import FoundationModels
import Contacts

struct FindContactTool: Tool {
  let name = "findContact"
  let description = "Finds a contact from a specified age generation."
    
  @Generable
  struct Arguments {
    let generation: Generation
        
    @Generable
    enum Generation {
      case babyBoomers
      case genX
      case millennial
      case genZ            
    }
  }
  
  func call(arguments: Arguments) async throws -> ToolOutput {
    let store = CNContactStore()
        
    let keysToFetch = [CNContactGivenNameKey, CNContactBirthdayKey] as [CNKeyDescriptor]
    let request = CNContactFetchRequest(keysToFetch: keysToFetch)

    var contacts: [CNContact] = []
    try store.enumerateContacts(with: request) { contact, stop in
      if let year = contact.birthday?.year {
        if arguments.generation.yearRange.contains(year) {
          contacts.append(contact)
        }
      }
    }
    guard let pickedContact = contacts.randomElement() else {
      return ToolOutput("Could not find a contact.")
    }
    return ToolOutput(pickedContact.givenName)
  }
}
```

To use our tool, we'll pass it in the session initializer. The model will then call our tool when it wants that extra piece of information.

```swift
import FoundationModels

let session = LanguageModelSession(
  tools: [FindContactTool()],
  instructions: "Generate fun NPCs"
)
```

This is more powerful than just getting the contact ourselves, because the model will only call the tool when it needs for a certain NPC, and it can pick fun input arguments based on the game state. Like the age generation for the NPC.

Keep in mind, this is using the regular contacts API, which you might be familiar with. When our tool is first is invoked, it will ask the player for the usual permission. Even if the player doesn’t want to give access to their contacts, Foundation Models can still generate content like before, but if they do give access, we make it more personal.

Let’s walk around a bit in our game until we encounter another NPC. And this time, I’ll get a name from my contacts! Oh hi there Naomy! Let’s checkout what she has to say, I didn’t know you liked coffee.

Note that LanguageModelSession takes an instance of a tool. This means you control the lifecycle of the tool. The instance of this tool stays the same for the whole session.

Now, in this example, because we're just getting a random character with our FindContactsTool, it's possible we'll get the same contact sometimes. In our game, there are multiple Naomy's now. And that's not right, there can only be the one.

To fix this, we can keep track of the contacts the game has already used. We can add state to our FindContactTool. To do this, we will first convert our FindContactTool to be a class. So it can mutate its state from the call method.

```swift
import FoundationModels
import Contacts

class FindContactTool: Tool {
  let name = "findContact"
  let description = "Finds a contact from a specified age generation."
   
  var pickedContacts = Set<String>()
    
  ...

  func call(arguments: Arguments) async throws -> ToolOutput {
    contacts.removeAll(where: { pickedContacts.contains($0.givenName) })
    guard let pickedContact = contacts.randomElement() else {
      return ToolOutput("Could not find a contact.")
    }
    return ToolOutput(pickedContact.givenName)
  }
}
```

Then we can keep track of the picked contacts, and in our call method we don't pick the same one again.

The NPC names are now based on my contacts! But talking to them doesn't feel right yet. Let's round this off with another tool, this time for accessing my calendar.

```swift
import FoundationModels
import EventKit

struct GetContactEventTool: Tool {
  let name = "getContactEvent"
  let description = "Get an event with a contact."

  let contactName: String
    
  @Generable
  struct Arguments {
    let day: Int
    let month: Int
    let year: Int
  }
    
  func call(arguments: Arguments) async throws -> ToolOutput { ... }
}
```

For this tool, we’ll pass in the contact name from a dialog that’s going on in our game. And when the model calls this tool, we’ll let it generate a day, month and a year for which to fetch events with this contact. And we’ll pass this tool in the session for the NPC dialog.

So now, if we ask my friend Naomy’s NPC "What’s going on?", she can reply with real events we have planned together.

Wow, it's like talking to the real Naomy now.

Let’s take a closer look at how tool calling works.

We start by passing the tool at the start of the session, along with instructions. And for this example, we include information like today’s date.

Then, when the user prompts the session, the model can analyze the text. In this example, the model understands that the prompt is asking for events, so calling the calendar tool makes sense.

To call the tool, the model first generates the input arguments. In this case the model needs to generate the date to get events for. The model can relate information from the instructions and prompt, and understand how to fill in the tool arguments based on that.

So in this example it can infer what tomorrow means based on today’s date in the instructions. Once the input for your tool is generated, your call method is invoked.

This is your time to shine, your tool can do anything it wants. But note, the session waits for your tool to return, before it can generate any further output.

The output of your tool is then put in the transcript, just like output from the model. And based on your tool’s output, the model can generate a response to the prompt.

Note that a tool can be called multiple times for a single request.

And when that happens, your tool gets called in parallel. So keep that in mind when accessing data from your tool’s call method.

Alright, that was pretty fun! Our game now randomly generates content, based on my personal contacts and calendar. All without my data ever leaving my device. To recap, tool calling can let the model call your code to access external data during a request. This can be private information, like Contacts, or even external data from sources on the web. Keep in mind that a tool can be invoked multiple times, within a given request. The model determines this based on its context.

Tools can also be called in parallel, and they can store state.

That was quite a lot.

Perhaps get a coffee before doing anything else.

To learn more, you can check out the dedicated video about prompt engineering, including design and safety tips. And, if you want to meet the real Naomy, check out the code-along video. I hope you will have as much fun with Foundation Models as I've had. Thanks for watching.
--- END FILE ---

--- FILE: generating-content-and-performing-tasks.md ---
# Generating content and performing tasks with Foundation Models

**Enhance the experience in your app by prompting an on-device large language model.**


## Overview

The Foundation Models framework lets you tap into the on-device large models at the core of Apple Intelligence. You can enhance your app by using generative models to create content or perform tasks. The framework supports language understanding and generation based on model capabilities.

For design guidance, see Human Interface Guidelines > Technologies > [https://developer.apple.com/design/human-interface-guidelines/generative-ai](https://developer.apple.com/design/human-interface-guidelines/generative-ai).


## Understand model capabilities

When considering features for your app, it helps to know what the on-device language model can do. The on-device model supports text generation and understanding that you can use to:

The on-device language model may not be suitable for handling all requests, like:

The model can complete complex generative tasks when you use guided generation or tool calling. For more on handling complex tasks, or tasks that require extensive world-knowledge, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation) and [doc://com.apple.foundationmodels/documentation/FoundationModels/expanding-generation-with-tool-calling](https://developer.apple.com/documentation/FoundationModels/expanding-generation-with-tool-calling).


## Check for availability

Before you use the on-device model in your app, check that the model is available by creating an instance of [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel) with the [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/default](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/default) property.

Model availability depends on device factors like:

- The device must support Apple Intelligence.

- The device must have Apple Intelligence turned on in Settings.


> **NOTE**: It can take some time for the model to download and become available when a person turns on Apple Intelligence.


Always verify model availability first, and plan for a fallback experience in case the model is unavailable.

```swift
struct GenerativeView: View {
    // Create a reference to the system language model.
    private var model = SystemLanguageModel.default

    var body: some View {
        switch model.availability {
        case .available:
            // Show your intelligence UI.
        case .unavailable(.deviceNotEligible):
            // Show an alternative UI.
        case .unavailable(.appleIntelligenceNotEnabled):
            // Ask the person to turn on Apple Intelligence.
        case .unavailable(.modelNotReady):
            // The model isn't ready because it's downloading or because of other system reasons.
        case .unavailable(let other):
            // The model is unavailable for an unknown reason.
        }
    }
}
```


## Create a session

After confirming that the model is available, create a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession) object to call the model. For a single-turn interaction, create a new session each time you call the model:

```swift
// Create a session with the system model.
let session = LanguageModelSession()
```

For a multiturn interaction — where the model retains some knowledge of what it produced — reuse the same session each time you call the model.


## Provide a prompt to the model

A [doc://com.apple.foundationmodels/documentation/FoundationModels/Prompt](https://developer.apple.com/documentation/FoundationModels/Prompt) is an input that the model responds to. Prompt engineering is the art of designing high-quality prompts so that the model generates a best possible response for the request you make. A prompt can be as short as “hello”, or as long as multiple paragraphs. The process of designing a prompt involves a lot of exploration to discover the best prompt, and involves optimizing prompt length and writing style.

When thinking about the prompt you want to use in your app, consider using conversational language in the form of a question or command. For example, “What’s a good month to visit Paris?” or “Generate a food truck menu.”

Write prompts that focus on a single and specific task, like “Write a profile for the dog breed Siberian Husky”. When a prompt is long and complicated, the model takes longer to respond, and may respond in unpredictable ways. If you have a complex generation task in mind, break the task down into a series of specific prompts.

You can refine your prompt by telling the model exactly how much content it should generate. A prompt like, “Write a profile for the dog breed Siberian Husky” often takes a long time to process as the model generates a full multi-paragraph essay. If you specify “using three sentences”, it speeds up processing and generates a concise summary. Use phrases like “in a single sentence” or “in a few words” to shorten the generation time and produce shorter text.

```swift
// Generate a longer response for a specific command.
let simple = "Write me a story about pears."

// Quickly generate a concise response.
let quick = "Write the profile for the dog breed Siberian Husky using three sentences."
```


## Provide instructions to the model

[doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) help steer the model in a way that fits the use case of your app. The model obeys prompts at a lower priority than the instructions you provide. When you provide instructions to the model, consider specifying details like:

- What the model’s role is; for example, “You are a mentor,” or “You are a movie critic”.

- What the model should do, like “Help the person extract calendar events,” or “Help the person by recommending search suggestions”.

- What the style preferences are, like “Respond as briefly as possible”.

- What the possible safety measures are, like “Respond with ‘I can’t help with that’ if you’re asked to do something dangerous”.

Use content you trust in instructions because the model follows them more closely than the prompt itself. When you initialize a session with instructions, it affects all prompts the model responds to in that session. Instructions can also include example responses to help steer the model. When you add examples to your prompt, you provide the model with a template that shows the model what a good response looks like.


## Generate a response

To call the model with a prompt, call [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/respond(to:options:)-b2re](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/respond(to:options:)-b2re) on your session. The response call is asynchronous because it may take a few seconds for the on-device foundation model to generate the response.

```swift
let instructions = """
    Suggest five related topics. Keep them concise (three to seven words) and make sure they \
    build naturally from the person's topic.
    """

let session = LanguageModelSession(instructions: instructions)

let prompt = "Making homemade bread"
let response = try await session.respond(to: prompt)
```


> **NOTE**: A session can only handle a single request at a time, and causes a runtime error if you call it again before the previous request finishes. Check [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/isResponding](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/isResponding) to verify the session is done processing the previous request before sending a new one.


Instead of working with raw string output from the model, the framework offers guided generation to generate a custom Swift data structure you define. For more information about guided generation, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation).

When you make a request to the model, you can provide custom tools to help the model complete the request. If the model determines that a [doc://com.apple.foundationmodels/documentation/FoundationModels/Tool](https://developer.apple.com/documentation/FoundationModels/Tool) can assist with the request, the framework calls your [doc://com.apple.foundationmodels/documentation/FoundationModels/Tool](https://developer.apple.com/documentation/FoundationModels/Tool) to perform additional actions like retrieving content from your local database. For more information about tool calling, see [doc://com.apple.foundationmodels/documentation/FoundationModels/expanding-generation-with-tool-calling](https://developer.apple.com/documentation/FoundationModels/expanding-generation-with-tool-calling)


## Consider context size limits per session

The *context window size* is a limit on how much data the model can process for a session instance. A token is a chunk of text the model processes, and the system model supports up to 4,096 tokens. A single token corresponds to three or four characters in languages like English, Spanish, or German, and one token per character in languages like Japanese, Chinese, or Korean. In a single session, the sum of all tokens in the instructions, all prompts, and all outputs count toward the context window size.

If your session processes a large amount of tokens that exceed the context window, the framework throws the error [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)). When you encounter the error, start a new session and try shortening your prompts. If you need to process a large amount of data that won’t fit in a single context window limit, break your data into smaller chunks, process each chunk in a separate session, and then combine the results.


## Tune generation options and optimize performance

To get the best results for your prompt, experiment with different generation options. [doc://com.apple.foundationmodels/documentation/FoundationModels/GenerationOptions](https://developer.apple.com/documentation/FoundationModels/GenerationOptions) affects the runtime parameters of the model, and you can customize them for every request you make.

```swift
// Customize the temperature to increase creativity.
let options = GenerationOptions(temperature: 2.0)

let session = LanguageModelSession()

let prompt = "Write me a story about coffee."
let response = try await session.respond(
    to: prompt,
    options: options
)
```

When you test apps that use the framework, use Xcode Instruments to understand more about the requests you make, like the time it takes to perform a request. When you make a request, you can access the [doc://com.apple.foundationmodels/documentation/FoundationModels/Transcript](https://developer.apple.com/documentation/FoundationModels/Transcript) entries that describe the actions the model takes during your [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession).

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models)*
--- END FILE ---

--- FILE: Code-along-with-the-foundation-models-framework.md ---
Hello everyone and welcome to the Foundation Models Framework Code Along. My name is Shashank. I'm a technology evangelist here at Apple and today I'm excited to guide you through integrating on-device generative AI features directly into your app. We'll cover everything from basic prompting to generating structured output, streaming responses and more. we have an incredible team of experts in Slido. If you have any questions at any point, please ask there.

Let's start with a quick overview to get everyone on the same page. At WWDC24, we introduced Apple Intelligence, powered by large foundation models built into the core of our operating systems. This brought system level features like Writing Tools and Genmoji. Many of you have asked for access to the underlying models and at WWDC25, we delivered with the Foundation Models Framework. It gives you direct access to the same on-device large language model that powers Apple intelligence, all through a powerful Swift API. For developers, this on-device approach has major advantages. Because everything runs locally, user data remains private. Your features work entirely offline with no accounts to set up or API keys to manage. There's no cost to you or someone using the app for any of these requests. And since it's all part of the OS, there's no impact on your app size.

Today, we're gonna build an app together. We'll start with a simple static app that lists landmarks and transform it into a dynamic travel planner. You learn how to generate rich structure itineraries for a custom UI, stream the results in real time as they're created. You'll also learn how to give the model access to custom tools to find real points of interest. And finally, how to optimize your app for performance.

Let's do a quick tour of the final app you'll be building.

Here is a completed app running on my Mac. And this is what you'll have by the end of our session today. We'll start with a simple, clean list of famous landmarks built using SwiftUI. Let's pick a landmark. How about Serengeti? When we click into the detail view, you see a header image and description.

At the bottom is our generate itinerary button. When I click this, the app will call the on-device model to generate a complete three-day travel plan. Watch the screen closely as this happens.

The UI is building itself in real time. First the title, then the description, then the day-by-day plan. This is the streaming API we'll incorporate in chapter four, and it creates a fantastic dynamic user experience. And this here isn't just a block of code, it's rich structured response, which we learn about in chapter two. We have distinct sections for day with a title, subtitle, and a map. Notice the names here like Hotel 1 and Restaurant 1. These aren't random. Our app is using tool calling to get these names, which we'll cover in chapter five. The foundation model framework lets you create rich, structured, and intelligent experiences that feel seamlessly integrated into your app. This is what we're going to build together today. To get the most out of today's Code Along, you have three key resources. First is the Xcode startup project. It has all the boilerplate UI and assets ready to go. If you're watching on developer.apple.com or the developer app, You'll find this under resources on the bottom of the page. If you're watching this on YouTube, it's linked from the description.

Second is our step by step guide on the web page. This is your source of truth with all the instructions and code snippets. You can simply copy paste these to avoid typos. And finally, you have me on the live stream and team of experts behind the scenes to answer your questions. I'll be building this project right here with you, explaining the why behind each change.

Before we jump into the settings and set up the project, let's quickly go over the system requirements for today's session. Everyone is welcome to watch and follow along. However, if you plan on coding live with me, you'll need an Apple Silicon based Mac running macOS Tahoe and Xcode 26. You'll also need to make sure that Apple intelligence is turned on under settings. I'll be building and running the app directly on my Mac today, but you can also use Xcode 26 with a recent iPhone running iOS 26 as your target.

With that, let's move on to the prerequisite section in our Code Along Guide and get our startup project downloaded and configured.

Here in our guide, you'll see a prerequisite section.

First, please click the link to download the project file.

Here, once you've downloaded, you'll find a zip file that macOS may automatically unzip for you. Inside, you'll find a folder named Foundation Models Code Along. This is a startup project we'll be using today. It contains all the necessary views, models, and placeholder code to get us started. I have my project open here and ready to go.

The first thing we need to do is set the developer team. In the project navigator, select the project file.

Then select targets.

Click on signing and capabilities. And under team, select the dropdown and select your team.

To make sure everything is working correctly, select myMac as the run destination in the Xcode toolbar.

and then click on the Run button. This will build and run the project. Alternatively, you can use Command + R.

What I have here is the app that we're gonna be building and adding our generative AI features into. So this is our starting point and we'll be adding powerful features throughout this session. Now let's do a quick tour of our startup project.

First we have here our Playground.swift file under the playgrounds folder. This is where we'll iterate on our prompts and test out foundation models APIs in isolation without having to build and run our entire app. Once we're happy with a prompt here, we'll move this code into our app.

Next is our view models folder and the most important file for us here is itineraryGenerator.swift. All the core logic for creating and managing foundation model sessions, calling the framework APIs and processing the results will live right here. And finally, we have a views folder.

This is where all our SwiftUI code lives. For this code along, the UI is mostly pre-built to let us focus on the Foundation Models Framework. You'll notice that there are several files here and to make it easy to follow, the key files we'll be editing are numbered.

Our job will be to take the output of our itinerary generator and wire it up to these views to create the rich and interactive UI that you'll see in the app.

As you go through these files, you'll notice there are special comments formatted this way. Mark, Code Along, Chapter, and a number. Each number here corresponds directly to the chapter and section with the same number in your Code Along guide. You can use the Xcode Find Navigator to search for the chapter number to see all the outstanding code changes.

Enter the chapter number here, and you'll see all the code changes. As we complete each step, we'll keep deleting these comments so we can track progress throughout the Code Along.

So in summary, we'll follow three simple steps. First, experiment in the playground. Second, implement the core logic in the view model, and finally, display the results in the view. Let's take a closer look at each of these views.

The first screen is a starting point, the main list of landmarks. This is powered by LandmarksView.swift. We won't be touching this file today. It's all set up for us to let us browse and select a destination. When you tap a landmark, you land on the details screen. This view is controlled by the landmark DetailView.swift file. Its main job is to check if the Foundation Models Framework is available on device and decide what UI to show based on that.

Next is the landmark trip view. Its role is to present the generate itinerary button. And this is also where we'll first display the raw unstructured text that we get back from the model.

And finally, the itinerary view is our destination. This view renders the rich structured itinerary data we'll have towards the end of the code along.

We're now ready to dive into the agenda. We've structured the code along into six chapters. We'll start with the absolute basics where you learn how to start prompting the model to generate text. Then we'll move beyond simple text and see how to get structured Swift types back from the model, making it easy to map model output to your custom views. We'll then dive into prompting techniques. That lets you improve models accuracy by providing high quality examples directly in your prompts. Next, we'll learn how to stream the model's response to update the UI in real time for a great user experience. We'll then explore tool calling. Tools are powerful ways to give the model access to your own custom functions and data to extend its capabilities.

And finally, we'll cover performance optimizations to make our generative features feel faster and more responsive. With that, let's dive into the basics of Foundation Models Framework. You can use the Foundation Models Framework to send a prompt to the on-device large language model, or LLM for short. The LLM can then reason about your prompt and generate text. For example, you could ask it to generate a three-day itinerary to Paris, and the model will respond with a detailed plan.

To start prompting the model, you'll need to create a session. The framework is built around this idea of stateful language model session, which maintains a history of all prompts and responses.

In this chapter, we'll get familiar with foundation models prompts and sessions. First, we'll start in the playground to get a feel for the API. We'll create a language model session and get our first response from the model. Then, we'll add concise instructions to shape the tone and content. Next, we look at availability API to handle different states gracefully. Once we are comfortable, we'll switch to the app, update the itinerary generator in a view model, and display the raw text output in our views. So let's head on over to our Code Along Guide.

Our goal in chapter one is to make our very first request on-device language model. We'll use the Xcode Playground to send a simple text prompt and see what happens. This will help us understand the model's basic behavior.

Feel free to copy and paste this code block into Xcode Playground.swift file and you can use this handy copy button on the top right corner. I'll be adding these lines of code step by step and explaining what is going on. Let's head over to our Xcode. open up our Playground.swift file. To prompt a model, you need three simple steps. The first is to import the Foundation Models Framework, which we've already done. The next step is to create a playground.

As soon as you use a playground macro to create a playground, you'll see a canvas show up on the right. If it doesn't, you can always click on editor options and ensure that there's a check mark next to canvas. you can click the refresh button and what that does is run all the code contained within the playground block. Right now you don't see an output because we haven't added anything. Step two in prompting the model is to create a session.

What we have here is let a variable session equal to language model session and you'll see the playground canvas automatically shows what is in the session variable. So you see that there are tools which we'll discuss in a later chapter and then transcript which includes all the conversations that you have with the model.

Step three is to prompt the model.

We say let response equal to try await session dot respond to and provide a prompt generate a three day itinerary to Paris. This is an async request so we await its response.

As soon as we do that, on the right side on the canvas, you'll see we have a response variable which includes a few properties. First is prompt. The prompt shows generate a 3-day itinerary to Paris and then there's a property called content which is of type String.

Let's click on this and you'll see that there's a detailed 3-day itinerary to Paris. Certainly here's a 3-day itinerary for exploring Paris, highlighting some of the city's most iconic sites and experience, and you see day by day plans for day one, morning, afternoon, and so on.

Great. Let's go back to our guide here and discuss a key topic. When you make the very first call to Session.response, you might notice that there's a slight delay. This is because the on-device language model needs to be loaded into memory before it can process your request. Our first request triggers a system to load the model, which causes the initial latency. We'll see how to address this in a later chapter. And we also saw that the output was unstructured natural language text, which is easy for us to read, but hard to use in a custom Swift UI. In the next chapter, we'll see how to generate structured output using Swift types instead of raw text. Finally, it's important to note that the entire itinerary without any data ever leaving your device. It's completely private and works offline. So congratulations, you've successfully prompted the on-device foundation model using the Foundation Models Framework.

Oh, and one last thing, let me head back to our playground.

We are always interested in improving the model, and if you want to provide feedback, you can always use these buttons right here in Canvas to share your feedback with us. Let's head on over to our Code Along Guide to Section 1.2, Guiding the model with instructions.

Our goal now is to get more consistent and higher quality results. We can do this by providing the model with instructions. Think of instructions as permanent rules or persona for the entire conversation within a single session. Feel free again to copy this piece of code into Playground and run it. and I'm going to go and add these instructions.

Back in our Playground.swift file, I add a new variable called instructions, and I say, your job is to create an itinerary for the user. Each day needs an activity, hotel, and restaurant. Always include a title, a short description, and a day-by-day plan. We can pass these instructions into the language model session using the instruction argument. When you pass this, the canvas will automatically detect code changes and update our results. We see now that we have our content property under response and this will include the request that we made, which is include activity, hotel and restaurant, and you can see this here, activity, hotel, and restaurants.

A question you may have is, what is the difference between these instructions and prompts? Let's take a look.

Instructions can be used to define a persona, set rules, and specify desired format for the response. This should come from the developer. Prompts, on the other hand, can come from someone using the app. The model is trained to obey instructions over prompts, and this can help protect against prompt injection attacks where the user may ask the model to ignore guidance provided in the prompt. As a rule, keep the instructions static and avoid inserting user input into them.

Also note that instructions are maintained throughout the session's life. Every interaction is recorded in the session's transcript, and The initial instructions are always the first entry.

Great, we're able to successfully prompt a model and get responses. But it's important to consider that our app might run on devices where Apple intelligence isn't available and showing a non-functional feature can be a bad user experience.

For example, the device may not even support Apple intelligence or The device may support Apple intelligence, but the user has not enabled it. Or the model assets are still downloading and they're not ready for use yet. Let's take a close look at how to handle these cases. We'll head on back to our Code Along Guide. We are now in section 1.3 in our Code Along Guide, Handling Model Availability.

The model provides APIs for availability.

Let's head on over to Xcode and take a closer look at each of these cases in this switch block and what they mean for your app.

Back in our Playground.swift file, a neat feature of playground is you can add multiple of these in the same Swift file.

I added a new # playground block here that includes the availability code. All right. Let's take a look at these APIs. You can also check the output of the multiple playgrounds. The second playground will show up as a second tab here on our canvas. And you'll see my Mac does support Apple intelligence. So it says foundation model is available and ready to go. Let's take a closer look at these cases now.

The first case is available. This means you have a green light. the model is loaded and you're ready to make generation requests.

If it says unavailable and device not eligible, this means the model doesn't support Apple Intelligence. You should gracefully hide the generative UI and show an alternate experience.

For unavailable and Apple Intelligence not enabled, this means the device is capable, but Apple Intelligence is turned off in settings. This is your chance to prompt the user to enable it.

Unavailable and model not ready, this is a temporary state, likely because the model assets are still downloading. The best practice is to tell the user to try again. We're now ready to add these features into our app. Let's head on over to our Code Along Guide.

We're now in the app section of chapter one. In this section, we'll update our landmark DetailView.swift to check the model availability and display a message if it is unavailable.

Feel free to copy these code blocks. You can search for these marked comments to know exactly where to insert these code changes and I'll be doing this live with you. Let's head on over to our Xcode project and click on landmark detail view.swift in the views folder. Again, as a reminder, you can always use the find navigator to look for all the code changes that you need to make in this chapter. All right, the first thing to do is to add our model instance.

So we say private let model equal to system language model.default. This is exactly the same line of code we used in our playground, so it should look familiar to you. And since I've added this, I'm gonna delete this comment. So it disappears from our find navigator. The next code change we need to do is to delete this placeholder availability code I have here. This was purely for convenience, so I'm gonna delete this. And as soon as I do that, Xcode will promptly remind me that availability has not been defined yet, but that's an easy fix because we have our model now, model.availability.

And I'm gonna get rid of this line of code too. Okay? With that code change, we've made all the changes to this specific file. Now, we've added these availability checks, which is familiar to you because we use the same in the playground, but how do you test them? You may not have access to multiple test devices. Thankfully, there's an easy way. Right here in the scheme settings in the project, there's an option to simulate unavailability. Let's take a look. Click on foundation models code along, click edit scheme, and if you scroll down, you'll see an option that says simulated foundation models availability.

If you click this, there are a few different options, and these options should be familiar to you because these are the cases we covered in the playground. So I'm gonna click Apple Intelligence Not Enabled, close, and I'm going to build and run our app.

We have our app here, I'm gonna select Sahara Desert, and aha, I see a message here that says, Trip Planner is unavailable because Apple Intelligence has not been turned on.

And this is the same message we have in our unavailability view.

Great. Let me switch this back so we can keep adding additional features throughout the code along.

All right. Let's head on over to section 1.5 in our Code Along Guide.

Now we are ready to update the app's itinerary generator to initialize a language model session and define a function called generate itinerary to invoke the model from our views. The code again should look familiar to you because we already implemented this in the code along. Now we'll be migrating this into our app. So let's head on over to Xcode and open our itinerary Generator.swift file, which you will find in the view models folder.

We'll again use our find navigator to look for all the code changes that we need to make and track progress. All right. In itinerary Generator.swift file, the first change we'll need to make is to add a session property.

And I'm going to do that first. So we define a variable called session for language model session.

Next, Xcode will remind us that we have not initialized a session. So we are going to initialize this session right here in the init functions.

Okay, so here's what we added. We added an instructions variable where we use the same instructions we had in the playground. Your job is to create an itinerary for the user. Each day needs an activity hotel and restaurant. Always include a title, a short description, and a day-by-day plan and I have a session with language model session and we pass in the instructions.

Okay, the third and final change we need to do is to update our generate itinerary function. This is the function that we'll invoke from our views in order to send in the prompt and get back a response. Let's go make this code change.

Okay, here's what we added. First, we said let prompt equal to generate a day count day itinerary to landmark.name. Day count here defaults to three and then landmark.name is the name of the landmark that the user clicks on when they open the app. So we gather this name and we pass it to the prompt So we can generate a response for that specific landmark. Next, we have letResponse equal to tryAwaitSession.Response and pass in a prompt. Finally, the response variable has a property.content, which you can recall from our playground canvas that we observed, which had all the natural unstructured text, which is a string, and we assign it to itinerary content.

That includes all the code changes for our view model, which is now ready to be called from our views. Let's head on back to our Code Along Guide to section 1.6. This is our final section in chapter one. We will now update the landmark trip view to take the output from the itinerary generator and display it in the app. Again, feel free to make these code changes by following along these comments. I'm gonna head over to Xcode.

Click on Views.

And landmark trip view. Okay.

All right, the first code change we'll need to make is to add a local variable for the itinerary generator class in our view model.

All right, so we have itinerary generator of the type itinerary and I'm gonna delete this comment.

The next code we need to do, a code change we need to do is to create an instance of this when the view is loaded.

So here's what we introduce under task modify. We said let generator equal to itinerary generator, which is the ViewModel class, and we pass in the landmark, so that it has information about which landmark the user clicked on, which if you recall, we pass it to the prompt. And then we hold on to the itinerary generator here. I'm going to delete the code change that we just made.

The next change we need to do is to update our view itself. Let's take a closer look at the view. By default, we have a Boolean variable here called requested itinerary. It is set to false.

Because it's set to false, we load up the first view on top here, which is a text field that has the landmark name. We access the landmark.name, and then we access the short description using Landmark.shortDescription. This is what shows up when the user has not generated, asked the model to generate an itinerary. But when the requested itinerary is set to false, we need to load up a new view where we can populate it with the model's output, and that is what we are going to implement right now. So I'm gonna remove the else case here and introduce a new else case where I say, if let content equal to itinerary generator dot itinerary content. If you recall, itinerary content is the string variable has our model's output. And then we simply take that content and we update it in our text view. Since we made this change, I'm gonna get rid of this comment too. We're almost there. We have one final change in this view. If you scroll back down here, we've defined a button that will show up at the bottom of the screen and currently this button is hidden. So we'll need to make two minor code changes here. One, we want to show the button so you can either comment this out or straight out delete it like what I'm doing. And then we need to insert code here to generate the itinerary when the user taps on the button. So let's add that here. Okay, so we said await itinerary generator and we invoke the generate itinerary function. If you recall, this is the function that takes the prompt and then passes it to the model and gets the output. That concludes all the code changes in this chapter.

Okay, we are now ready to build and run this app. Click on the run button here, which will build and run the app.

Here is our app. I'm gonna click on Sahara Desert here and we see that we have our generate itinerary button and when I click on this generate itinerary button, the prompt and instructions are being sent to the on device LLM which is going to generate a response asynchronously, token by token, right here on device.

If you see this itinerary like I do, congratulations, you built your very first fully functional on-device generative AI feature using Foundation Models Framework. With just a few lines of Swift, you've tapped into the power of Apple Intelligence.

This is great, but what we have here is a wall of text. What if I wanted to pull out a hotel name and show it on a map? This isn't the rich experience that we want. We'll address this in chapter two with guided generation. We'll discuss how you can get outputs using Swift structs directly from the model. For now, let's quickly recap chapter one.

In this chapter, we learned how to create a session and prompt the model for a basic text response. We saw how to provide instructions to guide the model's output and we covered how to handle different availability states using the availability API. Finally, we integrated these features into our app by updating the view model and view.

That wraps up chapter one.

Now that we can generate raw text, let's see how we can get structured data from the model to build a much richer UI.

Let's start with a fundamental challenge when working with LLMs. By default, they give us unstructured text, like the itinerary we just generated. While a human can read it, for an app developer, this can be challenging to work with. For example, how would you reliably extract the hotel for day one to plot it on a map? You'd have to write complex string parsing code that could break if the model's output changed. What we want instead is structured data that maps directly to our apps logic.

We'd need a more advanced nested structure that can be implemented using Swift structs. This itinerary object should contain an array of objects which in turn should contain an array of activity objects and so on. This is where guided generation comes in. The Foundation Models Framework provides APIs that allow you to specify exactly what your output should look like. If you have a Swift struct, you can simply apply @Generable to it. And this lets the model generate structured data using native Swift types.

We'll start this chapter in the playground where we'll define a simple struct with a generable macro applied to it. We'll then build on it to create more complex nested data structures for the model to generate. Finally, we'll go back to the app, we'll refactor our itinerary generator to output our new structured itinerary type and update our views to display it in a rich UI.

Let's head on back to our Code Along Guide.

We're now in chapter two, generating structured outputs. Our goal is to move beyond simple strings and get structured type-safe Swift data directly from the model. This will allow us to build rich custom UI without any fragile string parsing.

Feel free to copy this piece of code again into Playground and take a look at its output. And I'll be explaining what is going on when we introduce this new struct called simple itinerary. Let's go to the Xcode Playground file and make these code changes.

I'm gonna get rid of the second playground we just added and right here I'm going to introduce this new struct called simple itinerary. Let me walk through what this looks like and how we can incorporate it in our foundation model code to generate this output. First, this struct has a few different properties. It has a title, which is of type String. It has a description, which is of type String. And it has days, which is an array of String.

We want the model to generate these fields and we can provide it additional information by providing guides. The guide has a description argument which says, an exciting name for the trip. This tells the model that it has to generate a title for this variable and similarly we have description, a short and engaging description for the trip and similarly for day count. What we can do now is provide this to the model and we can do that using the generating argument. So previously we had Session.response and just the prompt. So I'm going to add a new argument called generating and provide simple Itinerary.self.

And we can go and refresh our canvas.

This will run through the code and we'll take a look at the output.

Okay. We have our response here. And let's take a closer look at the content property here.

Previously, this content was a string. If you look carefully here, it says this is a struct simple itinerary. Let's open this up. And what you'll notice is the output one to one matches with the struct that we just defined here. So we have our title, which is Parisian Bliss. And that is our title property here. We have our description that is right here. And then we have our array of String. So you'll see days, which is an array of String with day by day activity plan.

Awesome. So let's go back to our Code Along Guide and the section 2.2. An itinerary doesn't just have to be string or array of Strings. It can have nested structs too. Now, let's take a look at a full itinerary struct that we'll be building in our app. So we're going to make a small code change here. All you have to do is replace simple itinerary with itinerary.self, and we are going to make this code chain and I'll explain what this itinerary struct looks like. Back to Xcode.

I'm going to delete this simple itinerary and replace simple itinerary with just itinerary. Okay, so what does itinerary look like? You can command and click on this to open the definition or head on over to the models folder, click on itinerary.swift file, and here you'll see a new struct called itinerary which has similar fields to what we saw in simple itinerary but more. Let's take a closer look. It also has a title which is of type String. It has a description, it has rationale. And if you take a closer look at days, you'll see that it's no longer an array of String. It is actually an array of day plan, which in turn is its own struct. It has its own title, its own subtitle, its own destination and an activity, which is an array of another struct called activity, which has a type, title, description, and type here happens to be an enum, which is also generable. The enum is a great way to have the model generate specific cases that are predefined. For example, here, the type can only be sightseeing, food and dining, shopping, hotel and lodging. If you scroll all the way up to the top, there is another way to constrain what the model can generate. We can use enums or here for destination name. We have a guide that says any of and we provide model data dot landmark. What this tells the model is that it has to generate a destination name that is one of the landmarks that we see when we open up the app. This includes the Serengeti, the Grand Canyon, Sahara Desert and so on. So the output must be one of these. So this is what the itinerary struct looks like. And this is what we actually use in the app. Let's head on back to our Swift playground. And because if you recall, we said the destination name should be one of the names from the list. Paris is not part of the list. So I'm going to change it to something that is actually on the list. How about Grand Canyon? Canvas will detect this code change and let's take a look at the output.

There we have our response. It includes a content and again, if you take a closer look, it is of struct itinerary, not simple itinerary because we updated it. Let's open this up. You'll see it has a title, destination name, description, rationale and days, which is an array of date plan struct. You open it up, you have multiple days, and activities is a type of an activity struct, and so on.

The key thing to note here is that when you apply @Generable, it is completely composable. The framework understands how to build this entire complex object from the top down, all while guaranteeing structural correctness. Now let's integrate this into our app. Let's head on over to our Code Along Guide. We're now in the app section of chapter two. In this section, we'll update our itinerary generator to use the itinerary generable struct that we just tested in the playground. Feel free to copy this code again and I'm going to be making these code changes with you. So let's head on over to itinerary generator under view models folder and bring up my find navigator, set it to chapter 2 so I can take a look at all the code changes I'll be making in this chapter. The first code change we need to make is way up top here where we have to update our itinerary content to not be a string anymore but be a type of type itinerary. So let's first change the name of this variable to just itinerary and update string to itinerary. We can delete this comment because we've made this code change. The next code change we need to do is if you scroll down to the generate itinerary function you see that Xcode is promptly reminding us that itinerary content no longer exists. So we can update this to itinerary because we just added this. And it is complaining because the content currently that is coming out of Session.respond is a string. So similar to last time in the playground, we're going to add the generating argument and provide itinerary.self.

So the model can now output a value that is of the type itinerary and because we made this code change I'm going to get rid of this comment right here. Okay, the final change we'll need to make is to remove additional structural guidance that we are providing in our instructions. Notice how we say each day needs an activity, hotel and restaurant, always include a title, short description, day by day. But all of this information is already in our itinerary generable struct. We don't need to provide it again in our instructions. So the benefit, another benefit of using generables is you can make your prompts much simpler, which can help improve performance as well. So I'm gonna get rid of this comment.

And that concludes all the code changes in this section. So we've updated our itinerary generator view model to be able to generate our generable structure. Let's head on over to section 2.4, updating our view to display the structure data. In this section, we'll update our landmark trip view to generate itinerary view instead of the raw text that we saw in the previous section. This is a very quick code change, so let's head on over to our landmark trip view, which you'll find as the second number to find the views folder.

And the code change we'll need to make is right here.

If you recall previously, we loaded this view when the model output was generated, but we are no longer generating a string. So we can no longer use a text view. So first we have to update this, but then we also need to update this with another view instead of text so that we can actually extract the fields from our itinerary and populate it in a rich UI. So let me replace this with an updated view and I'll talk about what that looks like.

Okay, so here is what I did. And you can also copy and paste this from our guide. Let's take a closer look. So I said itinerary equal to itinerary generator.itinerary. And instead of the text view, we have this itinerary view, which takes in a landmark and takes in the generated itinerary. Now this itinerary view exists in our views folder but we haven't looked at it so let's take a closer look. This should be the file number three of course you can also command and click on this to open it up. Alright we won't be making any code changes to this file in this chapter but you see comments here which means we'll likely be making changes will surely be making changes in a later chapter. What this view does is it can take an itinerary that was generated by the model, extract the fields and create the rich UI we saw in the initial demo. If you take a closer look at our body here we see it can extract the itinerary title, its description, populated and then it's if you scroll down you'll see that when it extracts the day-by-day activity, there is a dedicated view called day view that can show that and we use for each to loop through these and extract all the properties and lay it out. Notice this is so much simpler than being able to parse strings and update it.

All right, so let's head on over to our slides. So the key benefit of guided generation is that it fundamentally guarantees structural correctness. It uses a technique called constraint decoding to do that. What it does is give you control over what the model should generate, whether that be strings or numbers or arrays or even a custom data structure that you define.

This also means that our prompts can be a lot simpler and more focused on the desired behavior instead of prompting the model for specific output formats. This also tends to improve model accuracy allow for optimizations that speed up inference. So to recap, in this chapter we explored how to get structured data from the model. We use the generable macro to define our own Swift types and saw how to create complex data structures by nesting them. We then updated our app to generate and render this structured data in a rich user interface. Let's go build this model to take a look at all the changes we did. Here's our app. Let's click on Sahara Desert and generate itinerary. Similar to before, it's going to take our prompts and instructions and send it to the model and now instead of generating the wall of text, it generates the itinerary type, we extract all the fields, and then populate it in our app using the new view, which is itinerary view. All right, this concludes this chapter. And then, now we are getting that we're getting structured data as model outputs. We can now switch gears and focus on improving the quality and consistency of the output with additional prompting techniques.

While a good prompt tells the model what to do, sometimes it's more effective to just show it. We can include a high quality example as an instance of our generable type directly in a prompt.

This is great because it gives the model a better idea towards the type of responses I'm looking for. So in this chapter, we'll be focusing on improving the quality of our generated content. We'll start again in the playground by using the Prompt Builder API to create more dynamic prompts. Then we'll explore one-shot prompting by providing a high quality example in the prompt to improve the model's accuracy. Finally, we'll integrate what we learned into our apps itinerary generator.

Let's head on over to our Code Along Guide.

We're now in chapter three, prompting techniques. Our goal now is to improve the quality and reliability of a model's output. First, we'll explore how to introduce dynamic prompts using the Prompt Builder API.

Let's head on over to Playground and take a look. Again, feel free to copy this code block into your Playground.swift file.

We are in Xcode, Heading over to Playground.swift file.

Okay. The key code change we're gonna make here is to introduce a prompt using the prompt builder API. Previously, if you recall, under Session.respond, we provided the two argument with generate a three-day itinerary to Grand Canyon in the format of a string. But instead, we can define the prompt not as a string, but using the prompt builder API and passing the values to a closure. The key benefit is that it can now include things like Swift conditionals. So right up top here, we have a variable called which is a Boolean, which is currently set to true. And then within the Prompt Builder API, I use this Boolean to conditionally update my prompt. So if the kit-friendly Boolean is true, then we inject this additional information into the prompt, which is the itinerary must be kit-friendly. We can update our Session.response call to include this new prompt and refresh our canvas.

Let's take a look at our output.

We have our response variable, content.

I'm gonna open up rationale here and take a look. So it says, this itinerary provides a safe, engaging and educational experience for children, ensuring they enjoy the natural beauty of Grand Canyon while being supported by age appropriate activities and accommodation. So you'll see that the model is honoring our request and this came in as a conditional and the benefit of this again is that you can have these prompt speed dynamic. This could be something that the user selects on the app or it could be something that you learn as a developer from the user's preference and update a prompt.

Awesome. Let's go back to our Code Along Guide to section 3.2. Our goal now is to use a more advanced prompting technique called one-shot prompting to show the model exactly what a high quality response looks like. So let's head on over to our Code Along.

So right in my prompt filter API here inside disclosure, I'm going to add another line of code here. Here I say, here is an example of the desired format, but don't copy its content. And I introduce an example. Let's take a closer look. It says Itinerary.exampleTripToJapan. Now what is this? So you can command click on this or head over to models folder, click on itinerary and scroll down and you'll see that example trip to Japan is defined right here. The first thing that you'll notice that this is not a big string that includes an example. This is actually an instance of the itinerary generable with all its properties populated. You'll see that we have a title, a destination name, description, rationale, days, and all the properties manually populated for you. We can head back to our playground and you'll see that we do have an output here and this output will include the additional information that we provided as a one-shot example in order to guide the tone and quality of the response.

The most important part is that we are embedding this itinerary.exampleTripToJapan directly into the prompt. This is our golden example. We're also telling the model explicitly, don't copy its content. We wanted to learn from the style and structure and not just repeat the data. Let's head back now to our guide.

We're now in the app section of chapter 3. We'll now integrate this one-shot prompting approach into the app. The code change we'll need to make is to update the prompt in our itinerary generator in the ViewModels folder and include our example. Let's go make this code change. We are back in our Xcode. I'm going to click on View Models and Itinerary Generator. I'm going to pull up my Find Navigator and click Section 3. You'll see the code change that we do need to make right here.

So within our Generate Itinerary function, we obviously define our prompt here and we're going to replace this prompt.

and I'm going to delete the previous prompt.

Again, just like what we used in the playground, we say let prompt equal to use a prompt builder API, pass this closure. This includes the same string that we previously had, but we also include this additional information whereby introduce Itinerary.exampleTripToJapan, which is of the type Itinerary. So not only does it include all the guidance, but also the schema that's part of this prompt now.

And because we made this change, we can get rid of this comment. And you'll notice that we made all the changes in chapter 3, which means we are ready to build and run this app. and take a look at the build app.

We can choose Serenity here, click on Generate Itinerary. We can ensure that the model will take the prompt, the instructions and the additional example, pass it to the model and generate our final output. There you go.

Okay, our app is working great. Let's close this and head on over to our slides. So in this chapter, we focused on prompting techniques. We learned how to use a prompt builder to construct prompts dynamically and saw how you can use one-shot prompting to improve the quality and consistency of the model's output. We then applied this by updating our app to include a detailed example in our prompt. While @Generable enforces the structure, the one-shot example teaches the model about relationship and the style within the structure.

The model also uses the provided example for the desired tone of voice, ensuring that the generated text aligns with the tone you want to set for the app.

While the difference in output may not always be dramatic, it's an important way to significantly improve the quality of your generated content. And that wraps up our section on prompting techniques.

This is a great place to pause. Let's take a quick 10 minute break. Feel free to use this time to catch up on the code, grab a coffee or stretch your legs. When we get back, we have some really exciting topics ahead. We'll make a UI update in real time with streaming, extend the model's capabilities with tool calling and wrap up with performance optimizations. We'll be back in 10 minutes. See you soon.

Welcome back everyone. I hope you had a great break. Let's keep going. With our high quality prompts in place, let's enhance the user experience by streaming the response in real time. In this chapter, we'll focus on refactoring our itinerary generator to use the streaming API to improve the user experience by streaming the model's response. We'll see how to handle partially generated content as the model is generating the response. We'll then update our view to render the itinerary as it's being generated, providing for a much responsive feel. So let's head on over to our guide. We're now in chapter four, streaming responses. Our goal in this chapter is to dramatically improve the user experience by streaming responses and showing the itinerary as it is being generated. We'll start by updating the itinerary generator file. This section doesn't include a playground component because it's easy to appreciate the streaming responses directly in the app. So let's head on over to our Xcode and open up itinerary generator.

We'll again use our find navigator, update to chapter four and take a look at all the code changes we need to make starting with itinerary. The first change we'll need to make is update our itinerary variable to be of the type Itinerary.partiallyGenerated.

So what is partiallyGenerated? Think of this as a mirror version of our struct where every single property is an optional. @Generable defines this automatically for us. It's a perfect way to represent data that arrives over time. So that is the first code change. I'm going to remove the comment here.

And the next code change we'll need to make is down here. So recall, our generate itinerary function included this async call to Session.respond, we passed our prompt, and then we passed our generable, and then we received our output. What we want instead is the model to generate responses and stream the responses to us. So what we are going to do is replace this code with a new API called Session.streamResponse. Let's take a look.

So we replaced Session.response with Session.streamResponse and kept the rest of the argument same. So you still pass in a prompt, you still provide the generating argument with the itinerary. But we don't have an await here. What we get instead is an async sequence called stream, which means we can then loop over it and assign all the outputs to our itinerary, which includes all these options. So we say try await partial response in stream, and we can extract it using partialresponse.content where you'll get a snapshot every time of whatever has been generated at that point in time. Because we made this code change, I'm going to remove this comment as well.

Okay, that includes all the code changes we need to make to our itinerary generator. So let's head on over to our Code Along Guide and move on to section 4.2. Now we are ready to update our views. Since partially generated fields are optionals, we can use if let statements to safely unwrap these options. And that is what we are going to do in this section. So we'll update our itinerary view, which we previously just got a preview in an earlier chapter, but now we are going to actually go make code changes to this. So let's head on over to Xcode, click on the views folder and click on itinerary view.

Okay, at the very top, you'll notice that we have itinerary, so we should also update this with the partially generated type that we also defined in our view model. And we need to make this code change to all the generables that we have here. So not only itinerary, but all the nested generables too. So if you scroll all the way down, if you recall, we have our day view, which includes a day plan, which should also be partially generated. And each time I make this code change, I'm going to remove these comments and further down, you'll also remember we have our activity array, and we are going to do the same to that.

Okay, so that is the primary code change to the generables. Let's go back all the way up to the top and you'll see Xcode is complaining about a few other things. So the other code change we'll need to make is, if you recall, I said these are optional, so we have to unwrap them. So let's go and do that.

So here is what I did. I said if let title equal to itinerary.title, If let is a great way to deal with these optionals. And because I have a title here, I don't need to extract it from itinerary. So I remove that. So that takes care of title. Now I need to repeat the same step for our description.

I use if let and update the text view to include description.

And then I need to repeat this again for rationale.

And I need to do this again for the other fields, which is days.

Okay, so you get the gist. So we have to keep doing this for all the itinerary fields that properties that we are accessing to safely unwrap them. Now I'm going to do something that I've been asking all of you to do all this while, which is go back to our Code Along Guide here and copy the completely updated file and paste it here because we have to do this for every single property. If you scroll here, you see in step three, we says repeat this for all these properties. So we changed title description rationale, but you have to do this for all the day plan and the activity views too. So instead, what I'm going to do right now in this code along is click on the show updated views, which includes all the code changes. So what I'm going to do is click on this copy button on the top right and go back to our Xcode itineraryview.swift file and just replace all the code with the updated code. And you can see in our find navigator that we don't have any more comments so we've made all the code changes. So I showed you a few different code changes that we need to make but you have to do the same for every single property. So that concludes all the code changes for chapter 4. So to quickly recap, we spoke about the changes we need to make to view model, which is used partially generated, and we updated our views to unwrap these options. So we're now ready to run this app. Click on run, it will build and run this app. And we have our app right here. I'm going to click on Sahara Desert here and click generate itinerary. Unlike previously where it was an async call, now we are able to stream responses as it is being generated. This has great user experience because someone using the app can start consuming this content even before all of the itinerary has been loaded.

Awesome. In this chapter, we made a big leap in user experience. We refactored our app to use a streaming API and learn how to work with partially generated content in our view model. And finally, we updated our view to display the itinerary as it is being generated in real time. That wraps up chapter four on streaming responses. Now our app is looking great but let's make it even smarter by giving the model new capabilities with tool calling. First let me introduce the concept of tool calling. In addition to what you provide to the prompt the model brings its own core knowledge from its training data but remember the model is built into the OS and its knowledge is frozen in time. So For example, if you ask it about weather in Cupertino right now, there's no way for it to know what that information is. To handle cases where you need real time or dynamic data, the framework supports tool calling. Here's how it works. We have a session transcript.

If you provided tools to the session, the session will present the tool definition to the model along with the instructions. In our example, the prompt tells the model which destination we want to visit.

Now, if the model decides that calling a tool can enhance the response, it will produce one or more tool calls. In this example, the model produces two tool calls, querying restaurants and hotels.

At this phase, the Foundation Models Framework will automatically call the code you wrote for these tools. The framework then automatically inserts the tool outputs back into the session transcript.

Finally, the model will incorporate the tool output and everything else in the transcript into the final response.

As we've seen so far, the model can be very creative, often giving a slightly different itinerary each time we make a request. While this randomness is great for creativity, it can be a challenge when we need predictable For an advanced feature like tool calling, especially when testing and debugging, we need to ensure that the model behaves consistently. We want to guarantee that it will call our tool when we expect it to. To achieve this, we are going to make another small change to our request using generation options API to use greedy sampling. Greedy sampling tells the model to stop being creative and to always pick the most obvious next token. This makes the models output deterministic. For our app, this ensures that the model will reliably call our tool every single time.

In this chapter, we'll take a look at a tool that can find points of interest. We'll then provide this tool to our language model session and instruct the model how to use it.

Back in the app, we'll integrate this tool into our itinerary generator to get real world data into our itineraries. Let's head on over to our Code Along Guide. We are now in chapter five, tool calling.

Our itinerary contains model generated hotel and restaurant names, and these may not be up to date. Our goal is to give the model a tool it can use to call a Swift code and fetch hotel and restaurant names that we've provided.

Let's go make these code changes to first build a tool and later use this tool in our app. I'll head on over to Xcode and click on our ViewModels folder and you'll see a new file here that says Find Points of Interest Tool.

Click on that. So here we have a class called Find Points of Interest Tool that conforms to the tool protocol, which means we have to define a few properties here that will go through step by step. So let's start making these code changes and I'll explain what is going on. The first change we'll need to make is to add a name and description for our tool. So I'm going to do that here.

So we provide our tool with a name which is find points of interest and a description which is find points of interest for a landmark. This is critical for the model to understand when to invoke this tool. So it will use the name and the description to determine when to invoke this tool. The next change we'll need to make is down here where let me pull up our find navigator so we can see all the code changes that we need to be making. Next code change we need to make here is to define the categories that the tool can search for points of interest for and we'll do that by introducing this generable enum. So The category is an enum that includes hotels and restaurants. This can of course include other cases like museums or campgrounds and others. We're going to use this in our next code chain which is to update our arguments.

Here we have an argument struct here. Let's update this and I'll talk about what this does.

the argument struct, I have a property here that says let point of interest and it is of type category which is something we just defined. So this point of interest could be a hotel or a restaurant and we also provide a guide. The guide has a description that says this is the type of destination to look for. So this argument is the contract between the tool and the model. When the model wants to invoke the tool, it will pass this argument to the tool so that the tool has access to whether it's a hotel or a restaurant that it wants the response from the tool, the category that it wants the response from the tool.

We've updated the argument. And now we're going to update our call function right here.

This function is the heart of our tool. It receives the arguments, performs an action, and returns an output that gets added back into the session's transcript for the model to see and use. So let's make this change.

Okay. And I'll go through step by step what's going on here.

First, I say let results equal to await get suggestions. We have not defined this. We'll define this in a moment. Essentially, think of this as a function that the call method can invoke in order to get these specific points of interest. And then the results will be part of the output here, which you can then, as you see in the return statement, we can insert this result as a string output back to be provided back to the model. The model then uses that information along with the prompts and instructions to generate the final response. So, the last code change we need to make, of course, is to define this function. I have a placeholder function here called getSuggestions. Let's update this.

All right. So within getSuggestions, I have a switch block here which takes in a category and then if it's a restaurant, it can return restaurant1, restaurant2 or restaurant3. Similarly, if it's a hotel, it can return hotel one, hotel two, or hotel three. Now, these are, for this demo, we are using hardcoded data. In a real app, this is where you would call APIs like MapKit or a server-side API to fetch real live data.

Okay, so we made all the code changes to our tool, which means we have fully defined our tool. Let's head on over back to our Code Along Guide and move on to section 5.2.

So what we're going to do now is test this tool. So we'll head on over to our playground and provide this tool to the model and take a look at the results. Again, like before, feel free to copy paste this and I'm going to step through each of these lines of code and explain what exactly is happening. So back in our Xcode, I'm going to switch over to Playground.swift file. And for this section, I'm going to just clean up the previous code and start from scratch.

Okay, so we have our empty playground here.

First, I'm going to add instructions.

Here, a neat feature of playground is that it has access to all the data structures in your Xcode project. without having to build the app. So what I'm doing here is create a landmark variable that has access to the model data defined here under the models folder under model data dot Swift and I say model data dot landmark zero which means I'm going to access one of those landmarks that you see specifically we are going to access the first landmark and if you recall that is Sahara Desert. So you have access to the same list of landmarks that you get when you run the app. So we take that and then we just defined this Find Points of Interest tool right here in the ViewModels folder. So we are going to create an instance of this tool and we can pass it the landmark because it uses that information. And finally, we have our instructions just like before. There are two minor code changes if you look carefully. One, it's no longer a string but instruction builder similar to prompt builder wherein we pass in a closure and provide our instructions. And the second key change you'll notice, very important for tool calling, is we say always use the find points of interest tool to find hotels and restaurants in this landmark. Now this instruction is telling the model that it must invoke this tool in order to get the points of interest response. Now we'll create a language model Session. Similar to previous code change, we said language model session and pasta instruction, but we do introduce a new argument called tools. Here tools can be an array of tools. We have only one tool here which is point of interest tool. Since it's an array, you can provide multiple tools so the model can reason about your prompts and instructions and decide which tool to call when and get back the response. So we've included our tool in our session. Next, we define a prompt. There are no changes to the prompt itself here. And finally, We will invoke the model.

No code changes here too, except we do introduce options that we briefly discussed in the slide. This generation option with sampling set to greedy will ensure that we always get consistent, repeatable and deterministic output given that the rest of the prompts and instructions are consistent. Okay, let's take a look at the canvas here and take a look at the output. Okay, we have our response generated and we have our content here.

So we have our title, description, rationale, days. Let me pick one of these days, day 0, arrival and let me take a look at the activities.

I'll open up activity 0, activity 1, and activity 2.

Now if you look closely, you'll see here under activity 1 description it says, "Enjoy a traditional Moroccan dinner at restaurant 1." You'll also see this in the title, "Dine-in at restaurant 1." And similarly, you see title for activity 2 here that says, "Stay in hotel 1 and unwind at hotel 1." This is the output of the tool that is being inserted into the output of the model. So the model took in a prompt instructions, the landmark name, invoke the tool, got back the hotel and restaurant names and inserted it back to the transcript and generated this response.

Let's take a look at the transcript itself.

So what I'm doing here is just creating a temporary variable for the session itself and capturing it into inspect session. The reason I'm doing this is to take a closer look at the session and transcript and we can see the tool calls being placed. Okay. So we have our inspect session, which we just created.

Now we are going to take a look at these properties. you see tools. It has one tool that we provided. And if you look at transcript, it has six elements in this entries. And here we have our instructions, which is always the very first entry in the transcript. And then we have a prompt, which is our initial request. And then we have tool calls. The model autonomously decided that it needs to call our tool. Then we have our tool outputs. The framework executed our tool and inserted these tool outputs back into the transcript. And then finally we have our response. The model synthesized the original prompt, the tool output data to generate this final response. There are two tool calls here because we are requesting for both restaurants as well as hotels. And you'll see this under the tool calls. So there's a request for a restaurant and a hotel.

Awesome. Let's head back to our Code Along Guide.

So now that we know how a tool works, we defined the tool, we tested the tool in our playground, We're now ready to update our itineraryGenerator.swift file to incorporate our tool into the app. That's what we'll do in section 5.3. We'll make our code changes to itineraryGenerator.swift. Feel free to copy and paste this into your files. The key changes as you see here we'll be making is to update our instructions, create an instance of tool, and also pass it to our language model session. Let's head on over to Xcode and open up our itineraryGenerator.swift. I'll also bring up my find navigator, set this to chapter 5 and we'll start making code changes.

So the first change we need to do is of course update our instructions.

I'm going to delete the previous instructions because I have this new instructions which includes point of interest tool that we defined and this additional text that is asking the model to call this tool in order to get the points of interest. And we also of course need to update the language model session using the tools argument. And since it can accept multiple tools it is an array and and we'll pass in the tool.

Okay, so that is the two code changes that we need to make in our initializer. And we did that, so I'm gonna get rid of these comments so we can track our changes. Okay, the final change we need to make is in the generate itinerary method here.

Recall, we mentioned that if we want get deterministic outputs, we can use greedy sampling. By default, it does random sampling. So right here, after in this session.stream response, after we pass the prompt, after we pass the generating argument, we can pass our options. Let me clean this up so it's easy for everyone to read.

All right, so we have our Session.streamResponse, we have a prompt, we have our generating argument, and finally we have our options which includes generation options and we use sampling and set it to greedy. Okay, so that concludes all the code changes that we need to make. Let's ensure we get rid of this comment.

There you go. If you don't see anything for chapter 5 in your Find Navigator, that means we've made all the code changes, we are ready to build and run this app.

Click on the run button, this will build and run this app.

And here is our app. Let's go through the standard user flow, which is click on Sahara Desert. I see a generate itinerary button. I click on that. Now this includes a streaming API along with our tools and it takes our instructions, our prompts, sends it to the model along with the tool definition. And as you see here, you can see stay at hotel one and dine in at restaurant one. These were responses from the tool that were inserted back into the session transcript and the model used all the information from the instructions, the prompts, the tool calls, The tool responses, package all of it, synthesized it, and is able to generate the output in the format of the generable, itinerary generable.

Fantastic. All right, let's go back to our slides and recap. So in this chapter, we gave the model powers with tool calling. We discussed a custom tool with its own arguments and call function. We learned how to provide the tool to the language model session, and importantly, how to instruct the model on when and how to use the tool. Finally, we integrated our tool into the app to fetch points of interest and include them in the generated itinerary. That wraps up chapter five on tool calling.

Before we wrap up this code along, let's look at a couple of key techniques to optimize performance and make our generative features feel more responsive.

Let's head on over to a Code Along Guide and move on to chapter six, Performance and Optimization.

Our app is now feature complete, but to make our app performant, we first need to understand where the bottlenecks are. We can't optimize what we can't measure. For this, we will use a powerful developer tool called Instruments.

Let's head on over to Xcode.

We'll do something slightly different now. If you long press on the run button here, you'll see a few different options. You see run, test, profile and analyze. So I'm going to click profile. What this does is it'll build the app and then launch up Xcode instruments.

Let's wait for it to finish building and there it is. So this is Xcode Instruments. We'll choose the blank template and then once you have your instruments open, I'm going click on this plus symbol here and search for foundation models. Okay, we are now ready to profile our app. I'm gonna click on the record and this will launch our app and we will use this app like we usually do. So as a user, Sahara Desert looks interesting. I read the title description, looks good. I click on generate itinerary and I see this nice itinerary come up. The results are being streamed to me. I can read through this, take a look at all the different activities that plan. Okay, I'm going to stop recording. Now let's take a closer look at what we have here in the instruments. Okay, there are a few different tracks here and I'll explain what is going on in each of these to identify any potential bottlenecks that we can address. First track here is response. The blue bar here represents entire session. So this is ever since the user clicks on generate itinerary, we create a session and the model takes in the instructions, prompts and generates output. All of this is represented by this blue bar. The second row here is asset loading. Here if you take a closer look, you'll see that once the session starts, there is a little bit of a delay and then the models are loaded here, the model assets, which means all this time from the start of the session all the way to end of loading the model, the model is not generating any responses and roughly looks like this is about 700 milliseconds, which is almost a full second, right? And then if you look at the third track, this is where you see that the first token is generated, which means it waits for all the the models to be loaded and then it starts the token generation process, starting with the first token and continues to generate all the responses. So there is an opportunity for performance improvement here. If we could load these assets ahead of time, maybe we could start this generation process as soon as the session starts.

So that is one bottleneck we can try and address. The second bottleneck, if you look at the bottom here, I'm going to choose the inference section here. If you take a closer look, you will see here that there is max token count. And we see here that this currently amounts to 1044. And this token count includes everything we've added into the session. This includes your instructions, your prompts, your tools. It includes the generables with the itinerary, all of it. So it includes all of this here and we can see if there's an opportunity to reduce this because the number of tokens has an implication on the model's performance. So that is a second bottleneck that we can see if we can try and address.

Okay. If you recall, when we call Session.respond, the OS will load the model if it's not already in memory.

pre-warming can give your session a head start by loading the model before you even make a request. In our app, when someone taps on the landmark, it's pretty likely that they are going to make a request soon. We can pre-warm before they press the generate itinerary button to proactively load the model. By the time they finish reading the description, our model will be ready to go.

Let's also look at another optimization that can reduce request latency. Recall that generable structs provided to the model can help generate structured outputs, but this comes at the cost of increased token count, which affects initial processing time. Also recall that in Chapter 3, we passed an example itinerary called example trip to Japan. Since our instructions includes this full example of the generable schema, we can often exclude the schema definition itself from the front, which saves space and can speed up the model.

Thanks to Xcode instruments, we've identified the bottlenecks in our app. Now, we'll implement some optimizations directly in the app. First, we'll pre-warm the session by calling the pre-warm method when the user taps on the landmark. This does the framework to start loading the model before the user even asks for the itinerary. Second, because our one-shot example is quite detailed, the full schema definition in the prompt is redundant. We can remove it by setting include schema and prompt to false. In our stream response call, we'll make this change. This will significantly reduce our input token count. Let's head on over to our Code Along Guide and take a look at the code changes we'll be making. We're now in chapter 6, the app section. The first part is to pre-warm the model and the code changes will be reflected in the itinerary generator where we'll add a function to pre-warm and then in the view as well so that we can call the pre-warm method when the view is loaded. So let's go make these changes in itinerary generator and landmark trip view. Let's head on over to Xcode. I'll keep the instrument open because I do want to check the effect of these optimizations. So I'm going to go to Xcode, click on itinerary generator. This is already open for us. And I'm going to use the find navigator to open chapter 6.

Okay.

The first change we'll make to PREWARM is to add the PREWARM code here. We've defined this placeholder function called PREWARM model. So all I'm going to do here is call the pre-womp method in the session.

It's as easy as that.

Now we have a function that we can invoke from our view that will pre-womp the model. If you ahead of time know what the prompt is going to be, you can also use a prompt prefix to update a pre-womp method.

So inside a Session.prewarm function, there is an optional argument called prompt prefix where you can provide a prompt so the model has knowledge of the prompt that the user might provide and it can prewarm using this. So here we pass a prompt with a closure that says generate a three-day itinerary to landmark.name. This can further improve performance.

Okay, the next code change we need to make is actually in landmark trip view. So in our views folder, we have our landmark trip view.

Here, we need to update our task in order to call the pre-warm method when the model is actually loaded. So let's do this here.

Again, this is as simple as calling the generator.prewarmModel function that we just defined. So that includes all the code changes for prewarming the model. Let's head back to our Code Along Guide and take a look at the second optimization that we discussed, which is to reduce the max token count. So we're now in section 6.2, where we'll optimize the prompt.

The code change we'll need to make here is again in itinerary generator. So we'll include this additional argument called include schema in prompt and set it to false. Let's make this change and I'll briefly again explain what is going on.

So back to our itinerary generator.

Here we have our Session.stream response where we pass in the prompt, the generable, and options. So we'll also include our new argument called include schema in prompt and set it to false. Now what this tells the model is that we can exclude the schema of the itinerary that we pass because we are already passing the example trip to Japan in instruments, which includes the golden example along with the structure. So we can skip including the schema which will help in reducing the maximum token count. Because we made this change, I'm going to get rid of this comment too.

Okay, that concludes all the changes in chapter 6, which means we are now ready to profile the app once again. Okay, let's do this again. So I'm going to click on the profile option again and again this will build the app and launch up our profiler in a moment.

You see Xcode is building, launched up our profiler again. Now when I record it will relaunch the app and we'll go through the same process again of using the app. Click record. I have my app here. I'm going to follow the same exact steps. I'm going to click on Sahara Desert. I'll read the title. The description looks good to me. I want to generate the itinerary and I see the itinerary being generated. Looks good. We have our day-by-day plan, what restaurants to eat in, what hotels to stay. We'll let it finish executing and I'm going to stop profiling. Let's do the same thing we did previously and take a look at the output and see what effect our optimizations have had on the app. The very first thing you should notice is that asset loading happened well before the session started thanks to our pre-warm function. So we loaded this asset at this point when the user clicked on the detail view we called the pre-warm method by adding the pre-warm function in the task which means by the time the user used to read the title and description, the model was already loaded and ready. And if you take a closer look at the start of the session here, you'll see that the output starts generating almost as soon as the session started. So the session started because the model has already been loaded. It starts to prepare the vocabulary, it starts generating the tokens and your responses are now much quicker. Let's also take a look at the second optimization that we did and what effect it has had. So down here under inference you'll see the maximum token count has dropped to 700. Previously it was 1000 so we have dropped the maximum token count to 700 by excluding the schema from the prompt. Now this also means that the model is able to much quickly process the initial token and start generating responses a lot quicker. Awesome. So in this last chapter we looked at performance. We learned how to pre-warm the model to make our app feel more responsive and how to optimize a prompt by excluding the schema when it's not needed. These are two simple but effective ways to improve the performance of your generative features. Now let's take one final look at that app we've built together. Let's go back to Xcode and build and run. Okay, so this should look familiar to you as it's the app running on your machine. We started with this simple Swift list of landmarks and when we select Serengeti here we see this detail view. Now let's tap on generate itinerary one last time.

The UI builds itself in real time. That's the streaming API from chapter four using Session.stream response and partially generated content. In chapter two, we used add generable to get this rich structured response. And in chapter five, we use tool calls to find these points of interest, which the model intelligently decided to call to get this data.

Okay, we've covered a lot today from basic text generation to guided generation, streaming, tool calling, and performance optimizations, but there's still more to explore. We didn't have time to cover some advanced topics such as training custom model adapters, dynamic runtime schemas, or diving into guardrails and error handling. To learn more about these topics, I highly recommend watching other WWDC25 videos on the Foundation Models Framework.

Looking at Slido, there are a lot of great questions here and if we didn't get to yours, please bring them to the developer forums at developer.apple.com/forums where we can continue this discussion. The completed sample project from today, including few additional features is available for download in the Foundation Models Framework documentation. Finally, you'll receive a survey later today. We hope you enjoyed the session and we'd appreciate your feedback. With that, thank you so much for coding along with me. We'll see you again soon. Bye.
--- END FILE ---

--- FILE: GenerationOptions.md ---
# GenerationOptions

**Options that control how the model generates its response to a prompt.**

## Availability

- **iOS** 26.0+
- **iPadOS** 26.0+
- **Mac Catalyst** 26.0+
- **macOS** 26.0+
- **visionOS** 26.0+


## Overview

Create a [doc://com.apple.foundationmodels/documentation/FoundationModels/GenerationOptions](https://developer.apple.com/documentation/FoundationModels/GenerationOptions) structure when you want to adjust the way the model chooses output tokens.

## Topics

### Creating options

- [init(sampling:temperature:maximumResponseTokens:)](https://developer.apple.com/documentation/foundationmodels/generationoptions/init(sampling:temperature:maximumresponsetokens:)) — Creates generation options that control token sampling behavior.
### Configuring the response tokens

- [maximumResponseTokens](https://developer.apple.com/documentation/foundationmodels/generationoptions/maximumresponsetokens) — The maximum number of tokens the model is allowed to produce in its response.
### Configuring the sampling mode

- [sampling](https://developer.apple.com/documentation/foundationmodels/generationoptions/sampling) — A sampling strategy for how the model picks tokens when generating a response.
- [GenerationOptions.SamplingMode](https://developer.apple.com/documentation/foundationmodels/generationoptions/samplingmode) — A type that defines how values are sampled from a probability distribution.
### Configuring the temperature

- [temperature](https://developer.apple.com/documentation/foundationmodels/generationoptions/temperature) — Temperature influences the confidence of the models response.

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/GenerationOptions](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/GenerationOptions)*
--- END FILE ---

--- FILE: Instructions.md ---
# Instructions

**Details you provide that define the model’s intended behavior on prompts.**

## Availability

- **iOS** 26.0+
- **iPadOS** 26.0+
- **Mac Catalyst** 26.0+
- **macOS** 26.0+
- **visionOS** 26.0+


## Overview

Instructions are typically provided by you to define the role and behavior of the model. In the code below, the instructions specify that the model replies with topics rather than, for example, a recipe:

```swift
let instructions = """
    Suggest related topics. Keep them concise (three to seven words) and make sure they \
    build naturally from the person's topic.
    """

let session = LanguageModelSession(instructions: instructions)

let prompt = "Making homemade bread"
let response = try await session.respond(to: prompt)
```

Apple trains the model to obey instructions over any commands it receives in prompts, so don’t include untrusted content in instructions. For more on how instructions impact generation quality and safety, see [doc://com.apple.foundationmodels/documentation/FoundationModels/improving-the-safety-of-generative-model-output](https://developer.apple.com/documentation/FoundationModels/improving-the-safety-of-generative-model-output).

## Topics

### Creating instructions

- [init(_:)](https://developer.apple.com/documentation/foundationmodels/instructions/init(_:))
- [InstructionsBuilder](https://developer.apple.com/documentation/foundationmodels/instructionsbuilder) — A type that represents an instructions builder.
- [InstructionsRepresentable](https://developer.apple.com/documentation/foundationmodels/instructionsrepresentable) — A type that can be represented as instructions.

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/Instructions)*
--- END FILE ---

--- FILE: Generable.md ---
# Generable

**A type that the model uses when responding to prompts.**

## Availability

- **iOS** 26.0+
- **iPadOS** 26.0+
- **Mac Catalyst** 26.0+
- **macOS** 26.0+
- **visionOS** 26.0+


## Overview

Annotate your Swift structure or enumeration with the `@Generable` macro to allow the model to respond to prompts by generating an instance of your type. Use the `@Guide` macro to provide natural language descriptions of your properties, and programmatically control the values that the model can generate.

```swift
@Generable
struct SearchSuggestions {
    @Guide(description: "A list of suggested search terms", .count(4))
    var searchTerms: [SearchTerm]

    @Generable
    struct SearchTerm {
        // Use a generation identifier for data structures the framework generates.
        var id: GenerationID

        @Guide(description: "A 2 or 3 word search term, like 'Beautiful sunsets'")
        var searchTerm: String
    }
}
```


> **NOTE**: `@Generable` macro [doc://com.apple.foundationmodels/documentation/FoundationModels/Generable(description:)](https://developer.apple.com/documentation/FoundationModels/Generable(description:)) and  `@Guide` macro [doc://com.apple.foundationmodels/documentation/FoundationModels/Guide(description:)](https://developer.apple.com/documentation/FoundationModels/Guide(description:)).


## Topics

### Defining a generable type

- [Generable(description:)](https://developer.apple.com/documentation/foundationmodels/generable(description:)) — Conforms a type to [doc://com.apple.foundationmodels/documentation/FoundationModels/Generable](https://developer.apple.com/documentation/FoundationModels/Generable) protocol.
### Creating a guide

- [Guide(description:)](https://developer.apple.com/documentation/foundationmodels/guide(description:)) — Allows for influencing the allowed values of properties of a [doc://com.apple.foundationmodels/documentation/FoundationModels/Generable](https://developer.apple.com/documentation/FoundationModels/Generable) type.
- [Guide(description:_:)](https://developer.apple.com/documentation/foundationmodels/guide(description:_:)) — Allows for influencing the allowed values of properties of a [doc://com.apple.foundationmodels/documentation/FoundationModels/Generable](https://developer.apple.com/documentation/FoundationModels/Generable) type.
- [GenerationGuide](https://developer.apple.com/documentation/foundationmodels/generationguide) — Guides that control how values are generated.
### Getting the schema

- [generationSchema](https://developer.apple.com/documentation/foundationmodels/generable/generationschema) — An instance of the generation schema.
- [GenerationSchema](https://developer.apple.com/documentation/foundationmodels/generationschema) — A type that describes the properties of an object and any guides on their values.
### Generating a unique identifier

- [GenerationID](https://developer.apple.com/documentation/foundationmodels/generationid) — A unique identifier that is stable for the duration of a response, but not across responses.
### Converting to partially generated

- [asPartiallyGenerated()](https://developer.apple.com/documentation/foundationmodels/generable/aspartiallygenerated()) — The partially generated type of this struct.
- [PartiallyGenerated](https://developer.apple.com/documentation/foundationmodels/generable/partiallygenerated) — A representation of partially generated content
### Generate dynamic shemas

- [DynamicGenerationSchema](https://developer.apple.com/documentation/foundationmodels/dynamicgenerationschema) — The dynamic counterpart to the generation schema type that you use to construct schemas at runtime.

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/Generable](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/Generable)*
--- END FILE ---

--- FILE: FoundationModels-Using-on-device-LLM-in-your-app.md ---
# Foundation Models: Using Apple's On-Device LLM in Your Apps

## Overview

Foundation Models is an Apple framework that provides access to on-device large language models (LLMs) that power Apple Intelligence. This framework enables developers to enhance their apps with generative AI capabilities without requiring cloud connectivity or compromising user privacy.

Key capabilities include:
- Text generation and understanding
- Content summarization and extraction
- Structured data generation
- Custom tool integration

## Getting Started

### Check Model Availability

Always check if the model is available before attempting to use it. Model availability depends on device factors such as Apple Intelligence support, system settings, and device state.

```swift
struct GenerativeView: View {
    // Create a reference to the system language model
    private var model = SystemLanguageModel.default

    var body: some View {
        switch model.availability {
        case .available:
            // Show your intelligence UI
            Text("Model is available")
        case .unavailable(.deviceNotEligible):
            // Show an alternative UI
            Text("Device not eligible for Apple Intelligence")
        case .unavailable(.appleIntelligenceNotEnabled):
            // Ask the person to turn on Apple Intelligence
            Text("Please enable Apple Intelligence in Settings")
        case .unavailable(.modelNotReady):
            // The model isn't ready (downloading or other system reasons)
            Text("Model is downloading or not ready")
        case .unavailable(let other):
            // The model is unavailable for an unknown reason
            Text("Model unavailable: \(other)")
        }
    }
}
```

### Create a Session

After confirming model availability, create a `LanguageModelSession` to interact with the model:

```swift
// Create a basic session with the system model
let session = LanguageModelSession()

// Create a session with instructions
let instructions = """
    You are a helpful assistant that provides concise answers.
    Keep responses under 100 words and focus on clarity.
    """
let sessionWithInstructions = LanguageModelSession(instructions: instructions)
```

- For single-turn interactions, create a new session each time
- For multi-turn interactions, reuse the same session to maintain context

## Basic Usage

### Provide Instructions to the Model

Instructions help steer the model's behavior for your specific use case. The model prioritizes instructions over prompts.

Good instructions typically specify:
- The model's role (e.g., "You are a mentor")
- What the model should do (e.g., "Help extract calendar events")
- Style preferences (e.g., "Respond as briefly as possible")
- Safety measures (e.g., "Respond with 'I can't help with that' for dangerous requests")

```swift
let instructions = """
    You are a cooking assistant.
    Provide recipe suggestions based on ingredients.
    Keep suggestions brief and practical for home cooks.
    Include approximate cooking time.
    """

let session = LanguageModelSession(instructions: instructions)
```

### Provide a Prompt to the Model

A prompt is the input that the model responds to. Effective prompts are:
- Conversational (questions or commands)
- Focused on a single, specific task
- Clear about the desired output format and length

```swift
// Simple prompt
let prompt = "What's a good month to visit Paris?"

// Specific prompt with output constraints
let specificPrompt = "Write a profile for the dog breed Siberian Husky using three sentences."
```

### Generate a Response

Call the model asynchronously to get a response:

```swift
// Basic response generation
let response = try await session.respond(to: prompt)
print(response.content)

// With custom generation options
let options = GenerationOptions(temperature: 0.7)
let customResponse = try await session.respond(to: prompt, options: options)
```

Note: A session can only handle one request at a time. Check `isResponding` to verify the session is available before sending a new request.

## Advanced Features

### Guided Generation

Guided generation allows you to receive model responses as structured Swift data instead of raw strings. This provides stronger guarantees about the format of the response.

#### 1. Define a Generable Type

```swift
@Generable(description: "Basic profile information about a cat")
struct CatProfile {
    // A guide isn't necessary for basic fields
    var name: String

    @Guide(description: "The age of the cat", .range(0...20))
    var age: Int

    @Guide(description: "A one sentence profile about the cat's personality")
    var profile: String
}
```

#### 2. Request a Response in Your Custom Type

```swift
// Generate a response using the custom type
let catResponse = try await session.respond(
    to: "Generate a cute rescue cat",
    generating: CatProfile.self
)

// Use the structured data
print("Name: \(catResponse.content.name)")
print("Age: \(catResponse.content.age)")
print("Profile: \(catResponse.content.profile)")
```

#### 3. Printing a Response from your Custom Type

When printing values from a LanguageModelSession.Response always use the instance property content. Not output.

For example:

```swift
import FoundationModels
import Playgrounds

@Generable
struct CookbookSuggestions {
    @Guide(description: "Cookbook Suggestions", .count(3))
    var suggestions: [String]
}

#Playground {
    let session = LanguageModelSession()

    let prompt = "What's a good name for a cooking app?"

    let response = try await session.respond(
        to: prompt,
        generating: CookbookSuggestions.self
    )

    // Notice how print values come from content. Not output.
    print(response.content.suggestions)
}
```

### Tool Calling

Tool calling allows the model to use custom code you provide to perform specific tasks, access external data, or integrate with other frameworks.

#### 1. Create a Custom Tool

```swift
// Define a tool for searching recipes
struct RecipeSearchTool: Tool {
    struct Arguments: Codable {
        var searchTerm: String
        var numberOfResults: Int
    }
    
    func call(arguments: Arguments) async throws -> ToolOutput {
        // Search your recipe database
        let recipes = await searchRecipes(term: arguments.searchTerm, 
                                         limit: arguments.numberOfResults)
        
        // Return results as a string the model can use
        return .string(recipes.map { "- \($0.name): \($0.description)" }.joined(separator: "\n"))
    }
    
    private func searchRecipes(term: String, limit: Int) async -> [Recipe] {
        // Implementation to search your database
        // ...
    }
}
```

#### 2. Provide the Tool to a Session

```swift
// Create the tool
let recipeSearchTool = RecipeSearchTool()

// Create a session with the tool
let session = LanguageModelSession(tools: [recipeSearchTool])

// The model will automatically use the tool when appropriate
let response = try await session.respond(to: "Find me some pasta recipes")
```

#### 3. Handle Tool Errors

```swift
do {
    let answer = try await session.respond("Find a recipe for tomato soup.")
} catch let error as LanguageModelSession.ToolCallError {
    // Access the name of the tool
    print(error.tool.name) 
    
    // Access the underlying error
    if case .databaseIsEmpty = error.underlyingError as? RecipeSearchToolError {
        // Handle specific error
    }
} catch {
    print("Other error: \(error)")
}
```

## Snapshot streaming

- LLM generate text as short groups of characters called tokens.
- Typically, when streaming tokens, tokens are delivered in what's called a delta. But Foundation Models does this different.
- As deltas are produced, the responsibility for accumulating them usually falls on the developer
- You append each delta as they come in. And the response grows as you do. But it gets tricky when the result has structure.
- If you want to show the greeting string after each delta, you have to parse it out of the accumulation, and that's not trival, especially for complicated structures.
- Structured output is at the core of the Foundation Model framework. Which is why we stream snapshots.

## Snapshot streaming

- LLM generate text as short groups of characters called tokens.
- Typically, when streaming tokens, tokens are delivered in what's called a delta. But Foundation Models does this different.
- As deltas are produced, the responsibility for accumulating them usually falls on the developer
- You append each delta as they come in. And the response grows as you do. But it gets tricky when the result has structure.
- If you want to show the greeting string after each delta, you have to parse it out of the accumulation, and that's not trival, especially for complicated structures.
- Structured output is at the core of the Foundation Model framework. Which is why we stream snapshots.

### What are snapshots

- Snapshots represent partically generated response. Their properties are all optinoal. And they get filled in as the model produces more of the response.
- Snapshots are a robust and convenient representation for streaming structure output.
- You are already familar with the `@Generable` macro, and as it turns out, it's also where the definitions for partially generated types come from.
- If you expand the macro, you'll discover it produces a types named `PartiallyGenerated`. It is effectively a mirror of the outer structure except every property is optional.
- The partically generated type comes into play when you call the 'streamResponse` method on your session.

```swift
import FoundationModels
import Playgrounds

@Generable
struct TripIdeas {
    @Guide(description: "Ideas for upcoming trips")
    var ideas: [String]
}

#Playground {
    let session = LanguageModelSession()

    let prompt = "What are some exciting trip ideas for the upcoming year?"

    let stream = session.streamResponse(
        to: prompt,
        generating: TripIdeas.self
    )

    for try await partial in stream {
        print(partial)
    }
}
```

- Stream response returns an async sequence. And the elements of that sequence are instances of a partially generated type.
- Each element in the sequence will contain an updated snapshot.
- These snapshots work great with declarative frameworks like SwiftUI.
- First, create state holding a partially generated type.
- Then, just iterate over a response stream, stores its elements, and watch as your UI comes to life.

## Best Practices and Limitations

### Context Size Limits

- The system model supports up to 4,096 tokens per session
- A token is roughly 3-4 characters in languages like English
- All instructions, prompts, and outputs count toward this limit
- If you exceed the limit, you'll get a `LanguageModelSession.GenerationError.exceededContextWindowSize` error
- For large data processing, break it into smaller chunks across multiple sessions

### Optimizing Performance

- Use `GenerationOptions` to tune model behavior:
  ```swift
  let options = GenerationOptions(temperature: 2.0) // Higher temperature = more creative
  ```
- Use Xcode Instruments to monitor request performance
- Access `Transcript` entries to see model actions during a session:
  ```swift
  let transcript = session.transcript
  ```

### Prompt Engineering Tips

- Be specific about what you want
- Specify output constraints (e.g., "in three sentences")
- Break complex tasks into multiple simple prompts
- Use examples in instructions to guide the model's output format

## References

- [Generating content and performing tasks with Foundation Models](https://developer.apple.com/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models)
- [Generating Swift data structures with guided generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation)
- [Expanding generation with tool calling](https://developer.apple.com/documentation/FoundationModels/expanding-generation-with-tool-calling)
- [Human Interface Guidelines: Generative AI](https://developer.apple.com/design/human-interface-guidelines/technologies/generative-ai)
--- END FILE ---

--- FILE: Generating-Swift-data-structures-with-guided-generation.md ---
# Generating Swift data structures with guided generation

**Create robust apps by describing output you want programmatically.**


## Overview

When you perform a request, the model returns a raw string in its natural language format. Raw strings require you to manually parse the details you want. Instead of working with raw strings, the framework provides guided generation, which gives strong guarantees that the response is in a format you expect.

To use guided generation, describe the output you want as a new Swift type. When you make a request to the model, include your custom type and the framework performs the work necessary to fill in and return an object with the parameters filled in for you. The framework uses constrained sampling when generating output, which defines the rules on what the model can generate. Constrained sampling prevents the model from producing malformed output and provides you with results as a type you define.

For more information about creating a session and prompting the model, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models](https://developer.apple.com/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models).


## Conform your data type to Generable

To conform your type to [doc://com.apple.foundationmodels/documentation/FoundationModels/Generable](https://developer.apple.com/documentation/FoundationModels/Generable), describe the type and the parameters to guide the response of the model. The framework supports generating content with basic Swift types like `Bool`, `Int`, `Float`, `Double`, `Decimal`, and `Array`. For example, if you only want the model to return a numeric result, call [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/respond(to:generating:includeSchemaInPrompt:options:)-13kji](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/respond(to:generating:includeSchemaInPrompt:options:)-13kji) using the type `Float`:

```swift
let prompt = "How many tablespoons are in a cup?"
let session = LanguageModelSession(model: .default)

// Generate a response with the type `Float`, instead of `String`.
let response = try await session.respond(to: prompt, generating: Float.self)
```

A schema provides the ability to control the values of a property, and you can specify guides to control values you associate with it. The framework provides two macros that help you with schema creation. Use [doc://com.apple.foundationmodels/documentation/FoundationModels/Generable(description:)](https://developer.apple.com/documentation/FoundationModels/Generable(description:)) on structures, actors, and enumerations; and only use [doc://com.apple.foundationmodels/documentation/FoundationModels/Guide(description:)](https://developer.apple.com/documentation/FoundationModels/Guide(description:)) with stored properties.

When you add descriptions to `Generable` properties, you help the model understand the semantics of the properties. Keep the descriptions as short as possible — long descriptions take up additional context size and can introduce latency. The following example creates a type that describes a cat and includes a name, an age that’s constrained to a range of values, and a short profile:

```swift
@Generable(description: "Basic profile information about a cat")
struct CatProfile {
    // A guide isn't necessary for basic fields.
    var name: String

    @Guide(description: "The age of the cat", .range(0...20))
    var age: Int

    @Guide(description: "A one sentence profile about the cat's personality")
    var profile: String
}
```


> **NOTE**: The model generates `Generable` properties in the order they’re declared.


You can nest custom `Generable` types inside other `Generable` types, and mark enumerations with associated values as `Generable`. The `Generable` macro ensures that all associated and nested values are themselves generable. This allows for advanced use cases like creating complex data types or dynamically generating views at runtime.


## Make a request with your custom data type

After creating your type, use it along with a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession) to prompt the model. When you use a `Generable` type it prevents the model from producing malformed output and prevents the need for any manual string parsing.

```swift
// Generate a response using a custom type.
let response = try await session.respond(
    to: "Generate a cute rescue cat",
    generating: CatProfile.self
)
```


## Define a dynamic schema at runtime

If you don’t know what you want the model to produce at compile time use [doc://com.apple.foundationmodels/documentation/FoundationModels/DynamicGenerationSchema](https://developer.apple.com/documentation/FoundationModels/DynamicGenerationSchema) to define what you need. For example, when you’re working on a restaurant app and want to restrict the model to pick from menu options that a restaurant provides. Because each restaurant provides a different menu, the schema won’t be known in its entirety until runtime.

```swift
// Create the dynamic schema at runtime.
let menuSchema = DynamicGenerationSchema(
    name: "Menu",
    properties: [
        DynamicGenerationSchema.Property(
            name: "dailySoup",
            schema: DynamicGenerationSchema(
                name: "dailySoup",
                anyOf: ["Tomato", "Chicken Noodle", "Clam Chowder"]
            )
        )

        // Add additional properties.
    ]
)
```

After creating a dynamic schema, use it to create a [doc://com.apple.foundationmodels/documentation/FoundationModels/GenerationSchema](https://developer.apple.com/documentation/FoundationModels/GenerationSchema) that you provide with your request. When you try to create a generation schema, it can throw an error if there are conflicting property names, undefined references, or duplicate types.

```swift
// Create the schema.
let schema = try GenerationSchema(root: menuSchema, dependencies: [])

// Pass the schema to the model to guide the output.
let response = try await session.respond(
    to: "The prompt you want to make.",
    schema: schema
)
```

The response you get is an instance of [doc://com.apple.foundationmodels/documentation/FoundationModels/GeneratedContent](https://developer.apple.com/documentation/FoundationModels/GeneratedContent). You can decode the outputs from schemas you define at runtime by calling [doc://com.apple.foundationmodels/documentation/FoundationModels/GeneratedContent/value(_:forProperty:)-3xsez](https://developer.apple.com/documentation/FoundationModels/GeneratedContent/value(_:forProperty:)-3xsez) for the property you want.

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation)*
--- END FILE ---
=== END SWIFT DOCUMENTATION ===
=== END CONTEXT ===

=== BUILD ATTEMPT 4 FAILED ===
The previous implementation failed with the following errors:

Build failed but no detailed error log available.

=== INSTRUCTIONS FOR ATTEMPT 5 ===
1. Analyze what went wrong in the previous approach
2. Try a DIFFERENT approach or fix the specific issues
3. Do NOT repeat the same mistakes
4. If the same approach keeps failing, consider an alternative implementation strategy
5. Write the corrected code directly - do not explain, just implement

Please fix the issues and provide the corrected implementation.
mcp: xcodebuildmcp starting
mcp: xcodebuildmcp ready
mcp startup: ready: xcodebuildmcp

thinking
**Inspecting project structure**
exec
/bin/zsh -lc ls in /Users/emmanuel/Documents/Theory/Redefining_racism succeeded in 169ms:
Algo
Artifacts
README.md
Racism_is_an_engineering_problem.txt
Redefining_Racism.aux
Redefining_Racism.fdb_latexmk
Redefining_Racism.fls
Redefining_Racism.log
Redefining_Racism.out
Redefining_Racism.pdf
Redefining_Racism.synctex.gz
Redefining_Racism.tex
__Avenue
app
critique
swiftDocs
venn_diagram_1.png
venn_diagram_2.png
website

thinking
**Listing files in target directory**

I'm checking the files in the app/decodingOppression directory to identify where 'Item' might be defined or used.
exec
/bin/zsh -lc 'rg --files' in /Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression succeeded in 143ms:
decodingOppressionUITests/decodingOppressionUITestsLaunchTests.swift
decodingOppressionUITests/decodingOppressionUITests.swift
decodingOppressionTests/decodingOppressionTests.swift
decodingOppression.xcodeproj/project.xcworkspace/xcshareddata/swiftpm/Package.resolved
decodingOppression.xcodeproj/project.xcworkspace/xcuserdata/emmanuel.xcuserdatad/UserInterfaceState.xcuserstate
decodingOppression.xcodeproj/project.xcworkspace/contents.xcworkspacedata
decodingOppression.xcodeproj/xcuserdata/emmanuel.xcuserdatad/xcschemes/xcschememanagement.plist
decodingOppression.xcodeproj/project.pbxproj
decodingOppression/Info.plist
decodingOppression/ContentView.swift
decodingOppression/decodingOppressionApp.swift
decodingOppression/Data/KeywordTaxonomies.json
decodingOppression/Models/GenerableTypes.swift
decodingOppression/Models/PipelineContracts.swift
decodingOppression/Models/PolicyAnalysis.swift
decodingOppression/Models/Policy.swift
decodingOppression/Models/AnalyzedClause.swift
decodingOppression/Models/ScoreResult.swift
decodingOppression/Assets.xcassets/Contents.json
decodingOppression/Assets.xcassets/AccentColor.colorset/Contents.json

thinking
**Reviewing build failure causes**

I'm opening key files to check for compile errors and incorrect imports that might be causing the build to fail.
exec
/bin/zsh -lc "sed -n '1,200p' app/decodingOppression/decodingOppression/Models/Policy.swift" in /Users/emmanuel/Documents/Theory/Redefining_racism succeeded in 139ms:
//
//  Policy.swift
//  decodingOppression
//
//  Created by Emmanuel Theodore on 2/19/26.
//

import Foundation

// MARK: - Section type and targeting

enum SectionType: String, Codable, CaseIterable {
    case title
    case definitions
    case operativeClauses
    case penalties
    case exceptions
}

enum TargetGroup: String, Codable, CaseIterable {

thinking
**Verifying Codable compatibility**

Added Codable to structs despite original plan to restrict it to enums; checking if this causes build errors or conflicts with SwiftData, starting with ScoreResult.
exec
/bin/zsh -lc "sed -n '1,200p' app/decodingOppression/decodingOppression/Models/ScoreResult.swift" in /Users/emmanuel/Documents/Theory/Redefining_racism succeeded in 118ms:
//
//  ScoreResult.swift
//  decodingOppression
//
//  Created by Emmanuel Theodore on 2/19/26.
//

import Foundation

struct ScoreResult: Codable {
    var dis: Double
    var ads: Double
    var eis: Double
    var cis: Double
    var oes: Double
    var coi: Double

    static var zero: ScoreResult {
        ScoreResult(dis: 0, ads: 0, eis: 0, cis: 0, oes: 0, coi: 0)
    }

thinking
**Recognizing clause analysis**
exec
/bin/zsh -lc "sed -n '1,200p' app/decodingOppression/decodingOppression/Models/AnalyzedClause.swift" in /Users/emmanuel/Documents/Theory/Redefining_racism succeeded in 126ms:
//
//  AnalyzedClause.swift
//  decodingOppression
//
//  Created by Emmanuel Theodore on 2/19/26.
//

import Foundation
import SwiftData

@Model
final class AnalyzedClause {
    var id: UUID
    var text: String
    var sectionType: SectionType
    var targetGroup: TargetGroup
    var effectDirection: EffectDirection
    var confidence: Double
    var tierUsed: MLTier
    @Relationship(inverse: \PolicyAnalysis.clauses)
exec
/bin/zsh -lc "sed -n '1,200p' app/decodingOppression/decodingOppression/Models/PolicyAnalysis.swift" in /Users/emmanuel/Documents/Theory/Redefining_racism succeeded in 118ms:
//
//  PolicyAnalysis.swift
//  decodingOppression
//
//  Created by Emmanuel Theodore on 2/19/26.
//

import Foundation
import SwiftData

@Model
final class PolicyAnalysis {
    var id: UUID
    var policyName: String
    var sourceFilename: String
    var dateAnalyzed: Date
    @Attribute(.externalStorage)
    var scoreResult: ScoreResult
    @Relationship(deleteRule: .cascade)
    var clauses: [AnalyzedClause]

thinking
**Noting Codable requirement for external storage**

The ScoreResult struct using @Attribute(.externalStorage) requires conformance to Codable, which is confirmed and needed for GenerableTypes.
exec
/bin/zsh -lc "sed -n '1,220p' app/decodingOppression/decodingOppression/Models/GenerableTypes.swift" in /Users/emmanuel/Documents/Theory/Redefining_racism succeeded in 128ms:
//
//  GenerableTypes.swift
//  decodingOppression
//
//  Created by Emmanuel Theodore on 2/19/26.
//

import Foundation
import FoundationModels

// MARK: - Clause classification (classification-first order for constrained decoding)

@Generable(description: "Classification of a policy clause by target group and effect direction")
struct ClauseClassification {
    @Generable
    enum TargetGroup: String {
        case outgroup
        case ingroupNonElite
        case elite
        case multiple

thinking
**Verifying count usage consistency**

The guide and instructions specify using `.count(0...5)` rather than `.maximumCount`, which likely doesn't exist for FoundationModels; I'll replace `.maximumCount` with `.count` where found to avoid compile errors.
exec
/bin/zsh -lc "sed -n '1,220p' app/decodingOppression/decodingOppression/Models/PipelineContracts.swift" in /Users/emmanuel/Documents/Theory/Redefining_racism succeeded in 119ms:
//
//  PipelineContracts.swift
//  decodingOppression
//
//  Created by Emmanuel Theodore on 2/19/26.
//

import Foundation

// MARK: - Architecture scores (Codable for pipeline and training)

struct ArchitectureScores: Codable {
    var aar: Double  // asymmetric autonomy restriction
    var se: Double   // selective empathy
    var ij: Double   // ideological justification
    var rsc: Double  // resistance to structural critique
}

// MARK: - Analysis progress


thinking
**Identifying ContentView**
exec
/bin/zsh -lc "sed -n '1,200p' app/decodingOppression/decodingOppression/ContentView.swift" in /Users/emmanuel/Documents/Theory/Redefining_racism succeeded in 111ms:
//
//  ContentView.swift
//  decodingOppression
//
//  Created by Emmanuel Theodore on 2/19/26.
//

import SwiftUI

struct ContentView: View {
    var body: some View {
        ContentUnavailableView(
            "decodingOppression",
            systemImage: "doc.text.magnifyingglass",
            description: Text("Policy analysis placeholder")
        )
    }
}

#Preview {
exec
/bin/zsh -lc "sed -n '1,200p' app/decodingOppression/decodingOppression/decodingOppressionApp.swift" in /Users/emmanuel/Documents/Theory/Redefining_racism succeeded in 111ms:
//
//  decodingOppressionApp.swift
//  decodingOppression
//
//  Created by Emmanuel Theodore on 2/19/26.
//

import SwiftUI
import SwiftData

@main
struct decodingOppressionApp: App {
    var sharedModelContainer: ModelContainer = {
        let schema = Schema([
            PolicyAnalysis.self,
            AnalyzedClause.self,
        ])
        let modelConfiguration = ModelConfiguration(schema: schema, isStoredInMemoryOnly: false)

        do {

thinking
**Confirming file removal**
exec
/bin/zsh -lc "rg --files -g 'Item.swift' app/decodingOppression" in /Users/emmanuel/Documents/Theory/Redefining_racism exited 1 in 115ms:


thinking
**Noting empty taxonomy file**
exec
/bin/zsh -lc 'cat app/decodingOppression/decodingOppression/Data/KeywordTaxonomies.json' in /Users/emmanuel/Documents/Theory/Redefining_racism succeeded in 110ms:
{
  "outgroupBurden": [
    "negro",
    "slave",
    "colored",
    "redlined",
    "drug offender",
    "felon",
    "illegal alien",
    "welfare dependent",
    "inner city",
    "thug",
    "undeserving"
  ],
  "ingroupBenefit": [
    "citizen",
    "property owner",
    "taxpayer",
    "homeowner",
    "veteran",

thinking
**Checking Swift Package Manager dependency**

I'm verifying if the project.pbxproj was updated with the SPM dependency by searching for relevant references in the codebase.
exec
/bin/zsh -lc 'rg "mlx-swift-lm|MLXLLM|MLXEmbedders|MLXLMCommon" app/decodingOppression/decodingOppression.xcodeproj/project.pbxproj' in /Users/emmanuel/Documents/Theory/Redefining_racism succeeded in 113ms:
				1487ADC12F47B281009460B8 /* mlx-swift-lm */,
		1487ADC12F47B281009460B8 /* mlx-swift-lm */ = {
			repositoryURL = "https://github.com/ml-explore/mlx-swift-lm";
		1487ADC22F47B281009460B8 /* MLXLLM */ = {
			package = 1487ADC12F47B281009460B8 /* mlx-swift-lm */;
			productName = MLXLLM;
		1487ADC32F47B281009460B8 /* MLXEmbedders */ = {
			package = 1487ADC12F47B281009460B8 /* mlx-swift-lm */;
			productName = MLXEmbedders;
		1487ADC42F47B281009460B8 /* MLXLMCommon */ = {
			package = 1487ADC12F47B281009460B8 /* mlx-swift-lm */;
			productName = MLXLMCommon;

thinking
**Diagnosing build failure cause**

Build likely fails because the deployment target is set below iOS 26, which is required for FoundationModels and @Generable; I'll confirm the deployment target in project settings or pbxproj to verify this.
exec
/bin/zsh -lc 'rg "IPHONEOS_DEPLOYMENT_TARGET" -n app/decodingOppression/decodingOppression.xcodeproj/project.pbxproj' in /Users/emmanuel/Documents/Theory/Redefining_racism succeeded in 111ms:
341:				IPHONEOS_DEPLOYMENT_TARGET = 26.2;
386:				IPHONEOS_DEPLOYMENT_TARGET = 26.2;
531:				IPHONEOS_DEPLOYMENT_TARGET = 26.2;
557:				IPHONEOS_DEPLOYMENT_TARGET = 26.2;
582:				IPHONEOS_DEPLOYMENT_TARGET = 26.2;
607:				IPHONEOS_DEPLOYMENT_TARGET = 26.2;


thinking
**Analyzing build failure causes**

The build likely fails due to using a non-existent property `.maximumCount` in Guide, and possible conflicts or import issues around ProxyDetection and FoundationModels; noted need to verify Codable conformance for structs with @Attribute(.externalStorage).
thinking
**Diagnosing attribute and enum storage issues**

Build likely fails due to use of non-supported `.maximumCount` in `@Guide` annotations, and possible improper use of `@Attribute(.externalStorage)` on custom codable structs; enums may require explicit `@Attribute(.transformable)` or raw value backing to be stored by SwiftData.
file update
M /Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
@@ -67,3 +67,3 @@
 
-    @Guide(description: "List of proxy terms found (up to 5 items)", .maximumCount(5))
+    @Guide(description: "List of proxy terms found (up to 5 items)", .count(0...5))
     var proxyTerms: [String]
apply_patch(auto_approved=true) exited 0 in 28ms:
Success. Updated the following files:
M /Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
file update:
diff --git a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
index 8c4f39c1cc2d4cc59c60a5cef9039e47b6cae3e7..5e8411c3ac0f19017361a8a5bf13e5f07b16020b
--- a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
+++ b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
@@ -65,7 +65,7 @@
     @Guide(description: "Whether the clause uses proxy variables for outgroup targeting")
     var usesProxyVariables: Bool
 
-    @Guide(description: "List of proxy terms found (up to 5 items)", .maximumCount(5))
+    @Guide(description: "List of proxy terms found (up to 5 items)", .count(0...5))
     var proxyTerms: [String]
 
     @Guide(description: "Whether language expands the outgroup definition")

file update:
diff --git a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
index 8c4f39c1cc2d4cc59c60a5cef9039e47b6cae3e7..5e8411c3ac0f19017361a8a5bf13e5f07b16020b
--- a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
+++ b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
@@ -65,7 +65,7 @@
     @Guide(description: "Whether the clause uses proxy variables for outgroup targeting")
     var usesProxyVariables: Bool
 
-    @Guide(description: "List of proxy terms found (up to 5 items)", .maximumCount(5))
+    @Guide(description: "List of proxy terms found (up to 5 items)", .count(0...5))
     var proxyTerms: [String]
 
     @Guide(description: "Whether language expands the outgroup definition")


thinking
**Searching for other .maximumCount uses**
exec
/bin/zsh -lc 'rg "maximumCount" -n app/decodingOppression/decodingOppression' in /Users/emmanuel/Documents/Theory/Redefining_racism exited 1 in 130ms:

file update:
diff --git a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
index 8c4f39c1cc2d4cc59c60a5cef9039e47b6cae3e7..5e8411c3ac0f19017361a8a5bf13e5f07b16020b
--- a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
+++ b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
@@ -65,7 +65,7 @@
     @Guide(description: "Whether the clause uses proxy variables for outgroup targeting")
     var usesProxyVariables: Bool
 
-    @Guide(description: "List of proxy terms found (up to 5 items)", .maximumCount(5))
+    @Guide(description: "List of proxy terms found (up to 5 items)", .count(0...5))
     var proxyTerms: [String]
 
     @Guide(description: "Whether language expands the outgroup definition")



thinking
**Reconciling instructions for code and summary**

Deciding to keep the final summary minimal and factual to respect the user's "do not explain" directive for code, while still following the system requirement to provide a summary.
thinking
**Planning to validate with xcodebuild**

Intending to use mcp to discover Xcode projects and run xcodebuild to catch remaining build issues and ensure all resources and files are properly included.
tool xcodebuildmcp.discover_projs({"workspaceRoot":"/Users/emmanuel/Documents/Theory/Redefining_racism","scanPath":"app/decodingOppression"})
xcodebuildmcp.discover_projs({"workspaceRoot":"/Users/emmanuel/Documents/Theory/Redefining_racism","scanPath":"app/decodingOppression"}) success in 7ms:
{
  "content": [
    {
      "text": "Discovery finished. Found 1 projects and 0 workspaces.",
      "type": "text"
    },
    {
      "text": "Projects found:\n - /Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression/decodingOppression.xcodeproj",
      "type": "text"
    },
    {
      "text": "Hint: Save a default with session-set-defaults { projectPath: '...' } or { workspacePath: '...' }.",
      "type": "text"
    }
  ],
  "isError": false
}
file update:
diff --git a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
index 8c4f39c1cc2d4cc59c60a5cef9039e47b6cae3e7..5e8411c3ac0f19017361a8a5bf13e5f07b16020b
--- a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
+++ b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
@@ -65,7 +65,7 @@
     @Guide(description: "Whether the clause uses proxy variables for outgroup targeting")
     var usesProxyVariables: Bool
 
-    @Guide(description: "List of proxy terms found (up to 5 items)", .maximumCount(5))
+    @Guide(description: "List of proxy terms found (up to 5 items)", .count(0...5))
     var proxyTerms: [String]
 
     @Guide(description: "Whether language expands the outgroup definition")


thinking
**Setting and listing default schemes**
tool xcodebuildmcp.list_schemes({})
xcodebuildmcp.list_schemes({}) failed in 1ms:
{
  "content": [
    {
      "text": "Error: Missing required session defaults\nDetails: Provide a project or workspace\nSet with: session-set-defaults { \"projectPath\": \"...\" } OR session-set-defaults { \"workspacePath\": \"...\" }",
      "type": "text"
    }
  ],
  "isError": true
}
file update:
diff --git a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
index 8c4f39c1cc2d4cc59c60a5cef9039e47b6cae3e7..5e8411c3ac0f19017361a8a5bf13e5f07b16020b
--- a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
+++ b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
@@ -65,7 +65,7 @@
     @Guide(description: "Whether the clause uses proxy variables for outgroup targeting")
     var usesProxyVariables: Bool
 
-    @Guide(description: "List of proxy terms found (up to 5 items)", .maximumCount(5))
+    @Guide(description: "List of proxy terms found (up to 5 items)", .count(0...5))
     var proxyTerms: [String]
 
     @Guide(description: "Whether language expands the outgroup definition")


thinking
**Setting session defaults**

Planning to set session defaults by applying session-set-defaults with the project path for configuration.
tool xcodebuildmcp.session-set-defaults({"projectPath":"/Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression/decodingOppression.xcodeproj","useLatestOS":true})
xcodebuildmcp.session-set-defaults({"projectPath":"/Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression/decodingOppression.xcodeproj","useLatestOS":true}) success in 1ms:
{
  "content": [
    {
      "text": "Defaults updated:\n{\n  \"projectPath\": \"/Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression/decodingOppression.xcodeproj\",\n  \"useLatestOS\": true\n}",
      "type": "text"
    }
  ],
  "isError": false
}
file update:
diff --git a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
index 8c4f39c1cc2d4cc59c60a5cef9039e47b6cae3e7..5e8411c3ac0f19017361a8a5bf13e5f07b16020b
--- a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
+++ b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
@@ -65,7 +65,7 @@
     @Guide(description: "Whether the clause uses proxy variables for outgroup targeting")
     var usesProxyVariables: Bool
 
-    @Guide(description: "List of proxy terms found (up to 5 items)", .maximumCount(5))
+    @Guide(description: "List of proxy terms found (up to 5 items)", .count(0...5))
     var proxyTerms: [String]
 
     @Guide(description: "Whether language expands the outgroup definition")


thinking
**Listing URL schemes**
tool xcodebuildmcp.list_schemes({})
xcodebuildmcp.list_schemes({}) success in 4.55s:
{
  "content": [
    {
      "text": "✅ Available schemes:",
      "type": "text"
    },
    {
      "text": "decodingOppression",
      "type": "text"
    },
    {
      "text": "Next Steps:\n1. Build the app: build_macos({ projectPath: \"/Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression/decodingOppression.xcodeproj\", scheme: \"decodingOppression\" })\n   or for iOS: build_sim({ projectPath: \"/Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression/decodingOppression.xcodeproj\", scheme: \"decodingOppression\", simulatorName: \"iPhone 16\" })\n2. Show build settings: show_build_settings({ projectPath: \"/Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression/decodingOppression.xcodeproj\", scheme: \"decodingOppression\" })",
      "type": "text"
    },
    {
      "text": "Hint: Consider saving a default scheme with session-set-defaults { scheme: \"decodingOppression\" } to avoid repeating it.",
      "type": "text"
    }
  ],
  "isError": false
file update:
diff --git a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
index 8c4f39c1cc2d4cc59c60a5cef9039e47b6cae3e7..5e8411c3ac0f19017361a8a5bf13e5f07b16020b
--- a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
+++ b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
@@ -65,7 +65,7 @@
     @Guide(description: "Whether the clause uses proxy variables for outgroup targeting")
     var usesProxyVariables: Bool
 
-    @Guide(description: "List of proxy terms found (up to 5 items)", .maximumCount(5))
+    @Guide(description: "List of proxy terms found (up to 5 items)", .count(0...5))
     var proxyTerms: [String]
 
     @Guide(description: "Whether language expands the outgroup definition")


thinking
**Checking available iOS simulators**

I'm planning to list available iOS simulators to confirm if iPhone 16 or another device can be set as the default for building the iOS simulator target.
tool xcodebuildmcp.list_sims({"enabled":true})
xcodebuildmcp.list_sims({"enabled":true}) success in 768ms:
{
  "content": [
    {
      "text": "Available iOS Simulators:\n\ncom.apple.CoreSimulator.SimRuntime.iOS-26-2:\n- iPhone 17 Pro (E831B1CE-E966-41D2-87FE-C9923EA3DDF2)\n- iPhone 17 Pro Max (0759CBE9-92B9-45C8-AA5C-3EE09A268734)\n- iPhone Air (F57B0500-8D61-47BB-8D66-BE64766085B1)\n- iPhone 17 (6F49B5CD-8345-4888-92B2-48CDDB265CAA)\n- iPhone 16e (E65822F6-D8EA-4B12-B740-DF47F6E67E5F)\n- iPad Pro 13-inch (M5) (838C26C4-CD94-47F4-BCF1-0C8176DE760A)\n- iPad Pro 11-inch (M5) (9AE03211-249D-4E64-B5D1-2768538B7A66)\n- iPad mini (A17 Pro) (91DB2C2E-AE60-410B-BDDF-03BAC36F9A19) [Booted]\n- iPad (A16) (8DD3EC87-E400-4AC9-88AB-C53ABEB542C2)\n- iPad Air 13-inch (M3) (AF11A304-7C47-4363-80D7-4DB72D2C1F73)\n- iPad Air 11-inch (M3) (10B63058-4898-4035-9FBA-DE98762279A4)\n\ncom.apple.CoreSimulator.SimRuntime.iOS-26-1:\n- iPhone 17 Pro (F557F983-55FA-4FD1-A115-72B76293AA1D)\n- iPhone 17 Pro Max (F3FCB4E9-6980-4280-A712-9D6AC2F3E0E6)\n- iPhone Air (1123F500-3DCD-4AB4-BDA8-C9A2574EE2D0)\n- iPhone 17 (1DBEBE01-72F0-4113-A5A8-DFD1A60754A1)\n- iPhone 16e (70843D11-EE61-4EC1-B231-3F1EC2C8ACE8)\n- iPad Pro 13-inch (M5) (34AE66B8-2AE3-4F8F-9344-C1B63E611743)\n- iPad Pro 11-inch (M5) (A5EDD393-4882-45EE-AA0B-DB0F15BBD32C)\n- iPad mini (A17 Pro) (2BF6B02D-2F4E-4D38-9816-8C077E67CADE)\n- iPad (A16) (45E6199E-9209-473A-818F-A2C408AD12AD)\n- iPad Air 13-inch (M3) (A673069B-D3E0-4742-AC8A-FF4CBEA84281)\n- iPad Air 11-inch (M3) (02BA69E7-CD9F-424B-AB83-56C4C1BE38C4)\n\ncom.apple.CoreSimulator.SimRuntime.iOS-26-0:\n- iPhone 17 Pro (142467F8-081F-43C4-8C9A-6D67013E609B)\n- iPhone 17 Pro Max (189FE235-650F-4301-B7F5-B9424443BBC4)\n- iPhone Air (838A770C-05A2-43C1-A703-82AD46AD75D9)\n- iPhone 17 (A6BD0A9C-A7BD-4DB9-AFDE-0C52B4C17387)\n- iPhone 16 Pro (4F1B7633-3FC2-47B9-987D-318A1E70D015)\n- iPhone 16 Pro Max (A598F699-4C06-456A-81EE-210EB80B3013)\n- iPhone 16e (FD92F70F-473E-40A5-97EA-144359F02AFF)\n- iPhone 16 (D9C0F339-6823-4BD9-AC9C-A0C00B560A14)\n- iPhone 16 Plus (301DB872-8B93-4C48-8548-6C1F84B7CC9F)\n- iPad Pro 13-inch (M5) (B5430884-3059-46E5-A176-75E573C27D78)\n- iPad Pro 11-inch (M5) (7E13E9CE-7B7C-4F6F-B7A2-4C4872E34EB1)\n- iPad Pro 11-inch (M4) (BE117D6A-DB5E-4050-900F-23780B79C17B)\n- iPad Pro 13-inch (M4) (8093D853-1FA3-4FA9-8CB9-93BDD41F9506)\n- iPad mini (A17 Pro) (401563EA-5C98-42CA-8382-A3D4EA9B155C)\n- iPad (A16) (A2EA9B11-FE38-43F7-ADCF-1ED0E963AF21)\n- iPad Air 13-inch (M3) (572F088B-F0B9-481F-A8B1-1B0C8756480D)\n- iPad Air 11-inch (M3) (9A156318-1CBF-4B43-934F-6737CAE33A95)\n\ncom.apple.CoreSimulator.SimRuntime.watchOS-11-4:\n- Apple Watch Series 10 (46mm) (396D1FB8-6812-4D1B-BAAE-02FD277EE1B8)\n- Apple Watch Series 10 (42mm) (6A867156-730F-47FC-9959-D6411E1C6F30)\n- Apple Watch Ultra 2 (49mm) (D4BE8CEB-EBF7-4481-9830-F6F9CB4844E9)\n- Apple Watch SE (44mm) (2nd generation) (258DB682-57B3-40F0-BBE9-1068EF93FAF8)\n- Apple Watch SE (40mm) (2nd generation) (E3269F08-798D-473F-B30E-1852EAE836C2)\n\ncom.apple.CoreSimulator.SimRuntime.watchOS-26-0:\n- Apple Watch Series 11 (46mm) (9E258C4E-2648-47B4-A7E5-B5E3D04FE4D0)\n- Apple Watch Series 11 (42mm) (963BFC93-EA17-4D30-99BC-7FACA5997E36)\n- Apple Watch Series 10 (46mm) (22418335-3516-4DC1-8930-1EC6238D574E)\n- Apple Watch Series 10 (42mm) (F1B62DAD-FA36-4772-9D42-4A1666CECE19)\n- Apple Watch Ultra 3 (49mm) (FDE670B0-0FE7-42C1-A99B-F0B397AEEBA6)\n- Apple Watch Ultra 2 (49mm) (05B0274F-F6C3-4CA9-9CAB-D6D3E0AEDCAF)\n- Apple Watch SE 3 (44mm) (68FAA294-D084-4420-9182-F808F69779A4)\n- Apple Watch SE 3 (40mm) (693B4D4E-A281-47AE-B7F4-1920C3A5B2A9)\n- Apple Watch SE (44mm) (2nd generation) (3DEB45DD-934D-4BE2-A204-F1E205408373)\n- Apple Watch SE (40mm) (2nd generation) (BAC7F4FE-6E27-465A-8F16-97E34587A693)\n\ncom.apple.CoreSimulator.SimRuntime.watchOS-9-1:\n- Apple Watch Series 8 (45mm) (C2AEA351-2E32-499A-B17F-72A8114CDAA7)\n- Apple Watch Series 8 (41mm) (CA8626A6-6693-44A4-8B16-44128796A653)\n- Apple Watch Ultra (49mm) (C9226C3F-9947-4A31-A5C3-66B78669C0A0)\n- Apple Watch SE (44mm) (2nd generation) (72B9ED3B-1689-4FAD-B348-5A526677C3D4)\n- Apple Watch SE (40mm) (2nd generation) (81C62343-F4AB-43B3-BF76-8E88C8EBC4B4)\n- Apple Watch Series 7 (45mm) (503AC081-0C43-4463-8F05-1B51E6E81EFC)\n- Apple Watch Series 7 (41mm) (94A66A0D-F828-4342-96D3-1542FC3A27B5)\n- Apple Watch Series 6 (44mm) (726DE38C-6451-47AE-9941-FE441E75112C)\n- Apple Watch Series 6 (40mm) (10FE6219-E493-44E2-812F-AE593F9DFAFA)\n- Apple Watch Series 5 (44mm) (2441BFDD-E7AF-4576-BB81-7335A342954D)\n- Apple Watch Series 5 (40mm) (FD131841-538A-47CD-BD57-BB325AB1FF3F)\n\ncom.apple.CoreSimulator.SimRuntime.iOS-17-4:\n- iPhone 15 Pro (7798944B-17F4-4897-8325-8DEAD33E7C5C)\n- iPhone 15 Pro Max (935FFFED-0845-4568-BEFE-B1D408F05E48)\n- iPhone 15 (B217F635-3B62-411A-8EA9-8F04D7129796)\n- iPhone 15 Plus (C58EAF31-8B7E-4D75-96EF-677636EAF8C6)\n- iPhone SE (3rd generation) (DC0E4846-E94E-4DF6-A79D-B83B35B4B961)\n- iPad Pro 11-inch (M4) (B11053F8-D353-4D9C-A105-CFD753DACB2F)\n- iPad Pro 13-inch (M4) (8A071DE1-A78B-40C5-96B2-7D05C6D97270)\n- iPad Air 11-inch (M2) (89163A78-3670-4D71-BECD-6BB68F8B81C7)\n- iPad Air 13-inch (M2) (0D14A6A4-A6A7-48E8-8844-497A2D99C9E7)\n- iPad Pro (11-inch) (4th generation) (3F61EE09-D8B7-4D70-A062-4FEC6263BCA7)\n- iPad Pro (12.9-inch) (6th generation) (4CD7EEC4-C06C-4568-8A3F-4D3B5873D251)\n- iPad (10th generation) (652F18EC-1815-4F79-A86A-7B53827F3D4B)\n- iPad Air (5th generation) (694FF60F-7132-43C1-8382-F831924C5EED)\n- iPad mini (6th generation) (491C3110-5AF3-4012-867C-B1EC4ADBA094)\n\ncom.apple.CoreSimulator.SimRuntime.iOS-18-4:\n- iPhone 16 Pro (467E4ADA-D119-4177-9059-62C1C17BC9B8)\n- iPhone 16 Pro Max (18) (F2611377-3FC4-4913-B674-350F308ECBB4)\n- iPhone 16e (3190744E-01A3-48C3-80F4-CAA7828AA592)\n- iPhone 16 (AE5E561D-0A7A-4A73-80FB-8B61E52801C3)\n- iPhone 16 Plus (0766AD6A-02D7-4FA4-8928-E94F5C182E7B)\n- iPad Pro 11-inch (M4) (A99DB0FB-3B8D-4479-B63D-7895CB3D5CDF)\n- iPad Pro 13-inch (M4) (E226C404-F574-4EAA-B1B0-48F2FE0D5496)\n- iPad mini (A17 Pro) (4F5C2C82-67DA-438F-8823-09018A8305E8)\n- iPad (A16) (FA5C9940-1A3D-4FA9-9BB8-CB8720115EE3)\n- iPad Air 13-inch (M3) (EAA78D0D-ADF1-4590-A39F-80036008F776)\n- iPad Air 11-inch (M3) (64BFD068-E7FA-437A-BAAA-BFA118A034D4)\n\ncom.apple.CoreSimulator.SimRuntime.xrOS-26-2:\n- Apple Vision Pro (4296E37F-52A0-4FAE-8593-E9EBF4DF2222)\n\ncom.apple.CoreSimulator.SimRuntime.iOS-17-2:\n- iPhone 15 Pro (C94C5EDF-13C6-4CE2-B6B6-CFA3C865CF69)\n- iPhone 15 Pro Max (D73ED43C-B205-480C-A013-A59B438B25B7)\n- iPhone 15 (58E5D217-C9DE-4CE6-B5A2-EAF5FF02044D)\n- iPhone 15 Plus (AB7725D0-382B-45D7-9A49-E94EDFEB77A0)\n- iPhone 14 Pro (9342B536-4DEA-4A1B-90CE-5B27983DC202)\n- iPhone 14 Pro Max (14EA4719-66AC-4D04-9878-D780336551EB)\n- iPhone 14 (9BD0495A-A0AE-49EE-BE3F-4FD2FBF2240C)\n- iPhone 14 Plus (5536DC7C-9656-47A9-ABDE-FCDC49D64CF8)\n- iPad Pro (11-inch) (4th generation) (9068D32A-A292-4965-9A4F-652DD9173CEA)\n- iPad Pro (12.9-inch) (6th generation) (2EA07219-83FC-46B2-9276-EE4E916B4CBA)\n- iPad mini (6th generation) (8D630A86-BB9C-4C3D-AE7E-B50AD7DD64B3)\n\ncom.apple.CoreSimulator.SimRuntime.xrOS-26-1:\n- Apple Vision Pro (672A1FE5-F110-4D36-9C55-A2C17C73EAAC)\n\ncom.apple.CoreSimulator.SimRuntime.watchOS-26-1:\n- Apple Watch Series 11 (46mm) (B3A6C46B-EABD-4C99-914A-B13028DD6A04)\n- Apple Watch Series 11 (42mm) (6889E616-542F-401B-A1D2-5408E1E4293A)\n- Apple Watch Ultra 3 (49mm) (6D324C0E-3124-4DBD-8FCD-9ED50A84D8FB)\n- Apple Watch SE 3 (44mm) (508E14AE-BF2C-4456-BE2D-578FED2D2774)\n- Apple Watch SE 3 (40mm) (769D5ECC-FE24-465E-81CA-CEA6F8F2151D)\n\ncom.apple.CoreSimulator.SimRuntime.xrOS-26-0:\n- Apple Vision Pro 4K (02B1C8E6-36A3-40EF-9E3D-BC53EC4822E6)\n\ncom.apple.CoreSimulator.SimRuntime.xrOS-2-4:\n- Apple Vision Pro (CCB94C1F-5609-4B83-94F2-4FD773457CB5)\n\ncom.apple.CoreSimulator.SimRuntime.xrOS-1-1:\n- Apple Vision Pro (5A0369E2-57FF-467C-BF56-F70FAC65E8E5)\n- Apple Vision Pro (5B4E04F8-97D5-4575-BEEA-F0159789E7B6)\n\ncom.apple.CoreSimulator.SimRuntime.watchOS-26-2:\n- Apple Watch Series 11 (46mm) (9CD49511-FF76-4408-8EB8-80D622DE8E5D)\n- Apple Watch Series 11 (42mm) (6AC5CF8E-DB3C-4B65-BD41-D743975C649D)\n- Apple Watch Ultra 3 (49mm) (67F9909C-97D2-4B3F-9630-A7609BE7D50A)\n- Apple Watch SE 3 (44mm) (683A8A5C-4795-4AD4-8D6D-FB0E0CE0FAA8)\n- Apple Watch SE 3 (40mm) (37303F82-0592-45F7-A601-DB800D8276A7)\n\nNext Steps:\n1. Boot a simulator: boot_sim({ simulatorId: 'UUID_FROM_ABOVE' })\n2. Open the simulator UI: open_sim({})\n3. Build for simulator: build_sim({ scheme: 'YOUR_SCHEME', simulatorId: 'UUID_FROM_ABOVE' })\n4. Get app path: get_sim_app_path({ scheme: 'YOUR_SCHEME', platform: 'iOS Simulator', simulatorId: 'UUID_FROM_ABOVE' })\nHint: Save a default simulator with session-set-defaults { simulatorId: 'UUID_FROM_ABOVE' } (or simulatorName).",
      "type": "text"
    }
  ]
}
file update:
diff --git a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
index 8c4f39c1cc2d4cc59c60a5cef9039e47b6cae3e7..5e8411c3ac0f19017361a8a5bf13e5f07b16020b
--- a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
+++ b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
@@ -65,7 +65,7 @@
     @Guide(description: "Whether the clause uses proxy variables for outgroup targeting")
     var usesProxyVariables: Bool
 
-    @Guide(description: "List of proxy terms found (up to 5 items)", .maximumCount(5))
+    @Guide(description: "List of proxy terms found (up to 5 items)", .count(0...5))
     var proxyTerms: [String]
 
     @Guide(description: "Whether language expands the outgroup definition")


thinking
**Planning simulator build with iPad mini**

Considering building for the simulator using the booted iPad mini A17 Pro with iOS 16.2, setting defaults for scheme and simulatorId to simplify the process.
tool xcodebuildmcp.session-set-defaults({"scheme":"decodingOppression","simulatorId":"91DB2C2E-AE60-410B-BDDF-03BAC36F9A19"})
xcodebuildmcp.session-set-defaults({"scheme":"decodingOppression","simulatorId":"91DB2C2E-AE60-410B-BDDF-03BAC36F9A19"}) success in 1ms:
{
  "content": [
    {
      "text": "Defaults updated:\n{\n  \"projectPath\": \"/Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression/decodingOppression.xcodeproj\",\n  \"useLatestOS\": true,\n  \"scheme\": \"decodingOppression\",\n  \"simulatorId\": \"91DB2C2E-AE60-410B-BDDF-03BAC36F9A19\"\n}",
      "type": "text"
    }
  ],
  "isError": false
}
file update:
diff --git a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
index 8c4f39c1cc2d4cc59c60a5cef9039e47b6cae3e7..5e8411c3ac0f19017361a8a5bf13e5f07b16020b
--- a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
+++ b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
@@ -65,7 +65,7 @@
     @Guide(description: "Whether the clause uses proxy variables for outgroup targeting")
     var usesProxyVariables: Bool
 
-    @Guide(description: "List of proxy terms found (up to 5 items)", .maximumCount(5))
+    @Guide(description: "List of proxy terms found (up to 5 items)", .count(0...5))
     var proxyTerms: [String]
 
     @Guide(description: "Whether language expands the outgroup definition")


thinking
**Invoking build_sim step**
tool xcodebuildmcp.build_sim({})
xcodebuildmcp.build_sim({}) success in 30.20s:
{
  "content": [
    {
      "text": "⚠️ Warning: 2026-02-19 17:13:57.112 appintentsmetadataprocessor[31640:27937315] warning: Metadata extraction skipped. No AppIntents.framework dependency found.",
      "type": "text"
    },
    {
      "text": "✅ iOS Simulator Build build succeeded for scheme decodingOppression.",
      "type": "text"
    },
    {
      "text": "Next Steps:\n1. Get app path: get_sim_app_path({ simulatorId: '91DB2C2E-AE60-410B-BDDF-03BAC36F9A19', scheme: 'decodingOppression', platform: 'iOS Simulator' })\n2. Get bundle ID: get_app_bundle_id({ appPath: 'PATH_FROM_STEP_1' })\n3. Launch: launch_app_sim({ simulatorId: '91DB2C2E-AE60-410B-BDDF-03BAC36F9A19', bundleId: 'BUNDLE_ID_FROM_STEP_2' })\n   Or with logs: launch_app_logs_sim({ simulatorId: '91DB2C2E-AE60-410B-BDDF-03BAC36F9A19', bundleId: 'BUNDLE_ID_FROM_STEP_2' })",
      "type": "text"
    }
  ]
}
file update:
diff --git a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
index 8c4f39c1cc2d4cc59c60a5cef9039e47b6cae3e7..5e8411c3ac0f19017361a8a5bf13e5f07b16020b
--- a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
+++ b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
@@ -65,7 +65,7 @@
     @Guide(description: "Whether the clause uses proxy variables for outgroup targeting")
     var usesProxyVariables: Bool
 
-    @Guide(description: "List of proxy terms found (up to 5 items)", .maximumCount(5))
+    @Guide(description: "List of proxy terms found (up to 5 items)", .count(0...5))
     var proxyTerms: [String]
 
     @Guide(description: "Whether language expands the outgroup definition")



thinking
**Updating guide count to fix build**

Updated `GenerableTypes.swift` to use a supported count constraint in ProxyDetection, resolving the previous FoundationModels compile issue. The build now succeeds with a warning about `AppIntentsMetadata`.

Tests run:
- `xcodebuildmcp build_sim` (scheme decodingOppression, simulatorId ...)
Build previously failed but now completes successfully with noted warning.
thinking
**Finalizing summary with build details**

Updated the ProxyDetection guide to use `@Guide(.count(0...5))`, enabling FoundationModels to compile successfully by applying a supported array constraint in `app/decodingOppression/decodingOppression/Models/GenerableTypes.swift`. This fixes the prior build failure and maintains expected guide behavior.

Tests run:
- `xcodebuildmcp build_sim` (scheme decodingOppression, simulatorId ...) — completed with warning: "Metadata extraction skipped for target AppIntentsMetadata"
codex
Updated the ProxyDetection guide to use the supported array count constraint so FoundationModels compiles cleanly. Change is in `app/decodingOppression/decodingOppression/Models/GenerableTypes.swift` to replace the unsupported maximum-count guide.

- Tests: `build_sim` (scheme `decodingOppression`, simulator `91DB2C2E-AE60-410B-BDDF-03BAC36F9A19`); warning: “Metadata extraction skipped. No AppIntents.framework dependency found.”
file update:
diff --git a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
index 8c4f39c1cc2d4cc59c60a5cef9039e47b6cae3e7..5e8411c3ac0f19017361a8a5bf13e5f07b16020b
--- a/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
+++ b/app/decodingOppression/decodingOppression/Models/GenerableTypes.swift
@@ -65,7 +65,7 @@
     @Guide(description: "Whether the clause uses proxy variables for outgroup targeting")
     var usesProxyVariables: Bool
 
-    @Guide(description: "List of proxy terms found (up to 5 items)", .maximumCount(5))
+    @Guide(description: "List of proxy terms found (up to 5 items)", .count(0...5))
     var proxyTerms: [String]
 
     @Guide(description: "Whether language expands the outgroup definition")

tokens used
74,955
Updated the ProxyDetection guide to use the supported array count constraint so FoundationModels compiles cleanly. Change is in `app/decodingOppression/decodingOppression/Models/GenerableTypes.swift` to replace the unsupported maximum-count guide.

- Tests: `build_sim` (scheme `decodingOppression`, simulator `91DB2C2E-AE60-410B-BDDF-03BAC36F9A19`); warning: “Metadata extraction skipped. No AppIntents.framework dependency found.”
