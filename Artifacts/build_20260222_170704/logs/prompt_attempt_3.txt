You are a Swift/SwiftUI developer. A previous attempt to complete a task failed.

TESTING & DEBUGGING REFERENCE:
For building, testing, and debugging iOS/macOS apps, reference this workflow guide:
/Users/emmanuel/Dev/Tools/Eocon-Foundation-V1/.Foundation/Docs/swiftDocs/Testing/XCODEBUILD_MCP_WORKFLOW.md

This guide covers:
- XcodeBuild MCP server tools for programmatic Xcode interaction
- Building for simulator, booting simulators, installing/launching apps
- UI automation: screenshots, accessibility hierarchy, tap simulation
- Debugging UI issues (button taps, gestures, navigation)

=== ORIGINAL TASK ===
I have the following verification comments after thorough review and exploration of the codebase. Implement the comments by following the instructions in the comments verbatim.

---
## Comment 1: Tier3 streaming path lacks availability/guardrail handling and can surface errors to callers

In \`AI/Tier3Engine.swift\` \`streamClassify\`, call \`checkAvailability()\` before creating the stream and return/finish early when it throws \`Tier3Error.unavailable\` (e.g., finish with that error or return an empty stream). Wrap the streaming loop in a \`do/catch\` that catches \`Tier3Error.safetyGuardrail\` and \`Tier3Error.contextWindowExceeded\`; log, then finish or return an empty stream so callers don’t see these errors.

### Referred Files
- /Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression/decodingOppression/AI/Tier3Engine.swift
---
## Comment 2: Tier3 classify rethrows context-window/session failures instead of degrading to lower tiers

In \`AI/Tier3Engine.swift\` \`classify\`, extend the \`do/catch\` to catch \`Tier3Error.contextWindowExceeded\` and \`Tier3Error.sessionFailed\`; log and return \`nil\` so the caller can fall back to lower tiers instead of propagating the error.

### Referred Files
- /Users/emmanuel/Documents/Theory/Redefining_racism/app/decodingOppression/decodingOppression/AI/Tier3Engine.swift
---
=== END ORIGINAL TASK ===

=== REFERENCE CONTEXT ===

=== SWIFT DOCUMENTATION ===

--- FILE: Improving-the-safety-of-generative-model-output.md ---
# Improving the safety of generative model output

**Create generative experiences that appropriately handle sensitive inputs and respect people.**


## Overview

Generative AI models have powerful creativity, but with this creativity comes the risk of unintended or unexpected results. For any generative AI feature, safety needs to be an essential part of your design.

The Foundation Models framework has two base layers of safety, where the framework uses:

- An on-device language model that has training to handle sensitive topics with care.

- *Guardrails* that aim to block harmful or sensitive content, such as self-harm, violence, and adult materials, from both model input and output.

Because safety risks are often contextual, some harms might bypass both built-in framework safety layers. It’s vital to design additional safety layers specific to your app. When developing your feature, decide what’s acceptable or might be harmful in your generative AI feature, based on your app’s use case, cultural context, and audience.

For more information on designing generative AI experiences responsibly, see Human Interface Guidelines > Foundations > [https://developer.apple.com/design/human-interface-guidelines/generative-ai](https://developer.apple.com/design/human-interface-guidelines/generative-ai).


## Handle guardrail errors

When you send a prompt to the model, [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/Guardrails](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/Guardrails) check the input prompt and the model’s output. If either fails the guardrail’s safety check, the model session throws a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)) error:

```swift
do {
    let session = LanguageModelSession()
    let topic = // A potentially harmful topic.
    let prompt = "Write a respectful and funny story about \(topic)."
    let response = try await session.respond(to: prompt)
} catch LanguageModelSession.GenerationError.guardrailViolation {
    // Handle the safety error.
}
```

If you encounter a guardrail violation error for any built-in prompt in your app, experiment with re-phrasing the prompt to determine which phrases are activating the guardrails, and avoid those phrases. If the error is thrown in response to a prompt created by someone using your app, give people a clear message that explains the issue. For example, you might say “Sorry, this feature isn’t designed to handle that kind of input” and offer people the opportunity to try a different prompt.


## Handle model refusals

The on-device language model may not be suitable for handling all requests and may refuse requests for a topic. When you generate a string response, and the model refuses a request, it generates a message that begins with a refusal like “Sorry, I can’t help with”.

Design your app experience with refusal messages in mind and present the message to the person using your app. You might not be able to programmatically determine whether a string response is a normal response or a refusal, so design the experience to anticipate both. If it’s critical to determine whether the response is a refusal message, initialize a new [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession) and prompt the model to classify whether the string is a refusal.

When you use guided generation to generate Swift structures or types, there’s no placeholder for a refusal message. Instead, the model throws a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/refusal(_:_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/refusal(_:_:)) error. When you catch the error, you can ask the model to generate a string refusal message:

```swift
do {
    let session = LanguageModelSession()
    let topic = ""  // A sensitive topic.
    let response = try session.respond(
        to: "List five key points about: \(topic)",
        generating: [String].self
    )
} catch LanguageModelSession.GenerationError.refusal(let refusal, _) {
    // Generate an explanation for the refusal.
    if let message = try? await refusal.explanation {
        // Display the refusal message.
    }
}
```

Display the explanation in your app to tell people why a request failed, and offer people the opportunity to try a different prompt. Retrieving an explanation message is asynchronous and takes time for the model to generate.

If you encounter a refusal message, or refusal error, for any built-in prompts in your app, experiment with re-phrasing your prompt to avoid any sensitive topics that might cause the refusal.

For more information about guided generation, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation).


## Build boundaries on input and output

Safety risks increase when a prompt includes direct input from a person using your app, or from an unverified external source, like a webpage. An untrusted source makes it difficult to anticipate what the input contains. Whether accidentally or on purpose, someone could input sensitive content that causes the model to respond poorly.


> **TIP**: The more you can define the intended usage and outcomes for your feature, the more you can ensure generation works great for your app’s specific use cases. Add boundaries to limit out-of-scope usage and minimize low generation quality from out-of-scope uses.


Whenever possible, avoid open input in prompts and place boundaries for controlling what the input can be. This approach helps when you want generative content to stay within the bounds of a particular topic or task. For the highest level of safety on input, give people a fixed set of prompts to choose from. This gives you the highest certainty that sensitive content won’t make its way into your app:

```swift
enum TopicOptions {
    case family
    case nature
    case work 
}
let topicChoice = TopicOptions.nature
let prompt = """
    Generate a wholesome and empathetic journal prompt that helps \
    this person reflect on \(topicChoice)
    """
```

If your app allows people to freely input a prompt, placing boundaries on the output can also offer stronger safety guarantees. Using guided generation, create an enumeration to restrict the model’s output to a set of predefined options designed to be safe no matter what:

```swift
@Generable
enum Breakfast {
    case waffles
    case pancakes
    case bagels
    case eggs 
}
let session = LanguageModelSession()
let userInput = "I want something sweet."
let prompt = "Pick the ideal breakfast for request: \(userInput)"
let response = try await session.respond(to: prompt, generating: Breakfast.self)
```


## Instruct the model for added safety

Consider adding detailed session [doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) that tell the model how to handle sensitive content. The language model prioritizes following its instructions over any prompt, so instructions are an effective tool for improving safety and overall generation quality. Use uppercase words to emphasize the importance of certain phrases for the model:

```swift
do {
    let instructions = """
        ALWAYS respond in a respectful way. \
        If someone asks you to generate content that might be sensitive, \
        you MUST decline with 'Sorry, I can't do that.'
        """
    let session = LanguageModelSession(instructions: instructions)
    let prompt = // Open input from a person using the app.
    let response = try await session.respond(to: prompt)
} catch LanguageModelSession.GenerationError.guardrailViolation {
    // Handle the safety error.
}
```


> **NOTE**: A session obeys instructions over a prompt, so don’t include input from people or any unverified input in the instructions. Using unverified input in instructions makes your app vulnerable to prompt injection attacks, so write instructions with content you trust.


If you want to include open-input from people, instructions for safety are recommended. For an additional layer of safety, use a format string in normal prompts that wraps people’s input in your own content that specifies how the model should respond:

```swift
let userInput = // The input a person enters in the app.
let prompt = """
    Generate a wholesome and empathetic journal prompt that helps \
    this person reflect on their day. They said: \(userInput)
    """
```


## Add a deny list of blocked terms

If you allow prompt input from people or outside sources, consider adding your own deny list of terms. A deny list is anything you don’t want people to be able to input to your app, including unsafe terms, names of people or products, or anything that’s not relevant to the feature you provide. Implement a deny list similarly to guardrails by creating a function that checks the input and the model output:

```swift
let session = LanguageModelSession()
let userInput = // The input a person enters in the app.
let prompt = "Generate a wholesome story about: \(userInput)"

// A function you create that evaluates whether the input 
// contains anything in your deny list.
if verifyText(prompt) { 
    let response = try await session.respond(to: prompt)
    
    // Compare the output to evaluate whether it contains anything in your deny list.
    if verifyText(response.content) { 
        return response 
    } else {
        // Handle the unsafe output.
    }
} else {
    // Handle the unsafe input.
}
```

A deny list can be a simple list of strings in your code that you distribute with your app. Alternatively, you can host a deny list on a server so your app can download the latest deny list when it’s connected to the network. Hosting your deny list allows you to update your list when you need to and avoids requiring a full app update if a safety issue arise.


## Use permissive guardrail mode for sensitive content

The default [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel) guardrails may throw a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)) error for sensitive source material. For example, it may be appropriate for your app to work with certain inputs from people and unverified sources that might contain sensitive content:

- When you want the model to tag the topic of conversations in a chat app when some messages contain profanity.

- When you want to use the model to explain notes in your study app that discuss sensitive topics.

To allow the model to reason about sensitive source material, use [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/Guardrails/permissiveContentTransformations](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/Guardrails/permissiveContentTransformations) when you initialize [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel):

```swift
let model = SystemLanguageModel(guardrails: .permissiveContentTransformations)
```

This mode only works for generating a string value. When you use guided generation, the framework runs the default guardrails against model input and output as usual, and generates [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)) and [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/refusal(_:_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/refusal(_:_:))errors as usual.

Before you use permissive content mode, consider what’s appropriate for your audience. The session skips the guardrail checks in this mode, so it never throws a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)) error when generating string responses.

However, even with the [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel) guardrails off, the on-device system language model still has a layer of safety. For some content, the model may still produce a refusal message that’s similar to, “Sorry, I can’t help with.”


## Create a risk assessment

Conduct a risk assessment to proactively address what might go wrong. Risk assessment is an exercise that helps you brainstorm potential safety risks in your app and map each risk to an actionable mitigation. You can write a risk assessment in any format that includes these essential elements:

- List each AI feature in your app.

- For each feature, list possible safety risks that could occur, even if they seem unlikely.

- For each safety risk, score how serious the harm would be if that thing occurred, from mild to critical.

- For each safety risk, assign a strategy for how you’ll mitigate the risk in your app.

For example, an app might include one feature with the fixed-choice input pattern for generation and one feature with the open-input pattern for generation, which is higher safety risk:

Besides obvious harms, like a poor-quality model output, think about how your generative AI feature might affect people, including real-world scenarios where someone might act based on information generated by your app.


## Write and maintain safety tests

Although most people will interact with your app in respectful ways, it’s important to anticipate possible failure modes where certain input or contexts could cause the model to generate something harmful. Especially if your app takes input from people, test your experience’s safety on input like:

- Input that is nonsensical, snippets of code, or random characters.

- Input that includes sensitive content.

- Input that includes controversial topics.

- Vague or unclear input that could be misinterpreted.

Create a list of potentially harmful prompt inputs that you can run as part of your app’s tests. Include every prompt in your app — even safe ones — as part of your app testing. For each prompt test, log the timestamp, full input prompt, the model’s response, and whether it activates any built-in safety or mitigations you’ve included in your app. When starting out, manually read the model’s response on all tests to ensure it meets your design and safety goals. To scale your tests, consider using a frontier LLM to auto-grade the safety of each prompt. Building a test pipeline for prompts and safety is a worthwhile investment for tracking changes in how your app responds over time.

Someone might purposefully attempt to break your feature or produce bad output — especially someone who won’t be harmed by their actions. But, keep in mind that it’s very important to identify cases where someone might *accidentally* be harmed during normal app use.


> **TIP**: Prioritize protecting people using your app with good intentions. Accidental safety failures often only occur in specific contexts, which make them hard to identify during testing. Test for a longer series of interactions, and test for inputs that could become sensitive only when combined with other aspects of your app.


Don’t engage in any testing that could cause you or others harm. Apple’s built-in responsible AI and safety measures, like safety guardrails, are built by experts with extensive training and support. These built-in measures aim to block egregious harms, allowing you to focus on the borderline harmful cases that need your judgement. Before conducting any safety testing, ensure that you’re in a safe location and that you have the health and well-being support you need.


## Report safety concerns

Somewhere in your app, it’s important to include a way that people can report potentially harmful content. Continuously monitor the feedback you receive, and be responsive to quickly handling any safety issues that arise. If someone reports a safety concern that you believe isn’t being properly handled by Apple’s built-in guardrails, report it to Apple with [https://support.apple.com/guide/feedback-assistant/get-started-fbab81460adb/mac](https://support.apple.com/guide/feedback-assistant/get-started-fbab81460adb/mac).

The Foundation Models framework offers utilities for feedback. Use [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelFeedback](https://developer.apple.com/documentation/FoundationModels/LanguageModelFeedback) to retrieve language model session transcripts from people using your app. After collecting feedback, you can serialize it into a JSON file and include it in the report you send with Feedback Assistant.


## Monitor safety for model or guardrail updates

Apple releases updates to the system model as part of regular OS updates. If you participate in the developer beta program you can test your app with new model version ahead of people using your app. When the model updates, it’s important to re-run your full prompt tests in addition to your adversarial safety tests because the model’s response may change. Your risk assessment can help you track any change to safety risks in your app.

Apple may update the built-in guardrails at any time outside of the regular OS update cycle. This is done to rapidly respond, for example, to reported safety concerns that require a fast response. Include all of the prompts you use in your app in your test suite, and run tests regularly to identify when prompts start activating the guardrails.

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/improving-the-safety-of-generative-model-output](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/improving-the-safety-of-generative-model-output)*
--- END FILE ---

--- FILE: Generating-content-and-performing-tasks-with-Foundation-Models.md ---
# Generating content and performing tasks with Foundation Models

**Enhance the experience in your app by prompting an on-device large language model.**


## Overview

The Foundation Models framework lets you tap into the on-device large models at the core of Apple Intelligence. You can enhance your app by using generative models to create content or perform tasks. The framework supports language understanding and generation based on model capabilities.

For design guidance, see Human Interface Guidelines > Technologies > [https://developer.apple.com/design/human-interface-guidelines/generative-ai](https://developer.apple.com/design/human-interface-guidelines/generative-ai).


## Understand model capabilities

When considering features for your app, it helps to know what the on-device language model can do. The on-device model supports text generation and understanding that you can use to:

The on-device language model may not be suitable for handling all requests, like:

The model can complete complex generative tasks when you use guided generation or tool calling. For more on handling complex tasks, or tasks that require extensive world-knowledge, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation) and [doc://com.apple.foundationmodels/documentation/FoundationModels/expanding-generation-with-tool-calling](https://developer.apple.com/documentation/FoundationModels/expanding-generation-with-tool-calling).


## Check for availability

Before you use the on-device model in your app, check that the model is available by creating an instance of [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel) with the [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/default](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/default) property.

Model availability depends on device factors like:

- The device must support Apple Intelligence.

- The device must have Apple Intelligence turned on in Settings.


> **NOTE**: It can take some time for the model to download and become available when a person turns on Apple Intelligence.


Always verify model availability first, and plan for a fallback experience in case the model is unavailable.

```swift
struct GenerativeView: View {
    // Create a reference to the system language model.
    private var model = SystemLanguageModel.default

    var body: some View {
        switch model.availability {
        case .available:
            // Show your intelligence UI.
        case .unavailable(.deviceNotEligible):
            // Show an alternative UI.
        case .unavailable(.appleIntelligenceNotEnabled):
            // Ask the person to turn on Apple Intelligence.
        case .unavailable(.modelNotReady):
            // The model isn't ready because it's downloading or because of other system reasons.
        case .unavailable(let other):
            // The model is unavailable for an unknown reason.
        }
    }
}
```


## Create a session

After confirming that the model is available, create a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession) object to call the model. For a single-turn interaction, create a new session each time you call the model:

```swift
// Create a session with the system model.
let session = LanguageModelSession()
```

For a multiturn interaction — where the model retains some knowledge of what it produced — reuse the same session each time you call the model.


## Provide a prompt to the model

A [doc://com.apple.foundationmodels/documentation/FoundationModels/Prompt](https://developer.apple.com/documentation/FoundationModels/Prompt) is an input that the model responds to. Prompt engineering is the art of designing high-quality prompts so that the model generates a best possible response for the request you make. A prompt can be as short as “hello”, or as long as multiple paragraphs. The process of designing a prompt involves a lot of exploration to discover the best prompt, and involves optimizing prompt length and writing style.

When thinking about the prompt you want to use in your app, consider using conversational language in the form of a question or command. For example, “What’s a good month to visit Paris?” or “Generate a food truck menu.”

Write prompts that focus on a single and specific task, like “Write a profile for the dog breed Siberian Husky”. When a prompt is long and complicated, the model takes longer to respond, and may respond in unpredictable ways. If you have a complex generation task in mind, break the task down into a series of specific prompts.

You can refine your prompt by telling the model exactly how much content it should generate. A prompt like, “Write a profile for the dog breed Siberian Husky” often takes a long time to process as the model generates a full multi-paragraph essay. If you specify “using three sentences”, it speeds up processing and generates a concise summary. Use phrases like “in a single sentence” or “in a few words” to shorten the generation time and produce shorter text.

```swift
// Generate a longer response for a specific command.
let simple = "Write me a story about pears."

// Quickly generate a concise response.
let quick = "Write the profile for the dog breed Siberian Husky using three sentences."
```


## Provide instructions to the model

[doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) help steer the model in a way that fits the use case of your app. The model obeys prompts at a lower priority than the instructions you provide. When you provide instructions to the model, consider specifying details like:

- What the model’s role is; for example, “You are a mentor,” or “You are a movie critic”.

- What the model should do, like “Help the person extract calendar events,” or “Help the person by recommending search suggestions”.

- What the style preferences are, like “Respond as briefly as possible”.

- What the possible safety measures are, like “Respond with ‘I can’t help with that’ if you’re asked to do something dangerous”.

Use content you trust in instructions because the model follows them more closely than the prompt itself. When you initialize a session with instructions, it affects all prompts the model responds to in that session. Instructions can also include example responses to help steer the model. When you add examples to your prompt, you provide the model with a template that shows the model what a good response looks like.


## Generate a response

To call the model with a prompt, call [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/respond(to:options:)-b2re](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/respond(to:options:)-b2re) on your session. The response call is asynchronous because it may take a few seconds for the on-device foundation model to generate the response.

```swift
let instructions = """
    Suggest five related topics. Keep them concise (three to seven words) and make sure they \
    build naturally from the person's topic.
    """

let session = LanguageModelSession(instructions: instructions)

let prompt = "Making homemade bread"
let response = try await session.respond(to: prompt)
```


> **NOTE**: A session can only handle a single request at a time, and causes a runtime error if you call it again before the previous request finishes. Check [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/isResponding](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/isResponding) to verify the session is done processing the previous request before sending a new one.


Instead of working with raw string output from the model, the framework offers guided generation to generate a custom Swift data structure you define. For more information about guided generation, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation).

When you make a request to the model, you can provide custom tools to help the model complete the request. If the model determines that a [doc://com.apple.foundationmodels/documentation/FoundationModels/Tool](https://developer.apple.com/documentation/FoundationModels/Tool) can assist with the request, the framework calls your [doc://com.apple.foundationmodels/documentation/FoundationModels/Tool](https://developer.apple.com/documentation/FoundationModels/Tool) to perform additional actions like retrieving content from your local database. For more information about tool calling, see [doc://com.apple.foundationmodels/documentation/FoundationModels/expanding-generation-with-tool-calling](https://developer.apple.com/documentation/FoundationModels/expanding-generation-with-tool-calling)


## Consider context size limits per session

The *context window size* is a limit on how much data the model can process for a session instance. A token is a chunk of text the model processes, and the system model supports up to 4,096 tokens. A single token corresponds to three or four characters in languages like English, Spanish, or German, and one token per character in languages like Japanese, Chinese, or Korean. In a single session, the sum of all tokens in the instructions, all prompts, and all outputs count toward the context window size.

If your session processes a large amount of tokens that exceed the context window, the framework throws the error [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)). When you encounter the error, start a new session and try shortening your prompts. If you need to process a large amount of data that won’t fit in a single context window limit, break your data into smaller chunks, process each chunk in a separate session, and then combine the results.


## Tune generation options and optimize performance

To get the best results for your prompt, experiment with different generation options. [doc://com.apple.foundationmodels/documentation/FoundationModels/GenerationOptions](https://developer.apple.com/documentation/FoundationModels/GenerationOptions) affects the runtime parameters of the model, and you can customize them for every request you make.

```swift
// Customize the temperature to increase creativity.
let options = GenerationOptions(temperature: 2.0)

let session = LanguageModelSession()

let prompt = "Write me a story about coffee."
let response = try await session.respond(
    to: prompt,
    options: options
)
```

When you test apps that use the framework, use Xcode Instruments to understand more about the requests you make, like the time it takes to perform a request. When you make a request, you can access the [doc://com.apple.foundationmodels/documentation/FoundationModels/Transcript](https://developer.apple.com/documentation/FoundationModels/Transcript) entries that describe the actions the model takes during your [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession).

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models)*
--- END FILE ---

--- FILE: LanguageModelSession.md ---
# LanguageModelSession

**An object that represents a session that interacts with a language model.**

## Availability

- **iOS** 26.0+
- **iPadOS** 26.0+
- **Mac Catalyst** 26.0+
- **macOS** 26.0+
- **visionOS** 26.0+


## Overview

A session is a single context that you use to generate content with, and maintains state between requests. You can reuse the existing instance or create a new one each time you call the model. When you create a session you can provide instructions that tells the model what its role is and provides guidance on how to respond.

```swift
let session = LanguageModelSession(instructions: """
    You are a motivational workout coach that provides quotes to inspire \
    and motivate athletes.
    """
)
let prompt = "Generate a motivational quote for my next workout."
let response = try await session.respond(to: prompt)
```

The framework records each call to the model in a [doc://com.apple.foundationmodels/documentation/FoundationModels/Transcript](https://developer.apple.com/documentation/FoundationModels/Transcript) that includes all prompts and responses. If your session exceeds the available context size, it throws [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)).

## Topics

### Creating a session

- [init(model:tools:instructions:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/init(model:tools:instructions:)) — Start a new session in blank slate state with instructions builder.
- [SystemLanguageModel](https://developer.apple.com/documentation/foundationmodels/systemlanguagemodel) — An on-device large language model capable of text generation tasks.
- [Tool](https://developer.apple.com/documentation/foundationmodels/tool) — A tool that a model can call to gather information at runtime or perform side effects.
- [Instructions](https://developer.apple.com/documentation/foundationmodels/instructions) — Details you provide that define the model’s intended behavior on prompts.
### Creating a session from a transcript

- [init(model:tools:transcript:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/init(model:tools:transcript:)) — Start a session by rehydrating from a transcript.
- [Transcript](https://developer.apple.com/documentation/foundationmodels/transcript) — A transcript contains a linear history of [doc://com.apple.foundationmodels/documentation/FoundationModels/Transcript/Entry](https://developer.apple.com/documentation/FoundationModels/Transcript/Entry) entries.
### Preloading the model

- [prewarm(promptPrefix:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/prewarm(promptprefix:)) — Requests that the system eagerly load the resources required for this session into memory and optionally caches a prefix of your prompt.
### Inspecting session properties

- [isResponding](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/isresponding) — A Boolean value that indicates a response is being generated.
- [transcript](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/transcript) — A full history of interactions, including user inputs and model responses.
### Generating a request

- [respond(options:prompt:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/respond(options:prompt:)) — Produces a response to a prompt.
- [respond(generating:includeSchemaInPrompt:options:prompt:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/respond(generating:includeschemainprompt:options:prompt:)) — Produces a generable object as a response to a prompt.
- [respond(schema:includeSchemaInPrompt:options:prompt:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/respond(schema:includeschemainprompt:options:prompt:)) — Produces a generated content type as a response to a prompt and schema.
- [respond(to:options:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/respond(to:options:)) — Produces a response to a prompt.
- [respond(to:generating:includeSchemaInPrompt:options:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/respond(to:generating:includeschemainprompt:options:)) — Produces a generable object as a response to a prompt.
- [respond(to:schema:includeSchemaInPrompt:options:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/respond(to:schema:includeschemainprompt:options:)) — Produces a generated content type as a response to a prompt and schema.
- [Prompt](https://developer.apple.com/documentation/foundationmodels/prompt) — A prompt from a person to the model.
- [LanguageModelSession.Response](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/response) — A structure that stores the output of a response call.
- [GenerationOptions](https://developer.apple.com/documentation/foundationmodels/generationoptions) — Options that control how the model generates its response to a prompt.
### Streaming a response

- [streamResponse(to:options:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/streamresponse(to:options:)) — Produces a response stream to a prompt.
- [streamResponse(to:generating:includeSchemaInPrompt:options:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/streamresponse(to:generating:includeschemainprompt:options:)) — Produces a response stream to a prompt and schema.
- [streamResponse(to:schema:includeSchemaInPrompt:options:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/streamresponse(to:schema:includeschemainprompt:options:)) — Produces a response stream to a prompt and schema.
- [streamResponse(options:prompt:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/streamresponse(options:prompt:)) — Produces a response stream to a prompt.
- [streamResponse(generating:includeSchemaInPrompt:options:prompt:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/streamresponse(generating:includeschemainprompt:options:prompt:)) — Produces a response stream for a type.
- [streamResponse(schema:includeSchemaInPrompt:options:prompt:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/streamresponse(schema:includeschemainprompt:options:prompt:)) — Produces a response stream to a prompt and schema.
- [LanguageModelSession.ResponseStream](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/responsestream) — An async sequence of snapshots of partially generated content.
- [GeneratedContent](https://developer.apple.com/documentation/foundationmodels/generatedcontent) — A type that represents structured, generated content.
- [ConvertibleFromGeneratedContent](https://developer.apple.com/documentation/foundationmodels/convertiblefromgeneratedcontent) — A type that can be initialized from generated content.
- [ConvertibleToGeneratedContent](https://developer.apple.com/documentation/foundationmodels/convertibletogeneratedcontent) — A type that can be converted to generated content.
### Generating feedback

- [logFeedbackAttachment(sentiment:issues:desiredOutput:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/logfeedbackattachment(sentiment:issues:desiredoutput:)) — Logs and serializes data that includes session information that you attach when reporting feedback to Apple.
### Getting the error types

- [LanguageModelSession.GenerationError](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/generationerror) — An error that may occur while generating a response.
- [LanguageModelSession.ToolCallError](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/toolcallerror) — An error that occurs while a system language model is calling a tool.
### Instance Methods

- [logFeedbackAttachment(sentiment:issues:desiredResponseContent:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/logfeedbackattachment(sentiment:issues:desiredresponsecontent:))
- [logFeedbackAttachment(sentiment:issues:desiredResponseText:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/logfeedbackattachment(sentiment:issues:desiredresponsetext:))

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession)*
--- END FILE ---

--- FILE: Foundation-Models.md ---
# Foundation Models

**Perform tasks with the on-device model that specializes in language understanding, structured output, and tool calling.**

## Availability

- **iOS** 26.0+
- **iPadOS** 26.0+
- **Mac Catalyst** 26.0+
- **macOS** 26.0+
- **visionOS** 26.0+


## Overview

The Foundation Models framework provides access to Apple’s on-device large language model that powers Apple Intelligence to help you perform intelligent tasks specific to your use case. The text-based on-device model identifies patterns that allow for generating new text that’s appropriate for the request you make, and it can make decisions to call code you write to perform specialized tasks.

![Image](foundation-models-hero)

Generate text content based on requests you make. The on-device model excels at a diverse range of text generation tasks, like summarization, entity extraction, text understanding, refinement, dialog for games, generating creative content, and more.

Generate entire Swift data structures with guided generation. With the `@Generable` macro, you can define custom data structures and the framework provides strong guarantees that the model generates instances of your type.

To expand what the on-device foundation model can do, use [doc://com.apple.foundationmodels/documentation/FoundationModels/Tool](https://developer.apple.com/documentation/FoundationModels/Tool) to create custom tools that the model can call to assist with handling your request. For example, the model can call a tool that searches a local or online database for information, or calls a service in your app.

To use the on-device language model, people need to turn on Apple Intelligence on their device. For a list of supported devices, see [https://www.apple.com/apple-intelligence/](https://www.apple.com/apple-intelligence/).

For more information about acceptable usage of the Foundation Models framework, see [https://developer.apple.com/apple-intelligence/acceptable-use-requirements-for-the-foundation-models-framework](https://developer.apple.com/apple-intelligence/acceptable-use-requirements-for-the-foundation-models-framework).


### Related videos


### Related Links

- doc://com.apple.documentation/videos/play/wwdc2025/286

- doc://com.apple.documentation/videos/play/wwdc2025/301

- doc://com.apple.documentation/videos/play/wwdc2025/259

## Topics

### Essentials

- [Generating content and performing tasks with Foundation Models](https://developer.apple.com/documentation/foundationmodels/generating-content-and-performing-tasks-with-foundation-models) — Enhance the experience in your app by prompting an on-device large language model.
- [Improving the safety of generative model output](https://developer.apple.com/documentation/foundationmodels/improving-the-safety-of-generative-model-output) — Create generative experiences that appropriately handle sensitive inputs and respect people.
- [Support languages and locales with Foundation Models](https://developer.apple.com/documentation/foundationmodels/support-languages-and-locales-with-foundation-models) — Generate content in the language people prefer when they interact with your app.
- [Adding intelligent app features with generative models](https://developer.apple.com/documentation/foundationmodels/adding-intelligent-app-features-with-generative-models) — Build robust apps with guided generation and tool calling by adopting the Foundation Models framework.
- [SystemLanguageModel](https://developer.apple.com/documentation/foundationmodels/systemlanguagemodel) — An on-device large language model capable of text generation tasks.
- [SystemLanguageModel.UseCase](https://developer.apple.com/documentation/foundationmodels/systemlanguagemodel/usecase) — A type that represents the use case for prompting.
### Prompting

- [LanguageModelSession](https://developer.apple.com/documentation/foundationmodels/languagemodelsession) — An object that represents a session that interacts with a language model.
- [Instructions](https://developer.apple.com/documentation/foundationmodels/instructions) — Details you provide that define the model’s intended behavior on prompts.
- [Prompt](https://developer.apple.com/documentation/foundationmodels/prompt) — A prompt from a person to the model.
- [Transcript](https://developer.apple.com/documentation/foundationmodels/transcript) — A transcript contains a linear history of [doc://com.apple.foundationmodels/documentation/FoundationModels/Transcript/Entry](https://developer.apple.com/documentation/FoundationModels/Transcript/Entry) entries.
- [GenerationOptions](https://developer.apple.com/documentation/foundationmodels/generationoptions) — Options that control how the model generates its response to a prompt.
### Guided generation

- [Generating Swift data structures with guided generation](https://developer.apple.com/documentation/foundationmodels/generating-swift-data-structures-with-guided-generation) — Create robust apps by describing output you want programmatically.
- [Generable](https://developer.apple.com/documentation/foundationmodels/generable) — A type that the model uses when responding to prompts.
### Tool calling

- [Expanding generation with tool calling](https://developer.apple.com/documentation/foundationmodels/expanding-generation-with-tool-calling) — Build tools that enable the model to perform tasks that are specific to your use case.
- [Generate dynamic game content with guided generation and tools](https://developer.apple.com/documentation/foundationmodels/generate-dynamic-game-content-with-guided-generation-and-tools) — Make gameplay more lively with AI generated dialog and encounters personalized to the player.
- [Tool](https://developer.apple.com/documentation/foundationmodels/tool) — A tool that a model can call to gather information at runtime or perform side effects.
### Feedback

- [LanguageModelFeedback](https://developer.apple.com/documentation/foundationmodels/languagemodelfeedback) — Feedback appropriate for logging or attaching to Feedback Assistant.
### Macros

- [Guide(description:semantics:)](https://developer.apple.com/documentation/foundationmodels/guide(description:semantics:))
- [Guide(description:semantics:_:)](https://developer.apple.com/documentation/foundationmodels/guide(description:semantics:_:))

### Related Resources

- [Meet the Foundation Models framework](https://developer.apple.com/videos/play/wwdc2025/286)
- [Deep dive into the Foundation Models framework](https://developer.apple.com/videos/play/wwdc2025/301)
- [Code-along: Bring on-device AI to your app using the Foundation Models framework](https://developer.apple.com/videos/play/wwdc2025/259)

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels)*
--- END FILE ---

--- FILE: Improving-the-safety-of-generative-model-output.md ---
# Improving the safety of generative model output

**Create generative experiences that appropriately handle sensitive inputs and respect people.**


## Overview

Generative AI models have powerful creativity, but with this creativity comes the risk of unintended or unexpected results. For any generative AI feature, safety needs to be an essential part of your design.

The Foundation Models framework has two base layers of safety, where the framework uses:

- An on-device language model that has training to handle sensitive topics with care.

- *Guardrails* that aim to block harmful or sensitive content, such as self-harm, violence, and adult materials, from both model input and output.

Because safety risks are often contextual, some harms might bypass both built-in framework safety layers. It’s vital to design additional safety layers specific to your app. When developing your feature, decide what’s acceptable or might be harmful in your generative AI feature, based on your app’s use case, cultural context, and audience.

For more information on designing generative AI experiences responsibly, see Human Interface Guidelines > Foundations > [https://developer.apple.com/design/human-interface-guidelines/generative-ai](https://developer.apple.com/design/human-interface-guidelines/generative-ai).


## Handle guardrail errors

When you send a prompt to the model, [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/Guardrails](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/Guardrails) check the input prompt and the model’s output. If either fails the guardrail’s safety check, the model session throws a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)) error:

```swift
do {
    let session = LanguageModelSession()
    let topic = // A potentially harmful topic.
    let prompt = "Write a respectful and funny story about \(topic)."
    let response = try await session.respond(to: prompt)
} catch LanguageModelSession.GenerationError.guardrailViolation {
    // Handle the safety error.
}
```

If you encounter a guardrail violation error for any built-in prompt in your app, experiment with re-phrasing the prompt to determine which phrases are activating the guardrails, and avoid those phrases. If the error is thrown in response to a prompt created by someone using your app, give people a clear message that explains the issue. For example, you might say “Sorry, this feature isn’t designed to handle that kind of input” and offer people the opportunity to try a different prompt.


## Handle model refusals

The on-device language model may not be suitable for handling all requests and may refuse requests for a topic. When you generate a string response, and the model refuses a request, it generates a message that begins with a refusal like “Sorry, I can’t help with”.

Design your app experience with refusal messages in mind and present the message to the person using your app. You might not be able to programmatically determine whether a string response is a normal response or a refusal, so design the experience to anticipate both. If it’s critical to determine whether the response is a refusal message, initialize a new [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession) and prompt the model to classify whether the string is a refusal.

When you use guided generation to generate Swift structures or types, there’s no placeholder for a refusal message. Instead, the model throws a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/refusal(_:_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/refusal(_:_:)) error. When you catch the error, you can ask the model to generate a string refusal message:

```swift
do {
    let session = LanguageModelSession()
    let topic = ""  // A sensitive topic.
    let response = try session.respond(
        to: "List five key points about: \(topic)",
        generating: [String].self
    )
} catch LanguageModelSession.GenerationError.refusal(let refusal, _) {
    // Generate an explanation for the refusal.
    if let message = try? await refusal.explanation {
        // Display the refusal message.
    }
}
```

Display the explanation in your app to tell people why a request failed, and offer people the opportunity to try a different prompt. Retrieving an explanation message is asynchronous and takes time for the model to generate.

If you encounter a refusal message, or refusal error, for any built-in prompts in your app, experiment with re-phrasing your prompt to avoid any sensitive topics that might cause the refusal.

For more information about guided generation, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation).


## Build boundaries on input and output

Safety risks increase when a prompt includes direct input from a person using your app, or from an unverified external source, like a webpage. An untrusted source makes it difficult to anticipate what the input contains. Whether accidentally or on purpose, someone could input sensitive content that causes the model to respond poorly.


> **TIP**: The more you can define the intended usage and outcomes for your feature, the more you can ensure generation works great for your app’s specific use cases. Add boundaries to limit out-of-scope usage and minimize low generation quality from out-of-scope uses.


Whenever possible, avoid open input in prompts and place boundaries for controlling what the input can be. This approach helps when you want generative content to stay within the bounds of a particular topic or task. For the highest level of safety on input, give people a fixed set of prompts to choose from. This gives you the highest certainty that sensitive content won’t make its way into your app:

```swift
enum TopicOptions {
    case family
    case nature
    case work 
}
let topicChoice = TopicOptions.nature
let prompt = """
    Generate a wholesome and empathetic journal prompt that helps \
    this person reflect on \(topicChoice)
    """
```

If your app allows people to freely input a prompt, placing boundaries on the output can also offer stronger safety guarantees. Using guided generation, create an enumeration to restrict the model’s output to a set of predefined options designed to be safe no matter what:

```swift
@Generable
enum Breakfast {
    case waffles
    case pancakes
    case bagels
    case eggs 
}
let session = LanguageModelSession()
let userInput = "I want something sweet."
let prompt = "Pick the ideal breakfast for request: \(userInput)"
let response = try await session.respond(to: prompt, generating: Breakfast.self)
```


## Instruct the model for added safety

Consider adding detailed session [doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) that tell the model how to handle sensitive content. The language model prioritizes following its instructions over any prompt, so instructions are an effective tool for improving safety and overall generation quality. Use uppercase words to emphasize the importance of certain phrases for the model:

```swift
do {
    let instructions = """
        ALWAYS respond in a respectful way. \
        If someone asks you to generate content that might be sensitive, \
        you MUST decline with 'Sorry, I can't do that.'
        """
    let session = LanguageModelSession(instructions: instructions)
    let prompt = // Open input from a person using the app.
    let response = try await session.respond(to: prompt)
} catch LanguageModelSession.GenerationError.guardrailViolation {
    // Handle the safety error.
}
```


> **NOTE**: A session obeys instructions over a prompt, so don’t include input from people or any unverified input in the instructions. Using unverified input in instructions makes your app vulnerable to prompt injection attacks, so write instructions with content you trust.


If you want to include open-input from people, instructions for safety are recommended. For an additional layer of safety, use a format string in normal prompts that wraps people’s input in your own content that specifies how the model should respond:

```swift
let userInput = // The input a person enters in the app.
let prompt = """
    Generate a wholesome and empathetic journal prompt that helps \
    this person reflect on their day. They said: \(userInput)
    """
```


## Add a deny list of blocked terms

If you allow prompt input from people or outside sources, consider adding your own deny list of terms. A deny list is anything you don’t want people to be able to input to your app, including unsafe terms, names of people or products, or anything that’s not relevant to the feature you provide. Implement a deny list similarly to guardrails by creating a function that checks the input and the model output:

```swift
let session = LanguageModelSession()
let userInput = // The input a person enters in the app.
let prompt = "Generate a wholesome story about: \(userInput)"

// A function you create that evaluates whether the input 
// contains anything in your deny list.
if verifyText(prompt) { 
    let response = try await session.respond(to: prompt)
    
    // Compare the output to evaluate whether it contains anything in your deny list.
    if verifyText(response.content) { 
        return response 
    } else {
        // Handle the unsafe output.
    }
} else {
    // Handle the unsafe input.
}
```

A deny list can be a simple list of strings in your code that you distribute with your app. Alternatively, you can host a deny list on a server so your app can download the latest deny list when it’s connected to the network. Hosting your deny list allows you to update your list when you need to and avoids requiring a full app update if a safety issue arise.


## Use permissive guardrail mode for sensitive content

The default [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel) guardrails may throw a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)) error for sensitive source material. For example, it may be appropriate for your app to work with certain inputs from people and unverified sources that might contain sensitive content:

- When you want the model to tag the topic of conversations in a chat app when some messages contain profanity.

- When you want to use the model to explain notes in your study app that discuss sensitive topics.

To allow the model to reason about sensitive source material, use [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/Guardrails/permissiveContentTransformations](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/Guardrails/permissiveContentTransformations) when you initialize [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel):

```swift
let model = SystemLanguageModel(guardrails: .permissiveContentTransformations)
```

This mode only works for generating a string value. When you use guided generation, the framework runs the default guardrails against model input and output as usual, and generates [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)) and [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/refusal(_:_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/refusal(_:_:))errors as usual.

Before you use permissive content mode, consider what’s appropriate for your audience. The session skips the guardrail checks in this mode, so it never throws a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/guardrailViolation(_:)) error when generating string responses.

However, even with the [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel) guardrails off, the on-device system language model still has a layer of safety. For some content, the model may still produce a refusal message that’s similar to, “Sorry, I can’t help with.”


## Create a risk assessment

Conduct a risk assessment to proactively address what might go wrong. Risk assessment is an exercise that helps you brainstorm potential safety risks in your app and map each risk to an actionable mitigation. You can write a risk assessment in any format that includes these essential elements:

- List each AI feature in your app.

- For each feature, list possible safety risks that could occur, even if they seem unlikely.

- For each safety risk, score how serious the harm would be if that thing occurred, from mild to critical.

- For each safety risk, assign a strategy for how you’ll mitigate the risk in your app.

For example, an app might include one feature with the fixed-choice input pattern for generation and one feature with the open-input pattern for generation, which is higher safety risk:

Besides obvious harms, like a poor-quality model output, think about how your generative AI feature might affect people, including real-world scenarios where someone might act based on information generated by your app.


## Write and maintain safety tests

Although most people will interact with your app in respectful ways, it’s important to anticipate possible failure modes where certain input or contexts could cause the model to generate something harmful. Especially if your app takes input from people, test your experience’s safety on input like:

- Input that is nonsensical, snippets of code, or random characters.

- Input that includes sensitive content.

- Input that includes controversial topics.

- Vague or unclear input that could be misinterpreted.

Create a list of potentially harmful prompt inputs that you can run as part of your app’s tests. Include every prompt in your app — even safe ones — as part of your app testing. For each prompt test, log the timestamp, full input prompt, the model’s response, and whether it activates any built-in safety or mitigations you’ve included in your app. When starting out, manually read the model’s response on all tests to ensure it meets your design and safety goals. To scale your tests, consider using a frontier LLM to auto-grade the safety of each prompt. Building a test pipeline for prompts and safety is a worthwhile investment for tracking changes in how your app responds over time.

Someone might purposefully attempt to break your feature or produce bad output — especially someone who won’t be harmed by their actions. But, keep in mind that it’s very important to identify cases where someone might *accidentally* be harmed during normal app use.


> **TIP**: Prioritize protecting people using your app with good intentions. Accidental safety failures often only occur in specific contexts, which make them hard to identify during testing. Test for a longer series of interactions, and test for inputs that could become sensitive only when combined with other aspects of your app.


Don’t engage in any testing that could cause you or others harm. Apple’s built-in responsible AI and safety measures, like safety guardrails, are built by experts with extensive training and support. These built-in measures aim to block egregious harms, allowing you to focus on the borderline harmful cases that need your judgement. Before conducting any safety testing, ensure that you’re in a safe location and that you have the health and well-being support you need.


## Report safety concerns

Somewhere in your app, it’s important to include a way that people can report potentially harmful content. Continuously monitor the feedback you receive, and be responsive to quickly handling any safety issues that arise. If someone reports a safety concern that you believe isn’t being properly handled by Apple’s built-in guardrails, report it to Apple with [https://support.apple.com/guide/feedback-assistant/get-started-fbab81460adb/mac](https://support.apple.com/guide/feedback-assistant/get-started-fbab81460adb/mac).

The Foundation Models framework offers utilities for feedback. Use [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelFeedback](https://developer.apple.com/documentation/FoundationModels/LanguageModelFeedback) to retrieve language model session transcripts from people using your app. After collecting feedback, you can serialize it into a JSON file and include it in the report you send with Feedback Assistant.


## Monitor safety for model or guardrail updates

Apple releases updates to the system model as part of regular OS updates. If you participate in the developer beta program you can test your app with new model version ahead of people using your app. When the model updates, it’s important to re-run your full prompt tests in addition to your adversarial safety tests because the model’s response may change. Your risk assessment can help you track any change to safety risks in your app.

Apple may update the built-in guardrails at any time outside of the regular OS update cycle. This is done to rapidly respond, for example, to reported safety concerns that require a fast response. Include all of the prompts you use in your app in your test suite, and run tests regularly to identify when prompts start activating the guardrails.

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/improving-the-safety-of-generative-model-output](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/improving-the-safety-of-generative-model-output)*
--- END FILE ---

--- FILE: Generating-content-and-performing-tasks-with-Foundation-Models.md ---
# Generating content and performing tasks with Foundation Models

**Enhance the experience in your app by prompting an on-device large language model.**


## Overview

The Foundation Models framework lets you tap into the on-device large models at the core of Apple Intelligence. You can enhance your app by using generative models to create content or perform tasks. The framework supports language understanding and generation based on model capabilities.

For design guidance, see Human Interface Guidelines > Technologies > [https://developer.apple.com/design/human-interface-guidelines/generative-ai](https://developer.apple.com/design/human-interface-guidelines/generative-ai).


## Understand model capabilities

When considering features for your app, it helps to know what the on-device language model can do. The on-device model supports text generation and understanding that you can use to:

The on-device language model may not be suitable for handling all requests, like:

The model can complete complex generative tasks when you use guided generation or tool calling. For more on handling complex tasks, or tasks that require extensive world-knowledge, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation) and [doc://com.apple.foundationmodels/documentation/FoundationModels/expanding-generation-with-tool-calling](https://developer.apple.com/documentation/FoundationModels/expanding-generation-with-tool-calling).


## Check for availability

Before you use the on-device model in your app, check that the model is available by creating an instance of [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel) with the [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/default](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/default) property.

Model availability depends on device factors like:

- The device must support Apple Intelligence.

- The device must have Apple Intelligence turned on in Settings.


> **NOTE**: It can take some time for the model to download and become available when a person turns on Apple Intelligence.


Always verify model availability first, and plan for a fallback experience in case the model is unavailable.

```swift
struct GenerativeView: View {
    // Create a reference to the system language model.
    private var model = SystemLanguageModel.default

    var body: some View {
        switch model.availability {
        case .available:
            // Show your intelligence UI.
        case .unavailable(.deviceNotEligible):
            // Show an alternative UI.
        case .unavailable(.appleIntelligenceNotEnabled):
            // Ask the person to turn on Apple Intelligence.
        case .unavailable(.modelNotReady):
            // The model isn't ready because it's downloading or because of other system reasons.
        case .unavailable(let other):
            // The model is unavailable for an unknown reason.
        }
    }
}
```


## Create a session

After confirming that the model is available, create a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession) object to call the model. For a single-turn interaction, create a new session each time you call the model:

```swift
// Create a session with the system model.
let session = LanguageModelSession()
```

For a multiturn interaction — where the model retains some knowledge of what it produced — reuse the same session each time you call the model.


## Provide a prompt to the model

A [doc://com.apple.foundationmodels/documentation/FoundationModels/Prompt](https://developer.apple.com/documentation/FoundationModels/Prompt) is an input that the model responds to. Prompt engineering is the art of designing high-quality prompts so that the model generates a best possible response for the request you make. A prompt can be as short as “hello”, or as long as multiple paragraphs. The process of designing a prompt involves a lot of exploration to discover the best prompt, and involves optimizing prompt length and writing style.

When thinking about the prompt you want to use in your app, consider using conversational language in the form of a question or command. For example, “What’s a good month to visit Paris?” or “Generate a food truck menu.”

Write prompts that focus on a single and specific task, like “Write a profile for the dog breed Siberian Husky”. When a prompt is long and complicated, the model takes longer to respond, and may respond in unpredictable ways. If you have a complex generation task in mind, break the task down into a series of specific prompts.

You can refine your prompt by telling the model exactly how much content it should generate. A prompt like, “Write a profile for the dog breed Siberian Husky” often takes a long time to process as the model generates a full multi-paragraph essay. If you specify “using three sentences”, it speeds up processing and generates a concise summary. Use phrases like “in a single sentence” or “in a few words” to shorten the generation time and produce shorter text.

```swift
// Generate a longer response for a specific command.
let simple = "Write me a story about pears."

// Quickly generate a concise response.
let quick = "Write the profile for the dog breed Siberian Husky using three sentences."
```


## Provide instructions to the model

[doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) help steer the model in a way that fits the use case of your app. The model obeys prompts at a lower priority than the instructions you provide. When you provide instructions to the model, consider specifying details like:

- What the model’s role is; for example, “You are a mentor,” or “You are a movie critic”.

- What the model should do, like “Help the person extract calendar events,” or “Help the person by recommending search suggestions”.

- What the style preferences are, like “Respond as briefly as possible”.

- What the possible safety measures are, like “Respond with ‘I can’t help with that’ if you’re asked to do something dangerous”.

Use content you trust in instructions because the model follows them more closely than the prompt itself. When you initialize a session with instructions, it affects all prompts the model responds to in that session. Instructions can also include example responses to help steer the model. When you add examples to your prompt, you provide the model with a template that shows the model what a good response looks like.


## Generate a response

To call the model with a prompt, call [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/respond(to:options:)-b2re](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/respond(to:options:)-b2re) on your session. The response call is asynchronous because it may take a few seconds for the on-device foundation model to generate the response.

```swift
let instructions = """
    Suggest five related topics. Keep them concise (three to seven words) and make sure they \
    build naturally from the person's topic.
    """

let session = LanguageModelSession(instructions: instructions)

let prompt = "Making homemade bread"
let response = try await session.respond(to: prompt)
```


> **NOTE**: A session can only handle a single request at a time, and causes a runtime error if you call it again before the previous request finishes. Check [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/isResponding](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/isResponding) to verify the session is done processing the previous request before sending a new one.


Instead of working with raw string output from the model, the framework offers guided generation to generate a custom Swift data structure you define. For more information about guided generation, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation).

When you make a request to the model, you can provide custom tools to help the model complete the request. If the model determines that a [doc://com.apple.foundationmodels/documentation/FoundationModels/Tool](https://developer.apple.com/documentation/FoundationModels/Tool) can assist with the request, the framework calls your [doc://com.apple.foundationmodels/documentation/FoundationModels/Tool](https://developer.apple.com/documentation/FoundationModels/Tool) to perform additional actions like retrieving content from your local database. For more information about tool calling, see [doc://com.apple.foundationmodels/documentation/FoundationModels/expanding-generation-with-tool-calling](https://developer.apple.com/documentation/FoundationModels/expanding-generation-with-tool-calling)


## Consider context size limits per session

The *context window size* is a limit on how much data the model can process for a session instance. A token is a chunk of text the model processes, and the system model supports up to 4,096 tokens. A single token corresponds to three or four characters in languages like English, Spanish, or German, and one token per character in languages like Japanese, Chinese, or Korean. In a single session, the sum of all tokens in the instructions, all prompts, and all outputs count toward the context window size.

If your session processes a large amount of tokens that exceed the context window, the framework throws the error [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)). When you encounter the error, start a new session and try shortening your prompts. If you need to process a large amount of data that won’t fit in a single context window limit, break your data into smaller chunks, process each chunk in a separate session, and then combine the results.


## Tune generation options and optimize performance

To get the best results for your prompt, experiment with different generation options. [doc://com.apple.foundationmodels/documentation/FoundationModels/GenerationOptions](https://developer.apple.com/documentation/FoundationModels/GenerationOptions) affects the runtime parameters of the model, and you can customize them for every request you make.

```swift
// Customize the temperature to increase creativity.
let options = GenerationOptions(temperature: 2.0)

let session = LanguageModelSession()

let prompt = "Write me a story about coffee."
let response = try await session.respond(
    to: prompt,
    options: options
)
```

When you test apps that use the framework, use Xcode Instruments to understand more about the requests you make, like the time it takes to perform a request. When you make a request, you can access the [doc://com.apple.foundationmodels/documentation/FoundationModels/Transcript](https://developer.apple.com/documentation/FoundationModels/Transcript) entries that describe the actions the model takes during your [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession).

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models)*
--- END FILE ---

--- FILE: LanguageModelSession.md ---
# LanguageModelSession

**An object that represents a session that interacts with a language model.**

## Availability

- **iOS** 26.0+
- **iPadOS** 26.0+
- **Mac Catalyst** 26.0+
- **macOS** 26.0+
- **visionOS** 26.0+


## Overview

A session is a single context that you use to generate content with, and maintains state between requests. You can reuse the existing instance or create a new one each time you call the model. When you create a session you can provide instructions that tells the model what its role is and provides guidance on how to respond.

```swift
let session = LanguageModelSession(instructions: """
    You are a motivational workout coach that provides quotes to inspire \
    and motivate athletes.
    """
)
let prompt = "Generate a motivational quote for my next workout."
let response = try await session.respond(to: prompt)
```

The framework records each call to the model in a [doc://com.apple.foundationmodels/documentation/FoundationModels/Transcript](https://developer.apple.com/documentation/FoundationModels/Transcript) that includes all prompts and responses. If your session exceeds the available context size, it throws [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)).

## Topics

### Creating a session

- [init(model:tools:instructions:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/init(model:tools:instructions:)) — Start a new session in blank slate state with instructions builder.
- [SystemLanguageModel](https://developer.apple.com/documentation/foundationmodels/systemlanguagemodel) — An on-device large language model capable of text generation tasks.
- [Tool](https://developer.apple.com/documentation/foundationmodels/tool) — A tool that a model can call to gather information at runtime or perform side effects.
- [Instructions](https://developer.apple.com/documentation/foundationmodels/instructions) — Details you provide that define the model’s intended behavior on prompts.
### Creating a session from a transcript

- [init(model:tools:transcript:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/init(model:tools:transcript:)) — Start a session by rehydrating from a transcript.
- [Transcript](https://developer.apple.com/documentation/foundationmodels/transcript) — A transcript contains a linear history of [doc://com.apple.foundationmodels/documentation/FoundationModels/Transcript/Entry](https://developer.apple.com/documentation/FoundationModels/Transcript/Entry) entries.
### Preloading the model

- [prewarm(promptPrefix:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/prewarm(promptprefix:)) — Requests that the system eagerly load the resources required for this session into memory and optionally caches a prefix of your prompt.
### Inspecting session properties

- [isResponding](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/isresponding) — A Boolean value that indicates a response is being generated.
- [transcript](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/transcript) — A full history of interactions, including user inputs and model responses.
### Generating a request

- [respond(options:prompt:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/respond(options:prompt:)) — Produces a response to a prompt.
- [respond(generating:includeSchemaInPrompt:options:prompt:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/respond(generating:includeschemainprompt:options:prompt:)) — Produces a generable object as a response to a prompt.
- [respond(schema:includeSchemaInPrompt:options:prompt:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/respond(schema:includeschemainprompt:options:prompt:)) — Produces a generated content type as a response to a prompt and schema.
- [respond(to:options:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/respond(to:options:)) — Produces a response to a prompt.
- [respond(to:generating:includeSchemaInPrompt:options:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/respond(to:generating:includeschemainprompt:options:)) — Produces a generable object as a response to a prompt.
- [respond(to:schema:includeSchemaInPrompt:options:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/respond(to:schema:includeschemainprompt:options:)) — Produces a generated content type as a response to a prompt and schema.
- [Prompt](https://developer.apple.com/documentation/foundationmodels/prompt) — A prompt from a person to the model.
- [LanguageModelSession.Response](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/response) — A structure that stores the output of a response call.
- [GenerationOptions](https://developer.apple.com/documentation/foundationmodels/generationoptions) — Options that control how the model generates its response to a prompt.
### Streaming a response

- [streamResponse(to:options:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/streamresponse(to:options:)) — Produces a response stream to a prompt.
- [streamResponse(to:generating:includeSchemaInPrompt:options:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/streamresponse(to:generating:includeschemainprompt:options:)) — Produces a response stream to a prompt and schema.
- [streamResponse(to:schema:includeSchemaInPrompt:options:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/streamresponse(to:schema:includeschemainprompt:options:)) — Produces a response stream to a prompt and schema.
- [streamResponse(options:prompt:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/streamresponse(options:prompt:)) — Produces a response stream to a prompt.
- [streamResponse(generating:includeSchemaInPrompt:options:prompt:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/streamresponse(generating:includeschemainprompt:options:prompt:)) — Produces a response stream for a type.
- [streamResponse(schema:includeSchemaInPrompt:options:prompt:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/streamresponse(schema:includeschemainprompt:options:prompt:)) — Produces a response stream to a prompt and schema.
- [LanguageModelSession.ResponseStream](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/responsestream) — An async sequence of snapshots of partially generated content.
- [GeneratedContent](https://developer.apple.com/documentation/foundationmodels/generatedcontent) — A type that represents structured, generated content.
- [ConvertibleFromGeneratedContent](https://developer.apple.com/documentation/foundationmodels/convertiblefromgeneratedcontent) — A type that can be initialized from generated content.
- [ConvertibleToGeneratedContent](https://developer.apple.com/documentation/foundationmodels/convertibletogeneratedcontent) — A type that can be converted to generated content.
### Generating feedback

- [logFeedbackAttachment(sentiment:issues:desiredOutput:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/logfeedbackattachment(sentiment:issues:desiredoutput:)) — Logs and serializes data that includes session information that you attach when reporting feedback to Apple.
### Getting the error types

- [LanguageModelSession.GenerationError](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/generationerror) — An error that may occur while generating a response.
- [LanguageModelSession.ToolCallError](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/toolcallerror) — An error that occurs while a system language model is calling a tool.
### Instance Methods

- [logFeedbackAttachment(sentiment:issues:desiredResponseContent:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/logfeedbackattachment(sentiment:issues:desiredresponsecontent:))
- [logFeedbackAttachment(sentiment:issues:desiredResponseText:)](https://developer.apple.com/documentation/foundationmodels/languagemodelsession/logfeedbackattachment(sentiment:issues:desiredresponsetext:))

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession)*
--- END FILE ---

--- FILE: Support-languages-and-locales-with-Foundation-Models.md ---
# Support languages and locales with Foundation Models

**Generate content in the language people prefer when they interact with your app.**


## Overview

The on-device system language model is multilingual, which means the same model understands and generates text in any language that Apple Intelligence supports. The model supports using different languages for prompts, instructions, and the output that the model produces.

When you enhance your app with multilingual support, generate content in the language people prefer to use when they interact with your app by:

- Prompting the model with the language you prefer.

- Including the target language for your app in the instructions you provide the model.

- Determining the language or languages a person wants to use when they interact with your app.

- Gracefully handling languages that Apple Intelligence doesn’t support.

For more information about the languages and locales that Apple Intelligence supports, see the “Supported languages” section in [https://support.apple.com/en-us/121115](https://support.apple.com/en-us/121115).


## Prompt the model in the language you prefer

Write your app’s built-in prompts in the language with which you normally write code, if Apple Intelligence supports that language. Translate your prompts into a supported language if your preferred language isn’t supported. In the code below, *all* inputs need to be in supported language for the model to understand, including all `Generable` types and descriptions:

```swift
@Generable(description: "Basic profile information about a cat")
struct CatProfile {
    var name: String

    @Guide(description: "The age of the cat", .range(0...20))
    var age: Int

    @Guide(description: "One sentence about this cat's personality")
    var profile: String
}

#Playground {
    let response = try await LanguageModelSession().respond(
        to: "Generate a rescue cat",
        generating: CatProfile.self
    )
}
```

Because the framework treats `Generable` types as model inputs, the names of properties like `age` or `profile` are just as important as the `@Guide` descriptions for helping the model understand your request.


## Check a person’s language settings for your app

People can use the Settings app on their device to configure the language they prefer to use on a per-app basis, which might differ from their default language. If your app supports a language that Apple Intelligence doesn’t, you need to verify that the current language setting of your app is supported before you call the model. Keep in mind that language support improves over time in newer model and OS versions. Thus, someone using your app with an older OS may not have the latest language support.

Before you call the model, run [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/supportsLocale(_:)](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/supportsLocale(_:)) to verify the support for a locale. By default, the method uses [doc://com.apple.documentation/documentation/Foundation/Locale/current](https://developer.apple.com/documentation/Foundation/Locale/current), which takes into account a person’s current language and app-specific settings. This method returns true if the model supports this locale, or if this locale is considered similar enough to a supported locale, such as `en-AU` and `en-NZ`:

```swift
if SystemLanguageModel.default.supportsLocale() {
    // Language is supported.
}
```

For advanced use cases where you need full language support details, use [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/supportedLanguages](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/supportedLanguages) to retrieve a list of languages supported by the on-device model.


## Handle an unsupported language or locale errors

When you call [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/respond(to:options:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/respond(to:options:)) on a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession), the Foundation Models framework checks the language or languages of the input prompt text, and whether your prompt asks the model to respond in any specific language or languages. If the model detects a language it doesn’t support, the session throws [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/unsupportedLanguageOrLocale(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/unsupportedLanguageOrLocale(_:)). Handle the error by communicating to the person using your app that a language in their request is unsupported.

If your app supports languages or locales that Apple Intelligence doesn’t, help people that use your app by:

- Explaining that their language isn’t supported by Apple Intelligence in your app.

- Disabling your Foundation Models framework feature.

- Providing an alternative app experience, if possible.


> **IMPORTANT**: Guardrails for model input and output safety are only for supported languages and locales. If a prompt contains sensitive content in an unsupported language, which typically is a short phrase mixed-in with text in a supported language, it might not throw a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/unsupportedLanguageOrLocale(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/unsupportedLanguageOrLocale(_:)) error. If unsupported-language detection fails, the guardrails may also fail to flag that short, unsupported content. For more on guardrails, see [doc://com.apple.foundationmodels/documentation/FoundationModels/improving-the-safety-of-generative-model-output](https://developer.apple.com/documentation/FoundationModels/improving-the-safety-of-generative-model-output).



## Use Instructions to set the language for model output

By default, the model responds in the language or languages of its inputs. If your app supports multiple languages, prompts that you write and inputs from people using your app, might be in different languages. For example, if you write your built-in prompts in Spanish, but someone using your app writes inputs in Dutch, the model may respond in either or both languages. If this issue occurs, use [doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) to explicitly tell the model which language or languages with which it needs to respond.

First, to ensure the best response quality, start your [doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) by using this *exact* phrase in English. This special phrase comes from the model’s training, and reduces the possibility of hallucinations in multilingual situations:

```swift
func localeInstructions(for locale: Locale = Locale.current) -> String {
    return "The user's locale is \(locale.identifier)."
}
```

Next, continue your [doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) with a phrase that tells the model which language or languages to use in its output. You can phrase this request in different ways, for example: “You MUST respond in Italian” or “You MUST respond in Italian and be mindful of Italian spelling, vocabulary, entities, and other cultural context of Italy.” These instructions can be in your preferred language.

Finally, thoroughly test your instructions to ensure the model is responding in the way you expect. If the model isn’t following your instructions, try capitalized words like “MUST” or “ALWAYS” to strengthen your instructions.

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/support-languages-and-locales-with-foundation-models](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/support-languages-and-locales-with-foundation-models)*
--- END FILE ---

--- FILE: Deep_dive_into_Foundation_Models_Framework.md ---
Hi, I’m Louis. Today we’ll look at getting the most out of the Foundation Models framework.

As you may know, the Foundation Models framework gives you direct access to an on-device Large Language Model, with a convenient Swift API. It’s available on macOS, iPadOS, iOS, and visionOS. And because it runs on-device, using it in your project is just a simple import away. In this video, we will look at how sessions work with Foundation Models. How to use Generable to get structured output. How to get structured output with dynamic schemas defined at runtime, and using tool calling to let the model call into your custom functions.

Let’s start simple, by generating text with a session.

Now, I've been working on this pixel art game about a coffee shop, and I think it could be really fun to use Foundation Models to generate game dialog and other content to make it feel more alive! We can prompt the model to respond to a player's question, so our barista gives a unique dialog.

To do this, we'll create a LanguageModelSession with custom instructions. This let's us tell the model what its purpose is for this session and for the prompt we'll take the user's input. And that's really all it takes for a pretty fun new game element. Let's ask the Barista "How long have you worked here?", and let it respond to our question.

```swift
import FoundationModels

func respond(userInput: String) async throws -> String {
  let session = LanguageModelSession(instructions: """
    You are a friendly barista in a world full of pixels.
    Respond to the player's question.
    """
  )
  let response = try await session.respond(to: userInput)
  return response.content
}
```

That was generated entirely on-device. Pretty amazing. But how does this actually work? Let’s get a better sense of how Foundation Models generates text, and what to look out for. When you call respond(to:) on a session, it first takes your session’s instructions, and the prompt, in this case the user’s input, and it turns that text into tokens. Tokens are small substrings, sometimes a word but typically just a few characters. A large language model takes a sequence of tokens as input, and it then generates a new sequence of tokens as output. You don’t have to worry about the exact tokens that Foundation Models operates with, the API nicely abstracts that away for you. But it is important to understand that tokens are not free. Each token in your instructions and prompt adds extra latency. Before the model can start producing response tokens, it first needs to process all the input tokens. And generating tokens also has a computational cost, which is why longer outputs take longer to generate.

A LanguageModelSession is stateful. Each respond(to:) call is recorded in the transcript.

The transcript includes all prompts and responses for a given session.

This can be useful for debugging, or even showing it in your UI.

But a session has a limit for how large it can grow.

If you’re making a lot of requests, or if you’re giving a large prompt or getting large outputs, you can hit the context limit.

If your session exceeds the available context size, it will throw an error, which you should be prepared to catch.

Back in our game, when we're talking with a character and hit an error, the conversation just ends, which is unfortunate, I was just getting to know this character! Luckily there are ways to recover from this error.

You can catch the exceededContextWindowSize error.

```swift
var session = LanguageModelSession()

do {
  let answer = try await session.respond(to: prompt)
  print(answer.content)
} catch LanguageModelSession.GenerationError.exceededContextWindowSize {
  // New session, without any history from the previous session.
  session = LanguageModelSession()
}
```

And when you do, you can start a brand new session, without any history. But in my game that would mean the character suddenly forgets the whole conversation.

You can also choose some of the transcript from your current session to carry over into the new session.

You can take the entries from a session's transcript, and condense it into a new array of entries.

So for our game dialog, we could take the first entry of the session's transcript, which is the instructions. As well as the last entry, which is the last successful response.

```swift
var session = LanguageModelSession()

do {
  let answer = try await session.respond(to: prompt)
  print(answer.content)
} catch LanguageModelSession.GenerationError.exceededContextWindowSize {
  // New session, with some history from the previous session.
  session = newSession(previousSession: session)
}

private func newSession(previousSession: LanguageModelSession) -> LanguageModelSession {
  let allEntries = previousSession.transcript.entries
  var condensedEntries = [Transcript.Entry]()
  if let firstEntry = allEntries.first {
    condensedEntries.append(firstEntry)
    if allEntries.count > 1, let lastEntry = allEntries.last {
      condensedEntries.append(lastEntry)
    }
  }
  let condensedTranscript = Transcript(entries: condensedEntries)
  // Note: transcript includes instructions.
  return LanguageModelSession(transcript: condensedTranscript)
}
```

And when we pass that into a new session, our character is good to chat with for another while.

But keep in mind, the session's transcript includes the initial instructions as the first entry. When carrying over a transcript for our game character, we definitely want to include those instructions.

Including just a few relevant pieces from the transcript can be a simple, and effective, solution. But sometimes it’s not that simple.

Let’s imagine a transcript with more entries.

You definitely always want to start by carrying over the instructions. But a lot of entries in the transcript might be relevant, so for this use case you could consider summarizing the transcript.

You could do this with some external library, or perhaps even summarize parts of the transcript with Foundation Models itself.

So that’s what you can do with the transcript of a session.

Now let’s take a brief look at how the responses are actually generated.

In our game, when you walk up to the barista, the player can ask any question.

But if you start two new games, and ask the exact same question in each, you will probably get different output. So how does that work? Well that’s where sampling comes in.

When the model is generating its output, it does so one token at a time. And it does this by creating a distribution, for the likelihood of any given token By default, Foundation Models will pick tokens within some probability range. Sometimes it might start by saying "Ah", and other times it might pick "Well" for the first token. This happens for every token that's generated. Picking a token is what we call sampling. And the default behavior is random sampling. Getting varied output is great for use cases like a game. But sometimes you might want deterministic output, like when you're writing a demo that should be repeatable. The GenerationOptions API let's you control the sampling method. You can set it to greedy to get deterministic output. And when that's set, you will get the same output for the same prompt, assuming your session is also in the same state. Although note, this only holds true for a given version of the on-device model. When the model is updated as part of an OS update, your prompt can definitely give different output, even when using greedy sampling.

```swift
// Deterministic output
let response = try await session.respond(
  to: prompt,
  options: GenerationOptions(sampling: .greedy)
)
                
// Low-variance output
let response = try await session.respond(
  to: prompt,
  options: GenerationOptions(temperature: 0.5)
)
                
// High-variance output
let response = try await session.respond(
  to: prompt,
  options: GenerationOptions(temperature: 2.0)
)
```

You can also play with the temperature for the random sampling. For example, setting the temperature to 0.5 to get output that only varies a little. Or setting it to a higher value to get wildly different output for the same prompt.

Also, keep in mind, when taking user input in your prompt, the language might not be supported.

There is the dedicated unsupportedLanguageOrLocale error that you can catch for this case.

This can be a good way to show a custom message in your UI.

```swift
var session = LanguageModelSession()

do {
  let answer = try await session.respond(to: userInput)
  print(answer.content)
} catch LanguageModelSession.GenerationError.unsupportedLanguageOrLocale {
  // Unsupported language in prompt.
}

let supportedLanguages = SystemLanguageModel.default.supportedLanguages
guard supportedLanguages.contains(Locale.current.language) else {
  // Show message
  return
}
```

And there's also an API to check whether the model supports a certain language. For example to checkout if the user's current language is supported, and to show a disclaimer when it's not. So that's an overview of sessions. You can prompt it, which will store the history in the transcript. And you can optionally set the sampling parameter, to control the randomness of the session’s output. But let’s get fancier! When the player walks around, we can generate NPCs, Non Playable Characters, again using Foundation Models. However, this time, we want more complicated output. Instead of just plain text, we’d like a name and a coffee order from the NPC. Generable can help us here.

It can be a challenge to get structured output from a Large Language Model. You could prompt it with the specific fields you expect, and have some parsing code to extract that. But this is hard to maintain, and very fragile, it might not always give the valid keys, which would make the whole method fail.

Luckily, Foundation Models has a much better API, called Generable.

On your struct, you can apply the @Generable macro. So, what is Generable and is that even a word? Well, yes, it is.

```swift
@Generable
struct NPC {
  let name: String
  let coffeeOrder: String
}
```

Generable is an easy way to let the model generate structured data, using Swift types The macro generates a schema at compile time, which the model can use to produce the expected structure.

The macro also generates an initializer, which is automatically called for you when making a request to a session.

So then we can generate instances of our struct. Like before, we'll call the respond method on our session. But this time pass the generating argument telling the model which type to generate.

```swift
@Generable
struct NPC {
  let name: String
  let coffeeOrder: String
}

func makeNPC() async throws -> NPC {
  let session = LanguageModelSession(instructions: ...)
  let response = try await session.respond(generating: NPC.self) {
    "Generate a character that orders a coffee."
  }
  return response.content
}
```

Foundation Models will even automatically include details about your Generable type in the prompt, in a specific format that the model has been trained on. You don't have to tell it about what fields your Generable type has In our game, we'll now get some great generated NPC encounters! Generable is actually more powerful than it might seem. At a low level, this uses constrained decoding, which is a technique to let the model generate text that follows a specific schema.

Remember, that schema that the macro generates.

As we saw before, an LLM generates tokens, which are later transformed into text. And with Generable, that text is even automatically parsed for you in a type-safe way. The tokens are generated in a loop, often referred to as the decoding loop.

Without constrained decoding, the model might hallucinate some invalid field name.

Like `firstName`instead of a name. Which would then fail to be parsed into the NPC type.

But with constrained decoding, the model is prevented from making structural mistakes like this. For every token that’s generated, there’s a distribution of all the tokens in the model’s vocabulary.

And constrained decoding works by masking out the tokens that are not valid. So instead of just picking any token, the model is only allowed to pick valid tokens according to the schema.

And that's all without needing to worry about manually parsing the model's output. Which means you can spend your time on what truly matters, like talking to virtual guests in your coffee shop! Generable is truly the best way to get output from the on-device LLM. And it can do so much more. Not only can you use it on structs, but also on enums! So let's use that to make our encounters more dynamic! Here, I've added an Encounter enum, with two cases. The enum can even contain associated values in its cases, so let's use that to either generate a coffee order, or, to have someone that wants to speak to the manager.

```swift
@Generable
struct NPC {
  let name: String
  let encounter: Encounter

  @Generable
  enum Encounter {
    case orderCoffee(String)
    case wantToTalkToManager(complaint: String)
  }
}
```

Let's checkout what we encounter in our game now! Wow, someone really needs a coffee.

Clearly, not every guest is as easy to deal with, so let's level this up by adding levels to our NPCs.

Generable supports most common Swift types out of the box, including Int. So let's add a level property. But we don't want to generate any integer. If we want the level to be in a specific range, we can specify this using a Guide. We can use the Guide macro on our property, and pass a range.

Again, the model will use constrained decoding, to guarantee a value in this range.

While we're at it, let's also add an array of attributes to our NPC.

```swift
@Generable
struct NPC {
  @Guide(description: "A full name")
  let name: String
  @Guide(.range(1...10))
  let level: Int
  @Guide(.count(3))
  let attributes: [Attribute]
  let encounter: Encounter

  @Generable
  enum Attribute {
    case sassy
    case tired
    case hungry
  }
  @Generable
  enum Encounter {
    case orderCoffee(String)
    case wantToTalkToManager(complaint: String)
  }
}
```

We can again use a guide, this time to specify we want exactly three attributes for this array in our NPC. Keep in mind, the properties of your Generable type are generated in the order they are declared in the source code. Here, name will be generated first, followed by the level, then the attributes, and encounter last.

This order can be important, if you’re expecting the value of a property to be influenced by another property.

And you can even stream property-by-property, if you don’t want to wait until the full output is generated. The game is pretty fun now! Almost ready to share with my friends. But I notice the names of the NPCs aren’t exactly what I had in mind. I would prefer to have a first and last name.

We can use a guide for this, but this time just provide a natural language description.

We can say our name should be a “full name”.

And this is effectively another way of prompting. Instead of having to describe different properties in your prompt, you can do it directly in your Generable type. And it gives the model a stronger relation for what these descriptions are tied to.

If we walk around in our game now, we’ll checkout these new names in action.

Here’s an overview of all the guides you can apply to different types.

With common numerical types, like int, you can specify the minimum, maximum or a range. And with array, you can control the count, or specify guides on the array's element type.

For String, you can let the model pick from an array with anyOf, or even constrain to a regex pattern.

A regex pattern guide is especially powerful. You may be familiar with using a regex for matching against text. But with Foundation Models, you can use a regex pattern to define the structure of a string to generate. For example, you can constrain the name to a set of prefixes.

```swift
@Generable
struct NPC {
  @Guide(Regex {
    Capture {
      ChoiceOf {
        "Mr"
        "Mrs"
      }
    }
    ". "
    OneOrMore(.word)
  })
  let name: String
}

session.respond(to: "Generate a fun NPC", generating: NPC.self)
// > {name: "Mrs. Brewster"}
```

And you can even use the regex builder syntax! If this renews your excitement in regex, make sure to watch the timeless classic "Meet Swift Regex" from a few years ago.

To recap, Generable is a macro that you can apply to structs and enums, and it gives you a reliable way to get structured output from the model. You don't need to worry about any of the parsing, and to get even more specific output, you can apply guides to your properties.

So Generable is great when you know the structure at compile time.

The macro generates the schema for you, and you get an instance of your type as output. But sometimes you only know about a structure at runtime. That's where dynamic schemas can help.

I'm adding a level creator to my game, where players can dynamically define entities to encounter while walking around in the game. For example, a player could create a riddle structure. Where a riddle has a question, and multiple choice answers. If we knew this structure at compile time, we could simply define a Generable struct for it:

```swift
@Generable
struct Riddle {
  let question: String
  let answers: [Answer]

  @Generable
  struct Answer {
    let text: String
    let isCorrect: Bool
  }
}
```

But our level creator allows for creating any structure the player can think of.

We can use DynamicGenerationSchema to create a schema at runtime.

Just like a compile-time defined struct, a dynamic schema has a list of properties. We can add a level creator, that can take a player's input.

Each property has a name and its own schema, which defines its type. You can use the schema for any Generable type, including built-in types, such as String.

A dynamic schema can contain an array, where you then specify a schema for the element of the array. And importantly, a dynamic schema can have references to other dynamic schemas.

So here, our array can reference a custom schema that is also defined at runtime.

From the user's input, we can create a riddle schema, with two properties.

The first is the question, which is a string property. And secondly, an array property, of a custom type called Answer.

And we'll then create the answer. This has a string and boolean property.

Note that the riddle's answers property refers to the answer schema by its name.

```swift
struct LevelObjectCreator {
  var properties: [DynamicGenerationSchema.Property] = []

  mutating func addStringProperty(name: String) {
    let property = DynamicGenerationSchema.Property(
      name: name,
      schema: DynamicGenerationSchema(type: String.self)
    )
    properties.append(property)
  }

  mutating func addArrayProperty(name: String, customType: String) {
    let property = DynamicGenerationSchema.Property(
      name: name,
      schema: DynamicGenerationSchema(
        arrayOf: DynamicGenerationSchema(referenceTo: customType)
      )
    )
    properties.append(property)
  }
  
  var root: DynamicGenerationSchema {
    DynamicGenerationSchema(
      name: name,
      properties: properties
    )
  }
}

var riddleBuilder = LevelObjectCreator(name: "Riddle")
riddleBuilder.addStringProperty(name: "question")
riddleBuilder.addArrayProperty(name: "answers", customType: "Answer")

var answerBuilder = LevelObjectCreator(name: "Answer")
answerBuilder.addStringProperty(name: "text")
answerBuilder.addBoolProperty(name: "isCorrect")

let riddleDynamicSchema = riddleBuilder.root
let answerDynamicSchema = answerBuilder.root

let schema = try GenerationSchema(
  root: riddleDynamicSchema,
  dependencies: [answerDynamicSchema]
)

let session = LanguageModelSession()
let response = try await session.respond(
  to: "Generate a fun riddle about coffee",
  schema: schema
)
let generatedContent = response.content
let question = try generatedContent.value(String.self, forProperty: "question")
let answers = try generatedContent.value([GeneratedContent].self, forProperty: "answers")
```

Then we can create the DynamicGenerationSchema instances. Each dynamic schema is independent. Meaning the riddle dynamic schema doesn't actually contain the answer's dynamic schema. Before we can do inference, we first have to convert our dynamic schemas into a validated schema. This can throw errors if there are inconsistencies in the dynamic schemas, such as type references that don't exist.

And once we have a validated schema, we can prompt a session as usual. But this time, the output type is a GeneratedContent instance. Which holds the dynamic values.

You can query this with the property names from your dynamic schemas. Again, Foundation Models will use guided generation to make sure the output matches your schema. It will never make up an unexpected field! So even though it's dynamic, you still don't have to worry about manually parsing the output.

So now when the player encounters an NPC, the model can generate this dynamic content. Which we’ll show in a dynamic UI. Let’s checkout what we run into. I’m dark or light, bitter or sweet, I wake you up and bring the heat, what am I? Coffee or hot chocolate. I think the answer is coffee.

That's correct! I think my players will have a lot of fun creating all sorts of fun levels.

To recap, with the Generable macro, we can easily generate structured output from a Swift type that’s defined at compile time.

And under the hood, Foundation Models takes care of the schema, and converting the GeneratedContent into an instance of your own type. Dynamic schemas work very similar, but give you much more control. You control the schema entirely at runtime, and get direct access to the GeneratedContent. Next, let’s take a look at tool calling, which can let the model call your own functions. I’m thinking of creating a DLC, downloadable content, to make my game more personal. Using tool calling, I can let the model autonomously fetch information. I’m thinking that integrating the player’s contacts and calendar could be really fun.

I wouldn't normally do that with a server-based model, my players wouldn't appreciate it if the game uploaded such personal data. But since it's all on-device with Foundation Models, we can do this while preserving privacy.

Defining a tool is very easy, with the Tool protocol. You start by giving it a name, and a description. This is what will be put in the prompt, automatically by the API, to let the model decide when and how often to call your tool.

It's best to make your tool name short, but still readable as English text. Avoid abbreviations, and don't make your description too long, or explain any of the implementations. Because remember, these strings are put verbatim in your prompt. So longer strings means more tokens, which can increase the latency. Instead, consider using a verb in the name, such as findContact. And your description should be about one sentence. As always, it's important to try different variations to checkout what works best for your specific tool.

Next, we can define the input for our tool. I want the tool to get contacts from a certain age generation, like millennials. The model will be able to pick a funny case based on the game state, and I can add the Arguments struct, and make it Generable.

When the model decides to call this tool, it will generate the input arguments. By using Generable, this guarantees your tool always gets valid input arguments. So it won't make up a different generation, like gen alpha, which we don't support in our game.

Then I can implement the call function. The model will call this function when it decides to invoke the tool.

In this example, we'll then call out to the Contacts API. And return a contact's name for that query.

```swift
import FoundationModels
import Contacts

struct FindContactTool: Tool {
  let name = "findContact"
  let description = "Finds a contact from a specified age generation."
    
  @Generable
  struct Arguments {
    let generation: Generation
        
    @Generable
    enum Generation {
      case babyBoomers
      case genX
      case millennial
      case genZ            
    }
  }
  
  func call(arguments: Arguments) async throws -> ToolOutput {
    let store = CNContactStore()
        
    let keysToFetch = [CNContactGivenNameKey, CNContactBirthdayKey] as [CNKeyDescriptor]
    let request = CNContactFetchRequest(keysToFetch: keysToFetch)

    var contacts: [CNContact] = []
    try store.enumerateContacts(with: request) { contact, stop in
      if let year = contact.birthday?.year {
        if arguments.generation.yearRange.contains(year) {
          contacts.append(contact)
        }
      }
    }
    guard let pickedContact = contacts.randomElement() else {
      return ToolOutput("Could not find a contact.")
    }
    return ToolOutput(pickedContact.givenName)
  }
}
```

To use our tool, we'll pass it in the session initializer. The model will then call our tool when it wants that extra piece of information.

```swift
import FoundationModels

let session = LanguageModelSession(
  tools: [FindContactTool()],
  instructions: "Generate fun NPCs"
)
```

This is more powerful than just getting the contact ourselves, because the model will only call the tool when it needs for a certain NPC, and it can pick fun input arguments based on the game state. Like the age generation for the NPC.

Keep in mind, this is using the regular contacts API, which you might be familiar with. When our tool is first is invoked, it will ask the player for the usual permission. Even if the player doesn’t want to give access to their contacts, Foundation Models can still generate content like before, but if they do give access, we make it more personal.

Let’s walk around a bit in our game until we encounter another NPC. And this time, I’ll get a name from my contacts! Oh hi there Naomy! Let’s checkout what she has to say, I didn’t know you liked coffee.

Note that LanguageModelSession takes an instance of a tool. This means you control the lifecycle of the tool. The instance of this tool stays the same for the whole session.

Now, in this example, because we're just getting a random character with our FindContactsTool, it's possible we'll get the same contact sometimes. In our game, there are multiple Naomy's now. And that's not right, there can only be the one.

To fix this, we can keep track of the contacts the game has already used. We can add state to our FindContactTool. To do this, we will first convert our FindContactTool to be a class. So it can mutate its state from the call method.

```swift
import FoundationModels
import Contacts

class FindContactTool: Tool {
  let name = "findContact"
  let description = "Finds a contact from a specified age generation."
   
  var pickedContacts = Set<String>()
    
  ...

  func call(arguments: Arguments) async throws -> ToolOutput {
    contacts.removeAll(where: { pickedContacts.contains($0.givenName) })
    guard let pickedContact = contacts.randomElement() else {
      return ToolOutput("Could not find a contact.")
    }
    return ToolOutput(pickedContact.givenName)
  }
}
```

Then we can keep track of the picked contacts, and in our call method we don't pick the same one again.

The NPC names are now based on my contacts! But talking to them doesn't feel right yet. Let's round this off with another tool, this time for accessing my calendar.

```swift
import FoundationModels
import EventKit

struct GetContactEventTool: Tool {
  let name = "getContactEvent"
  let description = "Get an event with a contact."

  let contactName: String
    
  @Generable
  struct Arguments {
    let day: Int
    let month: Int
    let year: Int
  }
    
  func call(arguments: Arguments) async throws -> ToolOutput { ... }
}
```

For this tool, we’ll pass in the contact name from a dialog that’s going on in our game. And when the model calls this tool, we’ll let it generate a day, month and a year for which to fetch events with this contact. And we’ll pass this tool in the session for the NPC dialog.

So now, if we ask my friend Naomy’s NPC "What’s going on?", she can reply with real events we have planned together.

Wow, it's like talking to the real Naomy now.

Let’s take a closer look at how tool calling works.

We start by passing the tool at the start of the session, along with instructions. And for this example, we include information like today’s date.

Then, when the user prompts the session, the model can analyze the text. In this example, the model understands that the prompt is asking for events, so calling the calendar tool makes sense.

To call the tool, the model first generates the input arguments. In this case the model needs to generate the date to get events for. The model can relate information from the instructions and prompt, and understand how to fill in the tool arguments based on that.

So in this example it can infer what tomorrow means based on today’s date in the instructions. Once the input for your tool is generated, your call method is invoked.

This is your time to shine, your tool can do anything it wants. But note, the session waits for your tool to return, before it can generate any further output.

The output of your tool is then put in the transcript, just like output from the model. And based on your tool’s output, the model can generate a response to the prompt.

Note that a tool can be called multiple times for a single request.

And when that happens, your tool gets called in parallel. So keep that in mind when accessing data from your tool’s call method.

Alright, that was pretty fun! Our game now randomly generates content, based on my personal contacts and calendar. All without my data ever leaving my device. To recap, tool calling can let the model call your code to access external data during a request. This can be private information, like Contacts, or even external data from sources on the web. Keep in mind that a tool can be invoked multiple times, within a given request. The model determines this based on its context.

Tools can also be called in parallel, and they can store state.

That was quite a lot.

Perhaps get a coffee before doing anything else.

To learn more, you can check out the dedicated video about prompt engineering, including design and safety tips. And, if you want to meet the real Naomy, check out the code-along video. I hope you will have as much fun with Foundation Models as I've had. Thanks for watching.
--- END FILE ---

--- FILE: Meet_the_Foundation_Models_framework.md ---
# Meet the Foundation Models framework

Hi, I’m Erik. And I’m Yifei. And today, we are so excited to get the privilege of introducing you to the new Foundation Models framework! The Foundation Models framework gives you access to the on-device Large Language Model that powers Apple Intelligence, with a convenient and powerful Swift API. It is available on macOS, iOS, iPadOS, and visionOS! You can use it to enhance existing features in your apps, like providing personalized search suggestions. Or you can create completely new features, like generating an itinerary in a travel app, all on-device. You can even use it to create dialog on-the-fly for characters in a game.

It is optimized for generating content, summarizing text, analyzing user input and so much more.

All of this runs on-device, so all data going into and out of the model stays private. That also means it can run offline! And it’s built into the operating system, so it won’t increase your app size. It’s a huge year, so to help you get the most out of the FoundationModels framework, we’ve prepared a series of videos. In this first video, we’ll be giving you a high level overview of the framework in its entirety. Starting with the details of the model.

We will then introduce guided generation which allows you to get structured output in Swift, and the powerful streaming APIs that turn latency into delight.

We will also talk about tool calling, which allows the model to autonomously execute code you define in your app.

Finally, we will finish up with how we provide multi-turn support with stateful sessions, and how we seamlessly integrate the framework into the Apple developer ecosystem. The most important part of the framework, of course, is the model that powers it. And the best way to get started with prompting the model, is to jump into Xcode.

Testing out a variety of prompts to find what works best is an important part of building with large language models, and the new Playgrounds feature in Xcode is the best way to do that. With just a few lines of code, you can immediately start prompting the on-device model. Here I'll ask it to generate a title for a trip to Japan, and the model's output will appear in the canvas on the right. 

```swift
import FoundationModels
import Playgrounds

#Playground {
    let session = LanguageModelSession()
    let response = try await session.respond(to: "What's a good name for a trip to Japan? Respond only with a title")
}
```

Now, I want to see if this prompt works well for other destinations too. In a #Playground, you can access types defined in your app, so I'll create a for loop over the landmarks featured in mine. Now Xcode will show me the model's response for all of the landmarks.

```swift
import FoundationModels
import Playgrounds

#Playground {
    let session = LanguageModelSession()
    for landmark in ModelData.shared.landmarks {
        let response = try await session.respond(to: "What's a good name for a trip to \(landmark.name)? Respond only with a title")
    }
}
```

The on-device model we just used is a large language model with 3 billion parameters, each quantized to 2 bits. It is several orders of magnitude bigger than any other models that are part of the operating system.

But even so, it’s important to keep in mind that the on-device model is a device-scale model. It is optimized for use cases like summarization, extraction, classification, and many more. It’s not designed for world knowledge or advanced reasoning, which are tasks you might typically use server-scale LLMs for.

Device scale models require tasks to be broken down into smaller pieces. As you work with the model, you’ll develop an intuition for its strengths and weaknesses.

For certain common use cases, such as content tagging, we also provide specialized adapters that maximize the model’s capability in specific domains.

We will also continue to improve our models over time. Later in this video we’ll talk about how you can tell us how you use our models, which will help us to improve them in ways that matter to you.

Now that we've taken a look at the model, the first stop on our journey is Guided Generation. Guided Generation is what makes it possible to build features like the ones you just saw, and it is the beating heart of the FoundationModels framework. Let's take a look at a common problem and talk about how Guided Generation solves it.

By default, language models produce unstructured, natural language as output. It's easy for humans to read, but difficult to map onto views in your app.

A common solution is to prompt the model to produce something that's easy to parse, like JSON or CSV.

However, that quickly turns into a game of whack-a-mole. You have to add increasingly specific instructions about what it it is and isn't supposed to do… Often that doesn't quite work… So you end up writing hacks to extract and patch the content. This isn't reliable because the model is probabilistic and there is a non-zero chance of structural mistakes. Guided Generation offers a fundamental solution to this problem.

When you import FoundationModels, you get access to two new macros, @Generable and @Guide. Generable let's you describe a type that you want the model to generate an instance of.

```swift
// Creating a Generable struct

@Generable
struct SearchSuggestions {
    @Guide(description: "A list of suggested search terms", .count(4))
    var searchTerms: [String]
}
```

Additionally, Guides let you provide natural language descriptions of properties, and programmatically control the values that can be generated for those properties.

Once you've defined a Generable type, you can make the model respond to prompts by generating an instance of your type. This is really powerful.

```swift
// Responding with a Generable type

let prompt = """
    Generate a list of suggested search terms for an app about visiting famous landmarks.
    """

let response = try await session.respond(
    to: prompt,
    generating: SearchSuggestions.self
)

print(response.content)
```

Observe how our prompt no longer needs to specify the output format. The framework takes care of that for you.

The most important part, of course, is that we now get back a rich Swift object that we can easily map onto an engaging view.

Generable types can be constructed using primitives, like Strings, Integers, Doubles, Floats, and Decimals, and Booleans. Arrays are also generable. And Generable types can be composed as well. Generable even supports recursive types, which have powerful applications in domains like generative UIs.

```swift
// Composing Generable types

@Generable struct Itinerary {
    var destination: String
    var days: Int
    var budget: Float
    var rating: Double
    var requiresVisa: Bool
    var activities: [String]
    var emergencyContact: Person
    var relatedItineraries: [Itinerary]
}
```

The most important thing to understand about Guided Generation is that it fundamentally guarantees structural correctness using a technique called constrained decoding.

When using Guided Generation, your prompts can be simpler and focused on desired behavior instead of the format.

Additionally, Guided Generation tends to improve model accuracy. And, it allows us to perform optimizations that speed up inference at the same time. This is all made possible by carefully coordinated integration of Apple operating systems, developer tools, and the training of our foundation models. There is still a lot more to cover about guided generation, like how to create dynamic schemas at runtime, so please check out our deep dive video for more details. So that wraps up Guided Generation — we’ve seen how Swift’s powerful type system augments natural language prompts to enable reliable structured output. Our next topic is streaming, and it all builds on top of the @Generable macro you’re already familiar with.

If you’ve worked with large language models before, you may be aware that they generate text as short groups of characters called tokens.

Typically when streaming output, tokens are delivered in what’s called a delta, but the FoundationModels framework actually takes a different approach, and I want to show you why.

As deltas are produced, the responsibility for accumulating them usually falls on the developer.

You append each delta as they come in. And the response grows as you do.

But it gets tricky when the result has structure. If you want to show the greeting string after each delta, you have to parse it out of the accumulation, and that’s not trivial, especially for complicated structures. Delta streaming just isn’t the right formula when working with structured output.

And as you’ve learned, structured output is at the very core of the FoundationModels framework, which is why we’ve developed a different approach. Instead of raw deltas, we stream snapshots.

As the model produces deltas, the framework transforms them into snapshots. Snapshots represent partially generated responses. Their properties are all optional. And they get filled in as the model produces more of the response.

Snapshots are a robust and convenient representation for streaming structured output.

You're already familiar with the @Generable macro, and as it turns out, it's also where the definitions for partially generated types come from. If you expand the macro, you'll discover it produces a type named `PartiallyGenerated`. It is effectively a mirror of the outer structure, except every property is optional.

```swift
// PartiallyGenerated types

@Generable struct Itinerary {
    var name: String
    var days: [Day]
}
```

The partially generated type comes into play when you call the `streamResponse` method on your session.

```swift
// Streaming partial generations

let stream = session.streamResponse(
    to: "Craft a 3-day itinerary to Mt. Fuji.",
    generating: Itinerary.self
)

for try await partial in stream {
    print(partial)
}
```

Stream response returns an async sequence. And the elements of that sequence are instances of a partially generated type. Each element in the sequence will contain an updated snapshot.

These snapshots work great with declarative frameworks like SwiftUI. First, create state holding a partially generated type.

Then, just iterate over a response stream, store its elements, and watch as your UI comes to life.

```swift
ItineraryView: View {
    let session: LanguageModelSession
    let dayCount: Int
    let landmarkName: String
  
    @State
    private var itinerary: Itinerary.PartiallyGenerated?
  
    var body: some View {
        //...
        Button("Start") {
            Task {
                do {
                    let prompt = """
                        Generate a \(dayCount) itinerary \
                        to \(landmarkName).
                        """
                  
                    let stream = session.streamResponse(
                        to: prompt,
                        generating: Itinerary.self
                    )
                  
                    for try await partial in stream {
                        self.itinerary = partial
                    }
                } catch {
                    print(error)  
                }
            }
        }
    }
}
```

To wrap up, let's review some best practices for streaming.

First, get creative with SwiftUI animations and transitions to hide latency. You have an opportunity turn a moment of waiting into one of delight. Second, you'll need to think carefully about view identity in SwiftUI, especially when generating arrays. Finally, bear in mind that properties are generated in the order they are declared on your Swift struct. This matters both for animations and for the quality of the model's output. For example, you may find that the model produces the best summaries when they're the last property in the struct.

```swift
@Generable struct Itinerary {
  
  @Guide(description: "Plans for each day")
  var days: [DayPlan]
  
  @Guide(description: "A brief summary of plans")
  var summary: String
}
```

There is a lot to unpack here, so make sure to check out our video on integrating Foundation Models into your app for more details. So that wraps up streaming with Foundation Models. Next up, Yifei is going to teach you all about tool calling! Thanks Erik! Tool calling is another one of our key features. It lets the model execute code you define in your app. This feature is especially important for getting the most out of our model, since tool calling gives the model many additional capabilities. It allows the model to identify that a task may require additional information or actions and autonomously make decisions about what tool to use and when, when it’s difficult to decide programmatically.

The information you provide to the model can be world knowledge, recent events, or personal data. For example, in our travel app, it provides information about various locations from MapKit. This also gives the model the ability to cite sources of truth, which can suppress hallucinations and allow fact-checking the model output.

Finally, it allows the model to take actions, whether it’s in your app, on the system, or in the real world.

Integrating with various sources of information in your app is a winning strategy for building compelling experiences. Now that you know why tool calling is very useful, let’s take a look at how it works.

On the left we have a transcript which records everything that has happened so far. If you’ve provided tools to the session, the session will present these tools to the model along with the instructions. Next comes the prompt, where we tell the model which destination we want to visit.

Now, if the model deems that calling a tool can enhance the response, it will produce one or more tool calls. In this example, the model produces two tool calls — querying restaurants and hotels.

At this phase, the FoundationModels framework will automatically call the code you wrote for these tools. The framework then automatically inserts the tool outputs back into the transcript. Finally, the model will incorporate the tool output along with everything else in the transcript to furnish the final response.

Now that we have a high level understanding of tool calling, let's define a tool.

Here we're defining a simple weather tool, which conforms to the Tool protocol. The weather tool has kind of emerged as the de-facto 'hello world' of tool calling, and it's a great way to get started.

The protocol first requires you to specify a name and a natural language description of the tool.

The framework will automatically provide them for the model to help it understand when to call your tool.

When the model calls your tool, it will run the call method you define.

The argument to the call method can be any Generable type.

The reason your arguments need to be generable is because tool calling is built on guided generation to ensure that the model will never produce invalid tool names or arguments.

After defining your arguments type, you can now write anything you want in the body of your method. Here we're using CoreLocation and WeatherKit to find the temperature of a given city. The output is represented using the ToolOutput type, which can be created from GeneratedContent to represent structured data. Or from a string if your tool's output is natural language. 

```swift
// Defining a tool
import WeatherKit
import CoreLocation
import FoundationModels

struct GetWeatherTool: Tool {
    let name = "getWeather"
    let description = "Retrieve the latest weather information for a city"

    @Generable
    struct Arguments {
        @Guide(description: "The city to fetch the weather for")
        var city: String
    }

    func call(arguments: Arguments) async throws -> ToolOutput {
        let places = try await CLGeocoder().geocodeAddressString(arguments.city)
        let weather = try await WeatherService.shared.weather(for: places.first!.location!)
        let temperature = weather.currentWeather.temperature.value

        let content = GeneratedContent(properties: ["temperature": temperature])
        let output = ToolOutput(content)

        // Or if your tool's output is natural language:
        // let output = ToolOutput("\(arguments.city)'s temperature is \(temperature) degrees.")

        return output
    }
}
```

Now that we have defined a tool, we have to ensure that the model has access to it.

To do so, pass your tool into your session's initializer. Tools must be attached at session initialization, and will be available to the model for the session's lifetime.

```swift
// Attaching tools to a session

let session = LanguageModelSession(
    tools: [GetWeatherTool()],
    instructions: "Help the user with weather forecasts."
)

let response = try await session.respond(
    to: "What is the temperature in Cupertino?"
)

print(response.content)
// It's 71˚F in Cupertino!
```

After creating a session with tools, all you need to do is prompt the model as you would normally. Tool calls will happen transparently and autonomously, and the model will incorporate the tools' outputs into its final response. The examples I’ve shown here demonstrate how to define type-safe tools at compile time, which is great for the vast majority of use cases. But tools can also be dynamic in every way! For example, you can define the arguments and behaviors of a tool at runtime by using dynamic generation schemas. If you are curious about that, feel free to check out our deep dive video to learn more.

That wraps up tool calling. We learned why tool calling is useful and how to implement tools to extend the model's capabilities. Next, let's talk about stateful sessions. You've seen the word session pop up in this video many times already. The Foundation Models framework is built around the notion of a stateful session. By default, when you create a session, you will be prompting the on-device general-purpose model. And you can provide custom instructions.

Instructions are an opportunity for you to tell the model its role and provide guidance on how the model should respond. For example, you can specify things like style and verbosity.

```swift
// Supplying custom instructions

let session = LanguageModelSession(
    instructions: """
        You are a helpful assistant who always \
        responds in rhyme.
        """
)
```

Note that providing custom instructions is optional, and reasonable default instructions will be used if you don't specify any.

If you do choose to provide custom instructions, it is important to understand the difference between instructions and prompts. Instructions should come from you, the developer, while prompts can come from the user. This is because the model is trained to obey instructions over prompts. This helps protect against prompt injection attacks, but is by no means bullet proof.

As a general rule, instructions are mostly static, and it’s best not to interpolate untrusted user input into the instructions.

So this is a basic primer on how to best form your instructions and prompts. To discover even more best practices, check out our video on prompt design and safety.

Now that you have initialized a session, let's talk about multi-turn interactions! When using the respond or streamResponse methods we talked about earlier. Each interaction with the model is retained as context in a transcript, so the model will be able to refer to and understand past multi-turn interactions within a single session. For example, here the model is able to understand when we say "do another one", that we're referring back to writing a haiku.

```swift
// Multi-turn interactions

let session = LanguageModelSession()

let firstHaiku = try await session.respond(to: "Write a haiku about fishing")
print(firstHaiku.content)
// Silent waters gleam,
// Casting lines in morning mist—
// Hope in every cast.

let secondHaiku = try await session.respond(to: "Do another one about golf")
print(secondHaiku.content)
// Silent morning dew,
// Caddies guide with gentle words—
// Paths of patience tread.

print(session.transcript)// (Prompt) Write a haiku about fishing
// (Response) Silent waters gleam...
// (Prompt) Do another one about golf
// (Response) Silent morning dew...
```

And the `transcript` property on the session object will allow you to inspect previous interactions or draw UI views to represent them.

One more important thing to know is that while the model is producing output, its `isResponding` property will become `true`. You may need to observe this property and make sure not to submit another prompt until the model finishes responding.

```swift
import SwiftUI
import FoundationModels

struct HaikuView: View {

    @State
    private var session = LanguageModelSession()

    @State
    private var haiku: String?

    var body: some View {
        if let haiku {
            Text(haiku)
        }
        Button("Go!") {
            Task {
                haiku = try await session.respond(
                    to: "Write a haiku about something you haven't yet"
                ).content
            }
        }
        // Gate on `isResponding`
        .disabled(session.isResponding)
    }
}
```

Beyond the default model, we are also providing additional built-in specialized use cases that are backed by adapters.

If you find a built-in use case that fits your need, you can pass it to SystemLanguageModel's initializer. 

```swift
// Using a built-in use case

let session = LanguageModelSession(
    model: SystemLanguageModel(useCase: .contentTagging)
)
```

To understand what built-in use cases are available and how to best utilize them, check out our documentation on the developer website. One specialized adapter I want to talk more about today is the content tagging adapter. The content tagging adapter provides first class support for tag generation, entity extraction, and topic detection. By default, the adapter is trained to output topic tags, and it integrates with guided generation out of the box. So you can simply define a struct with our Generable macro, and pass the user input to extract topics from it.

```swift
// Content tagging use case

@Generable
struct Result {
    let topics: [String]
}

let session = LanguageModelSession(model: SystemLanguageModel(useCase: .contentTagging))
let response = try await session.respond(to: ..., generating: Result.self)
```

But there's more! By providing it with custom instructions and a custom Generable output type, you can even use it to detect things like actions and emotions.

```swift
// Content tagging use case

@Generable
struct Top3ActionEmotionResult {
    @Guide(.maximumCount(3))
    let actions: [String]
    @Guide(.maximumCount(3))
    let emotions: [String]
}

let session = LanguageModelSession(
    model: SystemLanguageModel(useCase: .contentTagging),
    instructions: "Tag the 3 most important actions and emotions in the given input text."
)
let response = try await session.respond(to: ..., generating: Top3ActionEmotionResult.self)
```

Before you create a session, you should also check for availability, since the model can only run on Apple Intelligence-enabled devices in supported regions. To check if the model is currently available, you can access the availability property on the SystemLanguageModel.

Availability is a two case enum that's either available or unavailable. If it's unavailable, you also receive a reason so you can adjust your UI accordingly.

```swift
// Availability checking

struct AvailabilityExample: View {
    private let model = SystemLanguageModel.default

    var body: some View {
        switch model.availability {
        case .available:
            Text("Model is available").foregroundStyle(.green)
        case .unavailable(let reason):
            Text("Model is unavailable").foregroundStyle(.red)
            Text("Reason: \(reason)")
        }
    }
}
```

Lastly, you could encounter errors when you are calling into the model.

These errors might include guardrail violation, unsupported language, or context window exceeded. To provide the best user experience, you should handle them appropriately, and the deep-dive video will teach you more about them. That’s it for multi-turn stateful sessions! We learned how to create a session and use it, as well as how our model keeps track of your context. Now that you’ve seen all the cool features of the framework, let’s talk about developer tooling and experience. To start, you can go to any Swift file in your project and use the new playground macro to prompt the model.

Playgrounds are powerful because they let you quickly iterate on your prompts without having to rebuild and rerun your entire app.

In a playground, your code can access all the types in your project, such as the generable types that are already powering your UI.

Next, we know that when it comes to building app experiences powered by large language models, it is important to understand all the latency under the hood, because large language models take longer to run compared to traditional ML models. Understanding where latency goes can help you tweak the verbosity of your prompts, or determine when to call useful APIs such as prewarming.

And our new Instruments app profiling template is built exactly for that. You can profile the latency of a model request, observe areas of optimizations, and quantify improvements.

Now, as you develop your app, you may have feedback that can help us improve our models and our APIs.

We encourage you to provide your feedback through Feedback Assistant. We even provide an encodable feedback attachment data structure that you can attach as a file to your feedback.

```swift
let feedback = LanguageModelFeedbackAttachment(
  input: [
    // ...
  ],
  output: [
    // ...
  ],
  sentiment: .negative,
  issues: [
    LanguageModelFeedbackAttachment.Issue(
      category: .incorrect,
      explanation: "..."
    )
  ],
  desiredOutputExamples: [
    [
      // ...
    ]
  ]
)
let data = try JSONEncoder().encode(feedback)
```

Finally, if you are an ML practitioner with a highly specialized use case and a custom dataset, you can also train your custom adapters using our adapter training toolkit. But bear in mind, this comes with significant responsibilities because you need to retrain it as Apple improves the model over time. To learn more, you can visit the developer website. 

Now that you've learned many of the cool features provided by the new Foundation Models framework, we can't wait to see all the amazing things you build with it! To discover even more about how you can integrate generative AI into your app, how technologies like guided generation work under the hood, and how you can create the best prompts, we have a whole series of wonderful videos and articles for you.

Thank you so much for joining us today! Happy generating!
--- END FILE ---

--- FILE: Explore_prompt_design_and_Safety_for_foundation_models.md ---

--- END FILE ---

--- FILE: generating-content-and-performing-tasks.md ---
# Generating content and performing tasks with Foundation Models

**Enhance the experience in your app by prompting an on-device large language model.**


## Overview

The Foundation Models framework lets you tap into the on-device large models at the core of Apple Intelligence. You can enhance your app by using generative models to create content or perform tasks. The framework supports language understanding and generation based on model capabilities.

For design guidance, see Human Interface Guidelines > Technologies > [https://developer.apple.com/design/human-interface-guidelines/generative-ai](https://developer.apple.com/design/human-interface-guidelines/generative-ai).


## Understand model capabilities

When considering features for your app, it helps to know what the on-device language model can do. The on-device model supports text generation and understanding that you can use to:

The on-device language model may not be suitable for handling all requests, like:

The model can complete complex generative tasks when you use guided generation or tool calling. For more on handling complex tasks, or tasks that require extensive world-knowledge, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation) and [doc://com.apple.foundationmodels/documentation/FoundationModels/expanding-generation-with-tool-calling](https://developer.apple.com/documentation/FoundationModels/expanding-generation-with-tool-calling).


## Check for availability

Before you use the on-device model in your app, check that the model is available by creating an instance of [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel) with the [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/default](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/default) property.

Model availability depends on device factors like:

- The device must support Apple Intelligence.

- The device must have Apple Intelligence turned on in Settings.


> **NOTE**: It can take some time for the model to download and become available when a person turns on Apple Intelligence.


Always verify model availability first, and plan for a fallback experience in case the model is unavailable.

```swift
struct GenerativeView: View {
    // Create a reference to the system language model.
    private var model = SystemLanguageModel.default

    var body: some View {
        switch model.availability {
        case .available:
            // Show your intelligence UI.
        case .unavailable(.deviceNotEligible):
            // Show an alternative UI.
        case .unavailable(.appleIntelligenceNotEnabled):
            // Ask the person to turn on Apple Intelligence.
        case .unavailable(.modelNotReady):
            // The model isn't ready because it's downloading or because of other system reasons.
        case .unavailable(let other):
            // The model is unavailable for an unknown reason.
        }
    }
}
```


## Create a session

After confirming that the model is available, create a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession) object to call the model. For a single-turn interaction, create a new session each time you call the model:

```swift
// Create a session with the system model.
let session = LanguageModelSession()
```

For a multiturn interaction — where the model retains some knowledge of what it produced — reuse the same session each time you call the model.


## Provide a prompt to the model

A [doc://com.apple.foundationmodels/documentation/FoundationModels/Prompt](https://developer.apple.com/documentation/FoundationModels/Prompt) is an input that the model responds to. Prompt engineering is the art of designing high-quality prompts so that the model generates a best possible response for the request you make. A prompt can be as short as “hello”, or as long as multiple paragraphs. The process of designing a prompt involves a lot of exploration to discover the best prompt, and involves optimizing prompt length and writing style.

When thinking about the prompt you want to use in your app, consider using conversational language in the form of a question or command. For example, “What’s a good month to visit Paris?” or “Generate a food truck menu.”

Write prompts that focus on a single and specific task, like “Write a profile for the dog breed Siberian Husky”. When a prompt is long and complicated, the model takes longer to respond, and may respond in unpredictable ways. If you have a complex generation task in mind, break the task down into a series of specific prompts.

You can refine your prompt by telling the model exactly how much content it should generate. A prompt like, “Write a profile for the dog breed Siberian Husky” often takes a long time to process as the model generates a full multi-paragraph essay. If you specify “using three sentences”, it speeds up processing and generates a concise summary. Use phrases like “in a single sentence” or “in a few words” to shorten the generation time and produce shorter text.

```swift
// Generate a longer response for a specific command.
let simple = "Write me a story about pears."

// Quickly generate a concise response.
let quick = "Write the profile for the dog breed Siberian Husky using three sentences."
```


## Provide instructions to the model

[doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) help steer the model in a way that fits the use case of your app. The model obeys prompts at a lower priority than the instructions you provide. When you provide instructions to the model, consider specifying details like:

- What the model’s role is; for example, “You are a mentor,” or “You are a movie critic”.

- What the model should do, like “Help the person extract calendar events,” or “Help the person by recommending search suggestions”.

- What the style preferences are, like “Respond as briefly as possible”.

- What the possible safety measures are, like “Respond with ‘I can’t help with that’ if you’re asked to do something dangerous”.

Use content you trust in instructions because the model follows them more closely than the prompt itself. When you initialize a session with instructions, it affects all prompts the model responds to in that session. Instructions can also include example responses to help steer the model. When you add examples to your prompt, you provide the model with a template that shows the model what a good response looks like.


## Generate a response

To call the model with a prompt, call [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/respond(to:options:)-b2re](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/respond(to:options:)-b2re) on your session. The response call is asynchronous because it may take a few seconds for the on-device foundation model to generate the response.

```swift
let instructions = """
    Suggest five related topics. Keep them concise (three to seven words) and make sure they \
    build naturally from the person's topic.
    """

let session = LanguageModelSession(instructions: instructions)

let prompt = "Making homemade bread"
let response = try await session.respond(to: prompt)
```


> **NOTE**: A session can only handle a single request at a time, and causes a runtime error if you call it again before the previous request finishes. Check [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/isResponding](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/isResponding) to verify the session is done processing the previous request before sending a new one.


Instead of working with raw string output from the model, the framework offers guided generation to generate a custom Swift data structure you define. For more information about guided generation, see [doc://com.apple.foundationmodels/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation).

When you make a request to the model, you can provide custom tools to help the model complete the request. If the model determines that a [doc://com.apple.foundationmodels/documentation/FoundationModels/Tool](https://developer.apple.com/documentation/FoundationModels/Tool) can assist with the request, the framework calls your [doc://com.apple.foundationmodels/documentation/FoundationModels/Tool](https://developer.apple.com/documentation/FoundationModels/Tool) to perform additional actions like retrieving content from your local database. For more information about tool calling, see [doc://com.apple.foundationmodels/documentation/FoundationModels/expanding-generation-with-tool-calling](https://developer.apple.com/documentation/FoundationModels/expanding-generation-with-tool-calling)


## Consider context size limits per session

The *context window size* is a limit on how much data the model can process for a session instance. A token is a chunk of text the model processes, and the system model supports up to 4,096 tokens. A single token corresponds to three or four characters in languages like English, Spanish, or German, and one token per character in languages like Japanese, Chinese, or Korean. In a single session, the sum of all tokens in the instructions, all prompts, and all outputs count toward the context window size.

If your session processes a large amount of tokens that exceed the context window, the framework throws the error [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/exceededContextWindowSize(_:)). When you encounter the error, start a new session and try shortening your prompts. If you need to process a large amount of data that won’t fit in a single context window limit, break your data into smaller chunks, process each chunk in a separate session, and then combine the results.


## Tune generation options and optimize performance

To get the best results for your prompt, experiment with different generation options. [doc://com.apple.foundationmodels/documentation/FoundationModels/GenerationOptions](https://developer.apple.com/documentation/FoundationModels/GenerationOptions) affects the runtime parameters of the model, and you can customize them for every request you make.

```swift
// Customize the temperature to increase creativity.
let options = GenerationOptions(temperature: 2.0)

let session = LanguageModelSession()

let prompt = "Write me a story about coffee."
let response = try await session.respond(
    to: prompt,
    options: options
)
```

When you test apps that use the framework, use Xcode Instruments to understand more about the requests you make, like the time it takes to perform a request. When you make a request, you can access the [doc://com.apple.foundationmodels/documentation/FoundationModels/Transcript](https://developer.apple.com/documentation/FoundationModels/Transcript) entries that describe the actions the model takes during your [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession).

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models)*
--- END FILE ---

--- FILE: MODEL_CHAT_ARCHITECTURE.md ---
# Model Chat Architecture

This document explains exactly how ChAI enables users to chat with different model types: **Foundation Models** (Apple's on-device AI), **MLX Models** (local quantized models), and **Cloud Models** (API-based models from various providers).

## Overview

ChAI uses a unified chat interface powered by the `MultiModelManager` that intelligently routes requests to the appropriate model handler based on the selected model type. All chat interactions flow through a single entry point but branch into different execution paths depending on whether the model is local (Foundation/MLX) or cloud-based.

## Architecture Components

### Core Managers

1. **MultiModelManager** - Central orchestrator for all model interactions
2. **FoundationModelManager** - Handles Apple's on-device FoundationModels (iOS 26+)
3. **MLXModelManager** - Manages locally downloaded MLX models
4. **MessagesManager** - Builds conversation context with token awareness
5. **ThreadViewModel** - Coordinates UI and message sending

### Flow Diagram

```
User Input
    ↓
ThreadViewModel.sendMessage()
    ↓
MultiModelManager.respond() or streamResponse()
    ↓
    ├─→ [isLocal = true, provider = "MLX"] → MLXModelManager
    ├─→ [isLocal = true, iOS 26+] → FoundationModelManager
    └─→ [isLocal = false] → Cloud API (OpenAI, Anthropic, Google, etc.)
```

## Model Type 1: Foundation Models (Apple On-Device)

### What They Are
Apple's on-device AI models introduced in iOS 26, using the FoundationModels framework. These run entirely on-device with no API costs.

### How Chat is Enabled

#### 1. **Initialization** (`FoundationModelManager.swift`)
```swift
init(settings: Settings) {
    if #available(iOS 26.0, *) {
        guard SystemLanguageModel.default.availability == .available else { return }
        let session = try LanguageModelSession(instructions: settings.systemPrompt)
        self.session = session
        self.transcript = session.transcript
    }
}
```

Key points:
- Creates a `LanguageModelSession` with the system prompt
- The session maintains its own internal transcript for conversation context
- Checks model availability before initialization

#### 2. **Message Routing** (`MultiModelManager.swift` - Line 444-534)
```swift
func respond(to text: String, thread: Thread?) async throws -> String {
    guard var model = currentModel else {
        throw MultiModelError.noModelSelected
    }
    
    if model.isLocal {
        if model.provider == "MLX" {
            // Route to MLX
        } else if #available(iOS 26.0, *) {
            // Route to Foundation Models
            guard let thread = thread else {
                throw MultiModelError.noModelSelected
            }
            responseText = try await respondWithLocalModel(to: text, thread: thread)
        }
    }
}
```

Foundation Models **require a thread** for session management.

#### 3. **Non-Streaming Response** (`MultiModelManager.swift` - Line 564-629)
```swift
func respondWithLocalModel(to text: String, thread: Thread) async throws -> String {
    guard let manager = foundationModelManager else {
        throw MultiModelError.noModelSelected
    }
    
    // Handle simple greetings to avoid safety guardrails
    let simpleGreetings = ["hi", "hello", "hey", ...]
    if simpleGreetings.contains(normalizedText) {
        return "Hello! How can I help you today?"
    }
    
    do {
        let response = try await manager.respond(to: text, thread: thread)
        return response
    } catch FoundationModelManager.FoundationModelManagerError.safetyGuardrailsTriggered {
        // Trigger fallback to cloud model
        throw MultiModelError.foundationModelUnavailable(...)
    }
}
```

#### 4. **Streaming Response** (`FoundationModelManager.swift` - Line 136-200)
```swift
func streamResponse(to text: String, thread: Thread? = nil) -> AsyncStream<String>? {
    let responseStream = session.streamResponse(to: text)
    return AsyncStream<String> { continuation in
        Task {
            var previous = ""
            for try await snapshot in responseStream {
                let current = snapshot.content ?? ""
                // Yield only new content since last snapshot
                if current.count > previous.count {
                    let deltaText = String(current[start...])
                    continuation.yield(deltaText)
                }
                previous = current
            }
            continuation.finish()
        }
    }
}
```

#### 5. **Conversation Context**
Foundation Models handle context automatically through `LanguageModelSession.transcript`. The framework maintains conversation history internally, so ChAI doesn't need to manually build message arrays.

### Special Handling

**Safety Guardrails**: Foundation Models have built-in safety guardrails that can reject certain prompts. When triggered:
1. Error is caught in `respondWithLocalModel()`
2. Throws `MultiModelError.foundationModelUnavailable`
3. `ThreadViewModel` triggers automatic fallback to cloud model
4. User sees: "⚠️ Using alternative model (FoundationModels unavailable: safety)"

**Simple Greeting Bypass**: To avoid false positives on safety guardrails, simple greetings like "hi" and "hello" are intercepted and return canned responses.

---

## Model Type 2: MLX Models (Local Quantized Models)

### What They Are
Quantized language models downloaded from HuggingFace that run locally using Apple's MLX framework. These are stored in the device's Application Support directory.

### How Chat is Enabled

#### 1. **Model Discovery & Loading** (`MLXModelManager.swift`)

**Download Process** (Line 119-254):
```swift
func downloadModel(huggingFaceId: String, displayName: String) async throws -> MLXModel {
    // Download to Application Support/ChAi/MLXModels
    let mlxModelsDir = appSupportDir.appendingPathComponent("ChAi/MLXModels")
    let modelDir = mlxModelsDir.appendingPathComponent(directoryName)
    
    // Download using HubApi
    let hubApi = HubApi()
    let modelUrl = try await hubApi.snapshot(from: huggingFaceId, matching: ["*.safetensors", "*.json"])
    
    // Create MLXModel record
    let model = MLXModel(huggingFaceId: huggingFaceId, displayName: displayName, localPath: directoryName)
    modelContext.insert(model)
    
    return model
}
```

**Loading into Memory** (Line 258-339):
```swift
func loadModel(_ model: MLXModel) async throws -> MLXLMCommon.ModelContainer {
    // Check cache first
    let cacheKey = model.id.uuidString as NSString
    if let cached = modelCache.object(forKey: cacheKey) {
        return cached
    }
    
    // Load from disk
    let modelURL = URL(fileURLWithPath: model.resolvedPath)
    let hubApi = HubApi(downloadBase: modelURL)
    let configuration = ModelConfiguration(id: model.huggingFaceId)
    
    let container = try await LLMModelFactory.shared.loadContainer(
        hub: hubApi,
        configuration: configuration,
        progressHandler: progressHandler
    )
    
    // Cache for reuse
    modelCache.setObject(container, forKey: cacheKey)
    return container
}
```

#### 2. **Message Routing** (`MultiModelManager.swift` - Line 444-534)
```swift
if model.isLocal {
    if model.provider == "MLX" {
        guard let mlxModel = mlxModelManager?.downloadedModels.first(where: {
            $0.id.uuidString == model.id
        }) else {
            throw MultiModelError.noModelSelected
        }
        responseText = try await respondWithMLX(to: text, model: mlxModel, thread: thread)
    }
}
```

#### 3. **Building Conversation Context** (`MultiModelManager.swift` - Line 632-691)
Unlike Foundation Models, MLX models require explicit message arrays:

```swift
func buildMLXMessages(for text: String, thread: Thread?, model: MLXModel) async -> [[String: String]] {
    var messages: [[String: String]] = []
    
    // 1. Add system prompt
    if !settings.systemPrompt.isEmpty {
        messages.append(["role": "system", "content": settings.systemPrompt])
    }
    
    // 2. Add conversation history if memory enabled
    if let thread = thread, 
       settings.globalMemoryEnabled,
       settings.isMemoryEnabled(for: thread.id) {
        
        let sortedChats = thread.chats.sorted(by: { $0.timestamp < $1.timestamp })
        
        for chat in sortedChats {
            let role = chat.sender == .user ? "user" : "assistant"
            messages.append(["role": role, "content": chat.content])
        }
    }
    
    // 3. Add current user message
    messages.append(["role": "user", "content": text])
    
    return messages
}
```

#### 4. **Generation** (`MLXModelManager.swift` - Line 343-446)
```swift
func generate(
    model: MLXModel,
    messages: [[String: String]],
    maxTokens: Int,
    temperature: Double,
    topP: Double
) -> AsyncThrowingStream<String, Error> {
    return AsyncThrowingStream { continuation in
        Task {
            // Load model container
            let container = try await loadModel(model)
            
            // Prepare input with chat template
            try await container.perform { (context: ModelContext) in
                let userInput = UserInput(messages: messages)
                let preparedInput = try await context.processor.prepare(input: userInput)
                
                // Generate with streaming
                let result = try MLXLMCommon.generate(
                    input: preparedInput,
                    parameters: generateParameters,
                    context: context
                )
                
                // Stream tokens
                for await generation in result {
                    if case .chunk(let text) = generation {
                        continuation.yield(text)
                    }
                }
            }
            continuation.finish()
        }
    }
}
```

#### 5. **Response Collection** (`MultiModelManager.swift` - Line 710-755)
```swift
func respondWithMLX(to text: String, model: MLXModel, thread: Thread?) async throws -> String {
    let messages = await buildMLXMessages(for: text, thread: thread, model: model)
    
    var fullResponse = ""
    let stream = manager.generate(model: model, messages: messages, ...)
    
    for try await chunk in stream {
        fullResponse += chunk
    }
    
    return fullResponse
}
```

### MLX-Specific Features

**Model Caching**: Loaded models are cached in `NSCache` to avoid reloading on every request.

**Template Fallback**: If the model's Jinja template fails to process the message array:
```swift
catch {
    // Fallback: combine system + user message
    let combinedPrompt = "\(systemContent)\n\n\(lastUserMessage)"
    let fallbackMessages = [["role": "user", "content": combinedPrompt]]
    preparedInput = try await context.processor.prepare(input: fallbackInput)
}
```

**Cancellation Support**: MLX generation can be cancelled mid-stream via `cancelGeneration()`.

---

## Model Type 3: Cloud Models (API-based)

### What They Are
External AI models accessed via REST APIs from providers like OpenAI, Anthropic, Google, Deepseek, Perplexity, etc.

### How Chat is Enabled

#### 1. **Model Registration** (`MultiModelManager.swift` - Line 86-250)
All cloud models are registered in `AIModel.defaultModels`:

```swift
static let defaultModels: [AIModel] = [
    AIModel(id: "gpt-4o", name: "GPT-4o", provider: "OpenAI", isLocal: false, 
            maxTokens: 128000, requiresAPIKey: true),
    AIModel(id: "claude-3-5-sonnet-20241022", name: "Claude 3.5 Sonnet", 
            provider: "Anthropic", isLocal: false, maxTokens: 200000, requiresAPIKey: true),
    AIModel(id: "gemini-2.0-flash-exp", name: "Gemini 2.0 Flash", 
            provider: "Google", isLocal: false, maxTokens: 1048576, requiresAPIKey: true),
    // ... more models
]
```

#### 2. **API Key Management** (`APIKeyManager.swift`)
Each provider requires an API key:

```swift
enum AIProvider: String {
    case openAI = "OpenAI"
    case anthropic = "Anthropic"
    case google = "Google"
    case deepseek = "Deepseek"
    // ... more providers
}

func getAPIKey(for provider: AIProvider) async -> String? {
    // Retrieves encrypted API key from Keychain
}
```

#### 3. **Message Routing** (`MultiModelManager.swift` - Line 444-534)
```swift
if !model.isLocal {
    // Use token-aware context building
    let result = try await respondWithAPIWithTokenTracking(
        to: text, context: context, model: model, thread: thread
    )
    responseText = result.response
    contextTokens = result.tokenCount
}
```

#### 4. **Token-Aware Context Building** (`MultiModelManager.swift` - Line 768-802)
Cloud models have token limits, so context must be carefully managed:

```swift
func respondWithAPIWithTokenTracking(
    to text: String, model: AIModel, thread: Thread?
) async throws -> TokenAwareResponse {
    // Use MessagesManager for intelligent context building
    let messagesManager = MessagesManager()
    let contextResult = await messagesManager.apiMessages(
        for: thread,
        systemPrompt: settings.systemPrompt,
        settings: settings,
        model: model,
        includeHistory: true,
        respectTokenLimits: true
    )
    
    // Returns: messages, tokenCount, wasTruncated, summaryUsed
    let response = try await respondWithAPIUsingMessages(
        text: text, model: model, thread: thread, messages: contextResult.messages
    )
    
    return TokenAwareResponse(
        response: response,
        contextTokens: contextResult.tokenCount,
        wasTruncated: contextResult.wasTruncated,
        summaryUsed: contextResult.summaryUsed
    )
}
```

#### 5. **Context Building Logic** (`MessagesManager.swift` - Line 56-122)
```swift
func apiMessages(for thread: Thread, model: AIModel, ...) async -> (messages, tokenCount, wasTruncated, summaryUsed) {
    var messages: [[String: Any]] = []
    
    // 1. System prompt
    messages.append(["role": "system", "content": systemPrompt])
    
    // 2. Check memory settings
    if !settings.globalMemoryEnabled || !settings.isMemoryEnabled(for: thread.id) {
        // Memory disabled - only send last user message
        messages.append(["role": "user", "content": lastUserMessage])
        return (messages, tokenCount, false, false)
    }
    
    // 3. Apply retention policy
    let sortedChats = thread.chats.sorted(by: { $0.timestamp < $1.timestamp })
    let filteredChats = filterChatsByRetentionPolicy(sortedChats, settings: settings)
    
    // 4. Convert to message format
    for chat in filteredChats {
        let role = chat.sender == .user ? "user" : "assistant"
        messages.append(["role": role, "content": chat.content])
    }
    
    // 5. Apply token-aware truncation
    if respectTokenLimits {
        let result = await applyTokenAwareTruncation(messages, thread, model)
        messages = result.messages
        wasTruncated = result.wasTruncated
        summaryUsed = result.summaryUsed
    }
    
    return (messages, tokenCount, wasTruncated, summaryUsed)
}
```

#### 6. **Provider-Specific API Calls** (`MultiModelManager.swift` - Line 868-924)
```swift
func respondWithDirectAPIUsingMessages(...) async throws -> String {
    let provider = getProviderForModel(model)
    guard let apiKey = await apiKeyManager.getAPIKey(for: provider) else {
        throw MultiModelError.missingAPIKey(provider: provider.displayName)
    }
    
    switch provider {
    case .openAI:
        return try await callOpenAIAPIWithMessages(...)
    case .anthropic:
        return try await callAnthropicAPIWithMessages(...)
    case .google:
        return try await callGoogleAPIWithMessages(...)
    case .deepseek:
        return try await callDeepseekAPIWithMessages(...)
    // ... more providers
    }
}
```

#### 7. **Example: OpenAI API Call** (`MultiModelManager.swift` - Line 1247-1358)
```swift
func callOpenAIAPIWithMessages(
    text: String, apiKey: String, model: AIModel, messages: [[String: Any]]
) async throws -> String {
    var request = URLRequest(url: URL(string: "https://api.openai.com/v1/chat/completions")!)
    request.httpMethod = "POST"
    request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
    request.setValue("application/json", forHTTPHeaderField: "Content-Type")
    
    let body: [String: Any] = [
        "model": model.id,
        "messages": messages,
        "max_tokens": settings.maxTokens,
        "temperature": settings.temperature,
        "top_p": settings.topP
    ]
    request.httpBody = try JSONSerialization.data(withJSONObject: body)
    
    let (data, response) = try await URLSession.shared.data(for: request)
    
    let json = try JSONSerialization.jsonObject(with: data) as? [String: Any]
    let choices = json?["choices"] as? [[String: Any]]
    let message = choices?.first?["message"] as? [String: Any]
    let content = message?["content"] as? String
    
    return content ?? "No response received"
}
```

#### 8. **Streaming Support** (`MultiModelManager.swift` - Line 2111-2302)
```swift
func callOpenAIStreamingAPI(...) -> AsyncThrowingStream<String, Error> {
    return AsyncThrowingStream { continuation in
        Task {
            // Set stream: true in request body
            let body: [String: Any] = ["model": model.id, "messages": messages, "stream": true]
            
            let (bytes, response) = try await URLSession.shared.bytes(for: request)
            
            for try await line in bytes.lines {
                if line.hasPrefix("data: ") {
                    let jsonString = line.dropFirst(6)
                    if jsonString == "[DONE]" { break }
                    
                    let json = try JSONSerialization.jsonObject(with: Data(jsonString.utf8))
                    let delta = json["choices"][0]["delta"]["content"] as? String
                    if let content = delta {
                        continuation.yield(content)
                    }
                }
            }
            continuation.finish()
        }
    }
}
```

### Cloud Model Features

**Token Tracking**: All requests track prompt and completion tokens for analytics and cost estimation.

**Context Truncation**: When context exceeds model limits:
1. Calculate effective limit: `maxTokens - responseTokens - safetyMargin`
2. Truncate oldest messages first
3. Optionally generate summary of truncated content
4. Insert summary as system message

**Provider Detection**: Models are mapped to providers via string matching:
```swift
func getProviderForModel(_ model: AIModel) -> AIProvider {
    switch model.provider.lowercased() {
    case "openai": return .openAI
    case "anthropic": return .anthropic
    case "google": return .google
    // ...
    }
}
```

---

## Unified Chat Flow

### Non-Streaming Path

```
ThreadViewModel.sendMessage(text)
    ↓
MultiModelManager.respond(to: text, thread: thread)
    ↓
    ├─→ Foundation: foundationModelManager.respond(to: text, thread: thread)
    ├─→ MLX: respondWithMLX(to: text, model: mlxModel, thread: thread)
    └─→ Cloud: respondWithAPIWithTokenTracking(to: text, model: model, thread: thread)
           ↓
           MessagesManager.apiMessages(for: thread, model: model)
           ↓
           callOpenAIAPIWithMessages(...) / callAnthropicAPIWithMessages(...) / etc.
    ↓
Chat(content: response, sender: .agent)
```

### Streaming Path

```
ThreadViewModel.sendMessage(text)
    ↓
MultiModelManager.streamResponse(to: text, thread: thread)
    ↓
    ├─→ Foundation: foundationModelManager.streamResponse(to: text, thread: thread)
    ├─→ MLX: mlxModelManager.generate(model: mlxModel, messages: messages)
    └─→ Cloud: streamViaDirectAPI(text: text, model: model)
           ↓
           callOpenAIStreamingAPI(...) / callAnthropicStreamingAPI(...) / etc.
    ↓
for await chunk in stream {
    agentChat.appendPlaintextChunk(chunk)
}
```

---

## Key Differences Summary

| Feature | Foundation Models | MLX Models | Cloud Models |
|---------|------------------|------------|--------------|
| **Location** | On-device (iOS 26+) | On-device (local files) | Remote API |
| **Cost** | Free | Free | Pay per token |
| **Context Handling** | Automatic (session transcript) | Manual (message array) | Manual (message array) |
| **Requires Thread** | Yes | No (optional) | No (optional) |
| **Memory Management** | Internal | External (cache) | N/A |
| **Token Limits** | Framework handles | Model-specific | Provider-specific |
| **API Key** | No | No | Yes |
| **Availability Check** | `SystemLanguageModel.default.availability` | File system check | API key check |
| **Streaming** | `session.streamResponse()` | `generate()` returns stream | SSE/streaming API |
| **Cancellation** | AsyncStream termination | `cancelGeneration()` | Task cancellation |
| **Fallback Support** | Yes (to cloud) | No | N/A |
| **Safety Guardrails** | Built-in | None | Provider-specific |

---

## Memory & Context Management

### Foundation Models
- Context managed internally by `LanguageModelSession`
- No manual message building required
- Thread parameter passed for consistency but not used for context

### MLX Models
```swift
// Memory enabled: Include full conversation history
if settings.globalMemoryEnabled && settings.isMemoryEnabled(for: thread.id) {
    messages = buildMLXMessages(for: text, thread: thread, model: mlxModel)
}
// Memory disabled: Only current message
else {
    messages = [
        ["role": "system", "content": systemPrompt],
        ["role": "user", "content": text]
    ]
}
```

### Cloud Models
```swift
// Token-aware context building with truncation
let contextResult = await messagesManager.apiMessages(
    for: thread,
    respectTokenLimits: true  // Enable smart truncation
)

if contextResult.tokenCount > effectiveLimit {
    // Truncate oldest messages
    // Generate summary if needed
    // Insert summary as system message
}
```

---

## Error Handling & Fallback

### Foundation Model Fallback
When Foundation Models fail (safety guardrails, unavailable, etc.):

```swift
// MultiModelManager.respondWithLocalModel()
catch FoundationModelManager.FoundationModelManagerError.safetyGuardrailsTriggered {
    foundationModelFailureCount += 1
    
    if autoFallbackEnabled && foundationModelFailureCount >= maxFoundationFailures {
        // Automatic fallback to cloud model
        return try await attemptFallbackResponse(to: text, thread: thread, originalError: error)
    }
    
    throw MultiModelError.foundationModelUnavailable(reason: "safety", fallbackUsed: true)
}
```

Fallback model selection:
```swift
func selectFallbackModel() -> AIModel? {
    for modelId in preferredFallbackOrder {
        if let model = availableModels.first(where: { $0.id == modelId }) {
            return model
        }
    }
    // Default to first available cloud model
    return availableModels.first(where: { !$0.isLocal && $0.requiresAPIKey })
}
```

---

## Performance Optimizations

### Model Caching
```swift
// MLX: Cache loaded models to avoid reload
let modelCache = NSCache<NSString, MLXLMCommon.ModelContainer>()
```

### Token Estimation
```swift
// Fast token estimation (4 chars ≈ 1 token)
func estimateTokens(in text: String) -> Int {
    return max(1, text.count / 4)
}
```

### Context Truncation
```swift
// Only rebuild context when model changes or chats added
if thread.needsContextRecalculation(for: model.id) {
    let result = await messagesManager.rebuildContextForModel(model, thread: thread)
    thread.updateContextCache(modelId: model.id, tokenCount: result.tokenCount)
}
```

### View Updates
```swift
// Throttle view updates during streaming
if agentChat.content.count % 50 == 0 {
    scheduleViewUpdate()
}
```

---

## Testing & Debugging

### Model Availability Checks
```swift
// Foundation Models
if #available(iOS 26.0, *) {
    switch SystemLanguageModel.default.availability {
    case .available: // Ready
    case .unavailable(.deviceNotEligible): // Device too old
    case .unavailable(.appleIntelligenceNotEnabled): // Setting disabled
    case .unavailable(.modelNotReady): // Downloading
    }
}

// MLX Models
#if targetEnvironment(simulator)
    return false  // MLX doesn't work on simulator
#else
    return settings.mlxEnabled && !downloadedModels.isEmpty
#endif

// Cloud Models
guard apiKeyManager.hasAPIKey(for: provider) else {
    throw MultiModelError.missingAPIKey(provider: provider.displayName)
}
```

### Logging
Each model type has debug logging:
```swift
print("🔍 [Respond] Using Foundation model (iOS 26+)")
print("🔵 [MLX Response] Starting generation with model: \(model.displayName)")
print("🔍 [Direct API] Retrieved API key: \(String(apiKey.prefix(10)))...")
```

---

## Conclusion

ChAI's chat architecture provides a unified interface that seamlessly handles three very different model types:

1. **Foundation Models**: Leverage Apple's on-device AI with automatic context management
2. **MLX Models**: Run quantized models locally with full control over message arrays
3. **Cloud Models**: Access external APIs with intelligent token-aware context building

The `MultiModelManager` acts as the central orchestrator, routing requests to the appropriate handler while providing consistent error handling, token tracking, and streaming support across all model types.
--- END FILE ---

--- FILE: FoundationModels-Using-on-device-LLM-in-your-app.md ---
# Foundation Models: Using Apple's On-Device LLM in Your Apps

## Overview

Foundation Models is an Apple framework that provides access to on-device large language models (LLMs) that power Apple Intelligence. This framework enables developers to enhance their apps with generative AI capabilities without requiring cloud connectivity or compromising user privacy.

Key capabilities include:
- Text generation and understanding
- Content summarization and extraction
- Structured data generation
- Custom tool integration

## Getting Started

### Check Model Availability

Always check if the model is available before attempting to use it. Model availability depends on device factors such as Apple Intelligence support, system settings, and device state.

```swift
struct GenerativeView: View {
    // Create a reference to the system language model
    private var model = SystemLanguageModel.default

    var body: some View {
        switch model.availability {
        case .available:
            // Show your intelligence UI
            Text("Model is available")
        case .unavailable(.deviceNotEligible):
            // Show an alternative UI
            Text("Device not eligible for Apple Intelligence")
        case .unavailable(.appleIntelligenceNotEnabled):
            // Ask the person to turn on Apple Intelligence
            Text("Please enable Apple Intelligence in Settings")
        case .unavailable(.modelNotReady):
            // The model isn't ready (downloading or other system reasons)
            Text("Model is downloading or not ready")
        case .unavailable(let other):
            // The model is unavailable for an unknown reason
            Text("Model unavailable: \(other)")
        }
    }
}
```

### Create a Session

After confirming model availability, create a `LanguageModelSession` to interact with the model:

```swift
// Create a basic session with the system model
let session = LanguageModelSession()

// Create a session with instructions
let instructions = """
    You are a helpful assistant that provides concise answers.
    Keep responses under 100 words and focus on clarity.
    """
let sessionWithInstructions = LanguageModelSession(instructions: instructions)
```

- For single-turn interactions, create a new session each time
- For multi-turn interactions, reuse the same session to maintain context

## Basic Usage

### Provide Instructions to the Model

Instructions help steer the model's behavior for your specific use case. The model prioritizes instructions over prompts.

Good instructions typically specify:
- The model's role (e.g., "You are a mentor")
- What the model should do (e.g., "Help extract calendar events")
- Style preferences (e.g., "Respond as briefly as possible")
- Safety measures (e.g., "Respond with 'I can't help with that' for dangerous requests")

```swift
let instructions = """
    You are a cooking assistant.
    Provide recipe suggestions based on ingredients.
    Keep suggestions brief and practical for home cooks.
    Include approximate cooking time.
    """

let session = LanguageModelSession(instructions: instructions)
```

### Provide a Prompt to the Model

A prompt is the input that the model responds to. Effective prompts are:
- Conversational (questions or commands)
- Focused on a single, specific task
- Clear about the desired output format and length

```swift
// Simple prompt
let prompt = "What's a good month to visit Paris?"

// Specific prompt with output constraints
let specificPrompt = "Write a profile for the dog breed Siberian Husky using three sentences."
```

### Generate a Response

Call the model asynchronously to get a response:

```swift
// Basic response generation
let response = try await session.respond(to: prompt)
print(response.content)

// With custom generation options
let options = GenerationOptions(temperature: 0.7)
let customResponse = try await session.respond(to: prompt, options: options)
```

Note: A session can only handle one request at a time. Check `isResponding` to verify the session is available before sending a new request.

## Advanced Features

### Guided Generation

Guided generation allows you to receive model responses as structured Swift data instead of raw strings. This provides stronger guarantees about the format of the response.

#### 1. Define a Generable Type

```swift
@Generable(description: "Basic profile information about a cat")
struct CatProfile {
    // A guide isn't necessary for basic fields
    var name: String

    @Guide(description: "The age of the cat", .range(0...20))
    var age: Int

    @Guide(description: "A one sentence profile about the cat's personality")
    var profile: String
}
```

#### 2. Request a Response in Your Custom Type

```swift
// Generate a response using the custom type
let catResponse = try await session.respond(
    to: "Generate a cute rescue cat",
    generating: CatProfile.self
)

// Use the structured data
print("Name: \(catResponse.content.name)")
print("Age: \(catResponse.content.age)")
print("Profile: \(catResponse.content.profile)")
```

#### 3. Printing a Response from your Custom Type

When printing values from a LanguageModelSession.Response always use the instance property content. Not output.

For example:

```swift
import FoundationModels
import Playgrounds

@Generable
struct CookbookSuggestions {
    @Guide(description: "Cookbook Suggestions", .count(3))
    var suggestions: [String]
}

#Playground {
    let session = LanguageModelSession()

    let prompt = "What's a good name for a cooking app?"

    let response = try await session.respond(
        to: prompt,
        generating: CookbookSuggestions.self
    )

    // Notice how print values come from content. Not output.
    print(response.content.suggestions)
}
```

### Tool Calling

Tool calling allows the model to use custom code you provide to perform specific tasks, access external data, or integrate with other frameworks.

#### 1. Create a Custom Tool

```swift
// Define a tool for searching recipes
struct RecipeSearchTool: Tool {
    struct Arguments: Codable {
        var searchTerm: String
        var numberOfResults: Int
    }
    
    func call(arguments: Arguments) async throws -> ToolOutput {
        // Search your recipe database
        let recipes = await searchRecipes(term: arguments.searchTerm, 
                                         limit: arguments.numberOfResults)
        
        // Return results as a string the model can use
        return .string(recipes.map { "- \($0.name): \($0.description)" }.joined(separator: "\n"))
    }
    
    private func searchRecipes(term: String, limit: Int) async -> [Recipe] {
        // Implementation to search your database
        // ...
    }
}
```

#### 2. Provide the Tool to a Session

```swift
// Create the tool
let recipeSearchTool = RecipeSearchTool()

// Create a session with the tool
let session = LanguageModelSession(tools: [recipeSearchTool])

// The model will automatically use the tool when appropriate
let response = try await session.respond(to: "Find me some pasta recipes")
```

#### 3. Handle Tool Errors

```swift
do {
    let answer = try await session.respond("Find a recipe for tomato soup.")
} catch let error as LanguageModelSession.ToolCallError {
    // Access the name of the tool
    print(error.tool.name) 
    
    // Access the underlying error
    if case .databaseIsEmpty = error.underlyingError as? RecipeSearchToolError {
        // Handle specific error
    }
} catch {
    print("Other error: \(error)")
}
```

## Snapshot streaming

- LLM generate text as short groups of characters called tokens.
- Typically, when streaming tokens, tokens are delivered in what's called a delta. But Foundation Models does this different.
- As deltas are produced, the responsibility for accumulating them usually falls on the developer
- You append each delta as they come in. And the response grows as you do. But it gets tricky when the result has structure.
- If you want to show the greeting string after each delta, you have to parse it out of the accumulation, and that's not trival, especially for complicated structures.
- Structured output is at the core of the Foundation Model framework. Which is why we stream snapshots.

## Snapshot streaming

- LLM generate text as short groups of characters called tokens.
- Typically, when streaming tokens, tokens are delivered in what's called a delta. But Foundation Models does this different.
- As deltas are produced, the responsibility for accumulating them usually falls on the developer
- You append each delta as they come in. And the response grows as you do. But it gets tricky when the result has structure.
- If you want to show the greeting string after each delta, you have to parse it out of the accumulation, and that's not trival, especially for complicated structures.
- Structured output is at the core of the Foundation Model framework. Which is why we stream snapshots.

### What are snapshots

- Snapshots represent partically generated response. Their properties are all optinoal. And they get filled in as the model produces more of the response.
- Snapshots are a robust and convenient representation for streaming structure output.
- You are already familar with the `@Generable` macro, and as it turns out, it's also where the definitions for partially generated types come from.
- If you expand the macro, you'll discover it produces a types named `PartiallyGenerated`. It is effectively a mirror of the outer structure except every property is optional.
- The partically generated type comes into play when you call the 'streamResponse` method on your session.

```swift
import FoundationModels
import Playgrounds

@Generable
struct TripIdeas {
    @Guide(description: "Ideas for upcoming trips")
    var ideas: [String]
}

#Playground {
    let session = LanguageModelSession()

    let prompt = "What are some exciting trip ideas for the upcoming year?"

    let stream = session.streamResponse(
        to: prompt,
        generating: TripIdeas.self
    )

    for try await partial in stream {
        print(partial)
    }
}
```

- Stream response returns an async sequence. And the elements of that sequence are instances of a partially generated type.
- Each element in the sequence will contain an updated snapshot.
- These snapshots work great with declarative frameworks like SwiftUI.
- First, create state holding a partially generated type.
- Then, just iterate over a response stream, stores its elements, and watch as your UI comes to life.

## Best Practices and Limitations

### Context Size Limits

- The system model supports up to 4,096 tokens per session
- A token is roughly 3-4 characters in languages like English
- All instructions, prompts, and outputs count toward this limit
- If you exceed the limit, you'll get a `LanguageModelSession.GenerationError.exceededContextWindowSize` error
- For large data processing, break it into smaller chunks across multiple sessions

### Optimizing Performance

- Use `GenerationOptions` to tune model behavior:
  ```swift
  let options = GenerationOptions(temperature: 2.0) // Higher temperature = more creative
  ```
- Use Xcode Instruments to monitor request performance
- Access `Transcript` entries to see model actions during a session:
  ```swift
  let transcript = session.transcript
  ```

### Prompt Engineering Tips

- Be specific about what you want
- Specify output constraints (e.g., "in three sentences")
- Break complex tasks into multiple simple prompts
- Use examples in instructions to guide the model's output format

## References

- [Generating content and performing tasks with Foundation Models](https://developer.apple.com/documentation/FoundationModels/generating-content-and-performing-tasks-with-foundation-models)
- [Generating Swift data structures with guided generation](https://developer.apple.com/documentation/FoundationModels/generating-swift-data-structures-with-guided-generation)
- [Expanding generation with tool calling](https://developer.apple.com/documentation/FoundationModels/expanding-generation-with-tool-calling)
- [Human Interface Guidelines: Generative AI](https://developer.apple.com/design/human-interface-guidelines/technologies/generative-ai)
--- END FILE ---

--- FILE: Support-languages-and-locales-with-Foundation-Models.md ---
# Support languages and locales with Foundation Models

**Generate content in the language people prefer when they interact with your app.**


## Overview

The on-device system language model is multilingual, which means the same model understands and generates text in any language that Apple Intelligence supports. The model supports using different languages for prompts, instructions, and the output that the model produces.

When you enhance your app with multilingual support, generate content in the language people prefer to use when they interact with your app by:

- Prompting the model with the language you prefer.

- Including the target language for your app in the instructions you provide the model.

- Determining the language or languages a person wants to use when they interact with your app.

- Gracefully handling languages that Apple Intelligence doesn’t support.

For more information about the languages and locales that Apple Intelligence supports, see the “Supported languages” section in [https://support.apple.com/en-us/121115](https://support.apple.com/en-us/121115).


## Prompt the model in the language you prefer

Write your app’s built-in prompts in the language with which you normally write code, if Apple Intelligence supports that language. Translate your prompts into a supported language if your preferred language isn’t supported. In the code below, *all* inputs need to be in supported language for the model to understand, including all `Generable` types and descriptions:

```swift
@Generable(description: "Basic profile information about a cat")
struct CatProfile {
    var name: String

    @Guide(description: "The age of the cat", .range(0...20))
    var age: Int

    @Guide(description: "One sentence about this cat's personality")
    var profile: String
}

#Playground {
    let response = try await LanguageModelSession().respond(
        to: "Generate a rescue cat",
        generating: CatProfile.self
    )
}
```

Because the framework treats `Generable` types as model inputs, the names of properties like `age` or `profile` are just as important as the `@Guide` descriptions for helping the model understand your request.


## Check a person’s language settings for your app

People can use the Settings app on their device to configure the language they prefer to use on a per-app basis, which might differ from their default language. If your app supports a language that Apple Intelligence doesn’t, you need to verify that the current language setting of your app is supported before you call the model. Keep in mind that language support improves over time in newer model and OS versions. Thus, someone using your app with an older OS may not have the latest language support.

Before you call the model, run [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/supportsLocale(_:)](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/supportsLocale(_:)) to verify the support for a locale. By default, the method uses [doc://com.apple.documentation/documentation/Foundation/Locale/current](https://developer.apple.com/documentation/Foundation/Locale/current), which takes into account a person’s current language and app-specific settings. This method returns true if the model supports this locale, or if this locale is considered similar enough to a supported locale, such as `en-AU` and `en-NZ`:

```swift
if SystemLanguageModel.default.supportsLocale() {
    // Language is supported.
}
```

For advanced use cases where you need full language support details, use [doc://com.apple.foundationmodels/documentation/FoundationModels/SystemLanguageModel/supportedLanguages](https://developer.apple.com/documentation/FoundationModels/SystemLanguageModel/supportedLanguages) to retrieve a list of languages supported by the on-device model.


## Handle an unsupported language or locale errors

When you call [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/respond(to:options:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/respond(to:options:)) on a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession), the Foundation Models framework checks the language or languages of the input prompt text, and whether your prompt asks the model to respond in any specific language or languages. If the model detects a language it doesn’t support, the session throws [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/unsupportedLanguageOrLocale(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/unsupportedLanguageOrLocale(_:)). Handle the error by communicating to the person using your app that a language in their request is unsupported.

If your app supports languages or locales that Apple Intelligence doesn’t, help people that use your app by:

- Explaining that their language isn’t supported by Apple Intelligence in your app.

- Disabling your Foundation Models framework feature.

- Providing an alternative app experience, if possible.


> **IMPORTANT**: Guardrails for model input and output safety are only for supported languages and locales. If a prompt contains sensitive content in an unsupported language, which typically is a short phrase mixed-in with text in a supported language, it might not throw a [doc://com.apple.foundationmodels/documentation/FoundationModels/LanguageModelSession/GenerationError/unsupportedLanguageOrLocale(_:)](https://developer.apple.com/documentation/FoundationModels/LanguageModelSession/GenerationError/unsupportedLanguageOrLocale(_:)) error. If unsupported-language detection fails, the guardrails may also fail to flag that short, unsupported content. For more on guardrails, see [doc://com.apple.foundationmodels/documentation/FoundationModels/improving-the-safety-of-generative-model-output](https://developer.apple.com/documentation/FoundationModels/improving-the-safety-of-generative-model-output).



## Use Instructions to set the language for model output

By default, the model responds in the language or languages of its inputs. If your app supports multiple languages, prompts that you write and inputs from people using your app, might be in different languages. For example, if you write your built-in prompts in Spanish, but someone using your app writes inputs in Dutch, the model may respond in either or both languages. If this issue occurs, use [doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) to explicitly tell the model which language or languages with which it needs to respond.

First, to ensure the best response quality, start your [doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) by using this *exact* phrase in English. This special phrase comes from the model’s training, and reduces the possibility of hallucinations in multilingual situations:

```swift
func localeInstructions(for locale: Locale = Locale.current) -> String {
    return "The user's locale is \(locale.identifier)."
}
```

Next, continue your [doc://com.apple.foundationmodels/documentation/FoundationModels/Instructions](https://developer.apple.com/documentation/FoundationModels/Instructions) with a phrase that tells the model which language or languages to use in its output. You can phrase this request in different ways, for example: “You MUST respond in Italian” or “You MUST respond in Italian and be mindful of Italian spelling, vocabulary, entities, and other cultural context of Italy.” These instructions can be in your preferred language.

Finally, thoroughly test your instructions to ensure the model is responding in the way you expect. If the model isn’t following your instructions, try capitalized words like “MUST” or “ALWAYS” to strengthen your instructions.

---

*Source: [https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/support-languages-and-locales-with-foundation-models](https://developer.apple.com/documentation/com.apple.foundationmodels/documentation/FoundationModels/support-languages-and-locales-with-foundation-models)*
--- END FILE ---
=== END SWIFT DOCUMENTATION ===
=== END CONTEXT ===

=== BUILD ATTEMPT 2 FAILED ===
The previous implementation failed with the following errors:

codex CLI invocation failed. Please try again.

=== INSTRUCTIONS FOR ATTEMPT 3 ===
1. Analyze what went wrong in the previous approach
2. Try a DIFFERENT approach or fix the specific issues
3. Do NOT repeat the same mistakes
4. If the same approach keeps failing, consider an alternative implementation strategy
5. Write the corrected code directly - do not explain, just implement

Please fix the issues and provide the corrected implementation.